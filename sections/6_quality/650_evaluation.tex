\chapter{Evaluation and Discussion 
    \pgsize{15 p.}
}
\label{chap:commonalities_evaluation}

\todo{Draw tree structure of case study PCM-UML-Java (best from thesis Lukas)}

\todo{Aus MA Lukas aufgreifen: Was mir insgesamt sehr stark fehlt ist eine Erklärung der Idee der Baumstruktur. Letztendlich dreht sich die ganze Zeitlsetzung des Ansatzes und der Validierung in deiner Arbeit darum festzustellen, ob so etwas erreichbar ist. Du erklärst aber nirgendwo genauer, was du mit so einer Baumstruktur meinst. Das ist aber natürlich essentiell um da sinnvoll evaluieren zu können. Wenn du das genauer erklärst, werden auch die zugrundeliegenden Problemstellungen wie Inkompatibilitäten für den Zuhörer nachvollziehbar.
Du musst also mindestens noch eine Folie ergänzen, auf der du mal im Detail erklärst, was man unter so einer Baumstruktur versteht, zwischen welchen Elementen die bestehen muss usw.
Außerdem musst du dann später reflektieren, wer für das Einhalten der Baumstruktur zuständig ist, also ob das durch Ansatz/Sprache inhärent gegeben ist, ob das ein Entwickler selbst sicherstellen muss, ob man das analysieren kann usw.}

\section{Goals and Methodology}

\begin{table}
    \renewcommand{\arraystretch}{1.4}%
    \rowcolors{1}{\secondlinecolor}{\firstlinecolor}
    \begin{tabular}{L{8.2em} L{20em}}
        \toprule
        \rowcolor{\headinglinecolor}
        \goal{Approach} & 
            Show that concept and language can achieve consistency between several models. \\
        \question[eq:commonalities:correctness]{Correctness} & 
            \questiontext{How many model changes in a case study can be properly kept consistent?} \\
        \metric & 
            \metrictext{Ratio of successfull test cases} \\
        \question[eq:commonalities:practicality]{Practicality} & 
            \questiontext{How far is the assumption of defining a tree of \commonalities is achievable in practice?} \\
        \metric & 
            \metrictext{Number of cross-tree relations in a case study compared to number of relations} \\
            \midrule
        %
    \end{tabular}
    \rowcolors{1}{\secondlinecolor}{\firstlinecolor}
    \begin{tabular}{L{8.2em} L{20em}}
        \rowcolor{\headinglinecolor}
        \goal{Language} & 
            Show that a specialized language improves conciseness of consistency specifications \\
        \question[eq:language:benefit]{Benefit} & 
            \questiontext{How much more concise is the specification for a case study compared to a definition with direct transformations?} \\
        \metric & 
            \metrictext{Number of SLOC with \commonalities compared to number of SLOC with \reactions for same case study} \\
        \bottomrule
    \end{tabular}
    \caption[Goals, questions, metrics for commonalities]{Goals, questions and metrics for commonalities approach and language.}
    \label{tab:commonalities_evaluation:gqm}
\end{table}

% \gqm{Functionality}{Concept and language can achieve consistency between several models}{How many model changes in a case study can be properly kept consistent?}{Ratio of successfull test cases}

% \gqm{Practicality}{The assumption of defining a tree of \commonalities is achievable in practice}{Is the definition of cross-tree relations necessary in a case study?}{Number of cross-tree relations in a case study compared to number of relations}

% \gqm{Practicality/Benefit}{A specific language improves conciseness of consistency specifications}{How much more concise is the specification for a case study compared to a definition with direct transformations?}{Number of SLOC with \commonalities compared to number of SLOC with \reactions for same case study}

Diskussion: Erreichen der Modularität auch evaluieren? Ist per Konstruktion gegeben, könnte man aber natürlich auch noch auswerten (bringt aber nichts).


\section{Prototypical Implementation}

\section{Case Study}

* 15 Commonalities, 8 in OO, 7 in CBS, overview in A.2 of Hennig
\begin{table}[htb]
	\centering
	%\resizebox{\textwidth}{!}{
		\begin{tabular}{lrrrrr}
			\toprule
			\multicolumn{1}{l}{\bfseries Element Type} & \multicolumn{1}{r}{\bfseries PCM} & \multicolumn{1}{r}{\bfseries Direct} & \multicolumn{1}{r}{\bfseries Internal} & \multicolumn{1}{r}{\bfseries Total} & \multicolumn{1}{r}{\bfseries \%}\\
			\midrule
			Metaclasses 				& 16 & 7  & 2 		& 9 & 0.59  \\
			Attributes 					& 15 & 7  & 1 		& 8 & 0.53 \\
			Containment References 		& 18 & 6  & 0 		& 6 & 0.33  \\
			Non-containment References 	& 8  & 3  & 1  		& 4 & 0.50  \\
			Enums 						& 1  & 0  & 1  		& 1 & 1.00  \\
			\midrule
			Total 						& 58  & 23  & 5  	& 28 & 0.48  \\
			\bottomrule
		\end{tabular}
	%}
	\caption{Number of directly, internally, and total covered element types of PCM. Adapted from~\cite[Table 10.3]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:coverage_pcm}
\end{table}

Total elements relevant for case studies (as depicted in \autoref{chap:correctness_evaluation:compatibility:case_study}), directly covered elements (those as manifestations / participations in \commonalities) and indirectly covered elements (referenced within operators but not as participations, because they are only relevant when transferring information of other elements but not on their own).
Those internal elements are primitive data types, enums etc., but also UML interface realizations due to indirect reference of generalization which cannot be mapped yet, same as for provided role in PCM

Many Java elements internally covered, because primitive types, type references and modifiers are represented as metaclasses, which are not mapped on their own but only in context of an operator

\begin{table}[htb]
	\centering
	%\resizebox{\textwidth}{!}{
		\begin{tabular}{lrrrrr}
			\toprule
			\multicolumn{1}{l}{\bfseries Element Type} & \multicolumn{1}{r}{\bfseries UML} & \multicolumn{1}{r}{\bfseries Direct} & \multicolumn{1}{r}{\bfseries Internal} & \multicolumn{1}{r}{\bfseries Total} & \multicolumn{1}{r}{\bfseries \%}\\
			\midrule
			Metaclasses 				& 13	& 7		& 3	& 10	& 0.77	\\
			Attributes 					& 27	& 19	& 1	& 20	& 0.74	\\
			Containment References 		& 13	& 9		& 0	& 9		& 0.69	\\
			Non-containment References 	& 4		& 2		& 2	& 4		& 1.00	\\
			Enums 						& 2		& 0		& 2	& 2		& 1.00	\\
			\midrule
			Total 						& 59	& 37	& 8	& 45	& 0.76	\\
			\bottomrule
		\end{tabular}
	%}
	\caption{Number of directly, internally, and total covered element types of UML. Adapted from~\cite[Table 10.4]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:coverage_uml}
\end{table}


\begin{table}[htb]
	\centering
	%\resizebox{\textwidth}{!}{
		\begin{tabular}{lrrrrr}
			\toprule
			\multicolumn{1}{l}{\bfseries Element Type} & \multicolumn{1}{r}{\bfseries Java} & \multicolumn{1}{r}{\bfseries Direct} & \multicolumn{1}{r}{\bfseries Internal} & \multicolumn{1}{r}{\bfseries Total} & \multicolumn{1}{r}{\bfseries \%}\\
			\midrule
			Metaclasses 				& 30	& 9		& 11	& 20	& 0.67	\\
			Attributes 					& 13	& 11	& 0		& 11	& 0.85	\\
			Containment References 		& 32	& 19	& 1		& 20	& 0.63	\\
			Non-containment References 	& 1		& 0		& 0		& 0		& 0.00	\\
			Enums 						& 0		& 0		& 0		& 0		& 1.00	\\
			\midrule
			Total 						& 76	& 39	& 12	& 51	& 0.67	\\
			\bottomrule
		\end{tabular}
	%}
	\caption{Number of directly, internally, and total covered element types of Java. Adapted from~\cite[Table 10.5]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:coverage_java}
\end{table}

FROM LUKAS: 
Of the total \textbf{193} identified element types, our commonalities cover \textbf{124} (\textbf{64.25\%}) elements in total, \textbf{99} of which are covered directly and \textbf{25} are covered internally by operators. The largest portion of elements that are not covered is associated with PCM (\textbf{52\%}). We mostly covered all UML and Java elements that we considered in our cases study (\textbf{98\%} and \textbf{96\%} respectively), but of the total identified elements we only cover \textbf{76\%} and \textbf{67\%}.


NOT COVERED:
* Composite Components: Same as basic ones, need to be distinguished (e.g. by naming schema, user interaction or containment of other components), but then are comparable to basic ones, so no further insights
* Provided/Require Role, Generalization internally use non-containment references (discussed above)
* System: no covered intentionally, is basically only a composite component
* CollectionDataType: complicated to map between multiplicities in Java and Collection data types in Java and PCM. Other data types are already mapped. Since each type can only be related to one kind of data type, there are not further problems to be expected regarding a tree structure. It is basically doing and potentially limitations of existing operators of the language, but no conceptual problems.


\section{Results and Interpretation}

\begin{table}[htb]
	\centering
	%\resizebox{\textwidth}{!}{
		\begin{tabular}{lrrr}
			\toprule
			\multicolumn{1}{l}{\bfseries Test Group} & \multicolumn{1}{r}{\bfseries \# Test Scenarios} & \multicolumn{1}{r}{\bfseries \# Test Cases} & \multicolumn{1}{r}{\bfseries \# Failing Test Cases} \\
			\midrule
			Repository 				& 1	& 6		& 0		 \\
			ComponentInterface 		& 1 & 6		& 0		 \\
			Component 				& 1	& 6		& 0		 \\
			CompositeDataType 		& 8	& 48	& 0		 \\
			Operation 				& 8	& 48	& 0		 \\
			% PCM/UML -> Java
			ProvidedRole 			& 2	& 12	& 10		 \\
			\midrule
			Total 					& 21& 126	& 12		 \\
			\bottomrule
		\end{tabular}
	%}
	\caption{Test groups for CBS. Adapted from~\cite[Table 10.1]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:tests_cbs}
\end{table}

Provided role failures: Faulty definition of operator - provided interface of a role is only used in operator but not defined as parameter/participation, such that no reaction for its change is created
Limited expressiveness: Language cannot express mapping between non-containment reference (in Java) to containment reference with object (role) + non-containment reference (interface) (in PCM).

\begin{table}[htb]
	\centering
	%\resizebox{\textwidth}{!}{
		\begin{tabular}{lrrr}
			\toprule
			\multicolumn{1}{l}{\bfseries Test Group} & \multicolumn{1}{r}{\bfseries \# Test Scenarios} & \multicolumn{1}{r}{\bfseries \# Test Cases} & \multicolumn{1}{r}{\bfseries \# Failing Test Cases} \\
			\midrule
			Package 			& 3		& 6		& 0		 \\
			Interface 			& 5 	& 10	& 0		 \\
			InterfaceMethod 	& 14	& 28	& 0		 \\
			Class 				& 13	& 26	& 0		 \\
			Property 			& 10	& 20	& 0		 \\
			ClassMethod 		& 20	& 40	& 0		 \\
			% 1 scenario disabled: multi constructor
			Constructor 		& 12	& 24	& 1		 \\
			\midrule
			Total 				& 77	& 154	& 1		 \\
			\bottomrule
		\end{tabular}
	%}
	\caption{Test groups for OO. Adapted from~\cite[Table 10.2]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:tests_oo}
\end{table}

OO Constructor: Problem in \vitruv framework -- after two constructor creations, first both constructors are propagated before propagating the insertion of parameters. This results in two indistinguishable constructors (with empty parameter lists) in Java, which results in problems of the subsequent parameter propagation for one of them.
Adding one constructor after another (either in the test, i.e., by the user, or as propagation of the framework) would solve the problem.


MEDIA STORE

* From PCM to UML
* Only elements already supported (components, interfaces, data types, signatures with parameters)
* Missing: provided and required roles


\begin{table}[htb]
	\centering
	%\resizebox{\textwidth}{!}{
		\begin{tabular}{lrrrr}
			\toprule
			\multicolumn{1}{l}{\bfseries } & \multicolumn{1}{r}{$CS_{{UML}\leftrightarrow{Java}}$ (omitted)} & \multicolumn{1}{r}{$CS_{{UML}\leftrightarrow{Java}}$ (covered)} & \multicolumn{1}{r}{OO} & \multicolumn{1}{r}{$\Delta$}\\
			\midrule
			Specifications 			& 302	& 2390 	& 514 	& -1876 \\
			Utilities				& 445	& 2250	& 2523 	& 273 \\
			\midrule
			Total					& 747	& 4640 	& 3037 	& -1603\\
			\bottomrule
		\end{tabular}
	%}
	\caption[Lines of code in the consistency specifications for UML and Java]{Lines of code in the consistency specifications for UML and Java ($\Delta$ is the difference from $CS_{{UML}\leftrightarrow{Java}}$ (covered) to OO)}
	\label{tab:commonalities_evaluation:reactions_comparison}
\end{table}



\section{Discussion and Validity}

\section{Limitations and Future Work}
Limited to descriptive specification

Language does not provide inheritance for commonalities, repeated definition of names, repeated definition of shared information, e.g., between basic and composite components etc.

Limited set of operators, e.g., no generic operator for mapping attributes to references (e.g. visibility is EnumLiteral in UML, whereas it is a reference to a type instance in Java), complex pattern mappings, e.g., type reference in UML is direct reference, whereas in Java a reference contains a reference object, which then references a further object that references the type; or primitive types in Java represented as types and in UML as predefined instances of a generic primitive type type.

Movement of objects treated as removal and insertion leading to deletion of contained elements and values


Granularity of operators: open research question how to define a reusable set with appropriate degree of abstraction, such that only for few cases custom operators need to be defined. Especially necessary to define a metrics for that (what are "few cases"?). Currently left open in language design (see diagram with arbitrary operators) and implemented specific for case-study (as focus on structure of language, not on realization of manifestation relations).

Tree: Developer has to ensure that a tree is achieved. Can be improved by the language. Integrate compatibility approach from \autoref{chap:compatibility} into the language. Due to rather declarative specification, graph of consistency relations can be derived and analyzed. Assumptions have to be made on operators, which can do arbitrary stuff, e.g. that only the elements explicitly given to the operator are used, and no further navigation through the model is done within the operator. With that assumption, we can construct the graph from the commonalities specifications and operator arguments and apply the analysis.


\section{Summary}



\begin{copiedFrom}{VoSE}

\section*{Proof-of-Concept}

We have proposed the \commonalities approach and a realizing language.
We have explained that we expect them to improve understandability of transformations and to reduce problems of transformation networks, such as compatibility and modularity.
Although we gave arguments that justify this expectation, it has to be evaluated empirically to increase evidence.
However, before evaluating the benefits of our approach, we first have to investigate its feasibility.
For that reason, we built an initial prototype of the language and applied it to a simple evaluation case as a proof-of-concept.
%to show the feasibility of the concept.
%This forms our contribution~\ref{contrib:proofofconcept}.

% Evaluation Goal: Show feasibility of the idea

% Evaluation Methodology: Build a proof-of-concept prototype of a language and apply it to a simple case

\subsection*{Case Study}

We have implemented a prototype of the \commonalities language, which allows to define \commonalities with simple attribute and reference mappings and to compose \commonalities.
The syntax is an extension of the example shown in \autoref{lst:quality:commonalities_language_example}.
The language comprises a compiler that derives a \conceptmetamodel, as well as a set of transformations from a specification in the language.
The generated transformations are in turn defined in the \reactionslanguage~\cite{klare2016b}, which is a delta-based transformation language that is, just like the \commonalities language itself, part of the \vitruv approach~\cite{kramer2013b}.
\vitruv is a view-based development approach that uses transformations to keep models consistent.
The implementation of the \commonalities language can be found in the GitHub repository of the \vitruv project \cite{vitruvFrameworkGithub}. %\footnote{\label{githubfootnote}\url{https://github.com/vitruv-tools/Vitruv}}.

We have applied the implementation to a simple case study that consists of four metamodels, each containing one \metaclass that represents a root element and one that represents a contained element. 
Both elements have an identifier and a name in all metamodels, and an additional single-valued and multi-valued feature of integers in two of the metamodels.
The root \metaclass additionally has a containment reference to the contained \metaclass.
We have defined two \commonalities, one for the root element and one for the contained element, which redundantly represent the same concepts in all the metamodels.
The root \commonality references the contained \commonality.
This results in one \conceptmetamodel with four manifestations.

To validate that the specifications in the \commonalities language are correctly defined and operationalized, we have
%defined 8 test cases that 
defined test cases that perform 21 different model modifications, which 
%
create and delete all possible types of elements and modify all attribute and reference values in instances of every metamodel.
They cover the set of all possible modifications that can be performed on instances of those metamodels.
This also includes change propagation across composed \commonalities.
The tests successfully validate that the modifications are correctly propagated to all other models in all cases.
The test cases and the used example metamodels are also available in the GitHub repository of the \vitruv project \cite{vitruvFrameworkGithub}. %\footnotemark[1].

% \begin{itemize}
%     \item First reference to concrete implementation here
%     \item Refer to simple example implementation showing the ability to define and run the Commonalities approach
% \end{itemize}

\subsection*{Discussion}
% Formerly: Threats to Validity

%Maybe we can omit this section, but we need to discuss that it is really, really only a proof-of-concept (some reviewers do not understand the difference to a complete benefit, scalability and effectiveness evaluation if you do not tell them again and again).

Our proof-of-concept validates the feasibility of the proposed \commonalities approach: 
It demonstrates that it is possible to apply the concept of defining consistency relations between multiple metamodels  through a central metamodel in a simple scenario. It also shows that an operationalization can be derived that preserves consistency of all instances of such metamodels.
%Our evaluation only serves as a proof-of-concept to validate feasibility of the approach that we present in this paper.
%In consequence, 
The results only give an indicator that the \commonalities concept can be applied and that a language with an internal concept definition can be designed.
To further evaluate the capabilities of such an approach, the language would have to be extended to be able to define more complex relationships.
Additionally, the approach has to be applied to larger parts of more complex metamodels and metamodels for different contexts to improve external validity of the results.
This could also reveal whether the assumption of having a tree of \commonalities is practical in realistic scenarios.

Since evaluating functional capabilities of the approach is only an---essential---first step, the evaluation of further properties such as applicability, appropriateness, effectiveness and scalability are part of ongoing work with further case studies.
As a central benefit of our approach, we claim to improve understandability of relations between metamodels, but can only give arguments for that by now.
An evaluation of that claim would require a user experiment that compares our approach to specifications of direct transformations between multiple metamodels.

Finally, one might argue that defining \conceptmetamodels leads to additional effort, as for two metamodels it is necessary to define one additional metamodel and two transformations rather than only a single transformation.
First, this is only true as long as only two metamodels are related by one \conceptmetamodel. 
If three metamodels shall be related, there would be a network of three transformations, which are not necessarily compatible without using the \commonalities approach, and one metamodel with three transformations using the \commonalities approach.
When the \commonalities approach is applied, the number of necessary transformations increases linearly with the number of metamodels that are related, whereas it increases quadratic without them.
Second, the effort for defining transformations can be reduced by using an appropriate language to define \conceptmetamodels and transformations, as we have proposed in \autoref{chap:language}. Our language only requires developers to write one specification that contains both the \conceptmetamodel and all transformations to its manifestations.

% \subsection{Limitations}
% Contradictory Commonalities specifications?

\end{copiedFrom} % VoSE


