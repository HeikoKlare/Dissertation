\chapter{Evaluation and Discussion 
    \pgsize{15 p.}
}
\label{chap:commonalities_evaluation}

\mnote{Summary of contributions}
In the preceding chapters \ref{chap:classification}--\ref{chap:language}, we have discussed quality property of transformation networks and how they can be systematically improved.
We have discussed the effect of the network topology on properties, and we have derived the \commonalities approach for constructing transformation networks, which uses the effects of topologies to optimize specific quality properties.
Finally, we have proposed the \commonalities language and discussed central aspects of it, which supports the process of applying the \commonalities approach to define a transformation network.

\mnote{Trade-off mitigation by construction}
The central benefit of the developed \commonalities approach and the supporting \commonalities language is given by construction.
The way in which the transformation network is defined inherently improves correctness, especially in terms of compatibility (cf.\ \autoref{chap:compatibility}), and reusability, which are contradicting quality properties in a network of transformations that are directly defined between the metamodels whose instances are to be kept consistent.
We have argued this trade-off mitigation in more detail in \autoref{chap:improvement:benefits:properties}.
In addition to this central benefit, we discussed some further benefits that we expect from both the \commonalities approach as well as the \commonalities language in \autoref{chap:improvement:benefits} and \autoref{chap:language:commonalities:benefits}.
We empirically evaluate these benefits with a case study presented in this chapter.

\mnote{Empirical evaluation of \commonalities approach}
In the discussions of \autoref{chap:improvement} and \autoref{chap:language}, two general issues affecting the \commonalities approach remained that may only be solved by empirical investigations.
First, although consistency relations and their preservation are only described in a different way by means of auxiliary models, it may be possible that the approach restricts the possible consistency relations that can be described in any way, especially under the goal of achieving a consistency relation tree.
Second, the achievement of a consistency relation tree with the approach is important to maximize the compatibility guarantee while ensuring maximal reusability (see \autoref{chap:improvement:commonalities:tree}), but it is unclear how far or under which conditions this tree can be achieved in practice.

\mnote{Empirical evaluation of \commonalities language}
The \commonalities language provides the benefits of the \commonalities approach, but, as discussed in \autoref{chap:language:commonalities:benefits}, we also expect it to reduce the specification effort, which would actually increase with the \commonalities approach in comparison to an ordinary transformation network when employing existing tools for defining the auxiliary metamodels and transformations to them.
We have thus developed a prototype of that language and evaluate its correctness, as well as the goal of reducing specification effort in a case study.


\section{Goals and Methodology}

\mnote{Completeness, applicability and benefits}
In this evaluation, we aim to validate relevant properties of the \commonalities approach and the \commonalities language that are not given by their construction but have to be analyzed empirically.
This especially concerns the applicability of the approach and specific benefits provided by the language, but also the general completeness of the approach, i.e., the ability to express every required set of consistency relations.
It is an extension of the preliminary case study on feasibility that we have conducted and presented in previous work~\owncite{klare2019models}

\begin{table}
    \renewcommand{\arraystretch}{1.4}%
    \rowcolors{1}{\secondlinecolor}{\firstlinecolor}
    \begin{tabular}{L{8.2em} L{20em}}
        \toprule
        \rowcolor{\headinglinecolor}
        \goal{Approach} & 
            Show that transformation developers can use the \commonalities approach to specify consistency and its preservation between multiple models. \\
        \question[eq:commonalities:completeness]{Completeness} & 
			\questiontext{How far are the \commonalities approach and the \commonalities language capable of defining arbitrary conistency relations?} \\
        \metric & 
			\metrictext{Definition ratio: Ratio of consistency relations for which consistency can successfully be defined} \\
		\question[eq:commonalities:practicality]{Practicality} & 
            \questiontext{How far is the goal of achieving a consistency relation tree with \commonalities achievable in practice?} \\
        \metric & 
            \metrictext{Cross-tree ratio: Number of cross-tree relations compared to the number of relations} \\
            \midrule
    \end{tabular}
    \rowcolors{1}{\secondlinecolor}{\firstlinecolor}
    \begin{tabular}{L{8.2em} L{20em}}
        \rowcolor{\headinglinecolor}
        \goal{Language} & 
			Show that transformation developers can define consistency in a concise way with the \commonalities language. \\
		\question[eq:language:correctness]{Correctness} & 
			\questiontext{Do transformations generated by specifications in the \commonalities language preserve consistency according to the defined relations?} \\
        \metric & 
            \metrictext{Preservation ratio: Ratio of scenarios in which consistency can successfully be preserved} \\
        \question[eq:language:benefit]{Benefit} & 
            \questiontext{How much more concise is a specification in the \commonalities language to a specification in the \reactionslanguage?} \\
        \metric & 
            \metrictext{Code ratio: Ratio between the number of \acrshort{SLOC} in a \commonalities specification compared to the number of \acrshort{SLOC} with a \reactions specification for the same transformations} \\
        \bottomrule
    \end{tabular}
    \caption[Goals, questions, metrics for \commonalities]{Goals, questions and metrics for \commonalities approach and language.}
    \label{tab:commonalities_evaluation:gqm}
\end{table}

\mnote{Empirical evaluation in case study}
In the following, we present an empirical evaluation based on a case study, in which we apply a prototypical realization of the \commonalities language to consistency relations and their preservation in the domain of component-based software engineering, which we have already employed for the evaluation of our contributions regarding the construction of correct transformation networks in \autoref{chap:correctness_evaluation:categorization}.
We summarize the general goals of the evaluation along with according questions and metrics as quantitative measures for answering them in \autoref{tab:commonalities_evaluation:gqm}.

\mnote{Completeness evaluation}
Regarding the \commonalities approach as such, we are interested in the possibility to be used by transformation developers to define consistency preservation.
In a first place, this comprises the validation of completeness according to \autoref{chap:classification:properties}.
We want to find out whether it is possible to define arbitrary consistency relations with the \commonalities approach. 
In fact, \citeauthor{stevens2020BidirectionalTransformationLarge-SoSym} shows that a multiary relation can be expressed by an auxiliary metamodel with binary relations between this auxiliary metamodels and the metamodels to describe consistency between.
This means that also any set of binary relations, which induce a multiary relation as discussed in \autoref{chap:correctness:notions_consistency:monolithic_modular}, can be expressed by an auxiliary metamodel and binary relation between it and the metamodels to define consistency between.
This conforms to general idea of the \commonalities approach and, if recursively applied, even to the hierarchic composition of \commonalities.
Despite this theoretical insight, we investigate whether such a specification is actually achievable in practice, especially under the specific goal of achieving a consistency relation tree in a specification of \commonalities.
Even if the \commonalities approach itself may not be restricted in expressiveness, the proposed \commonalities language may be because of the selected way in which \commonalities and their relations are defined.
This leads to \autoref{eq:commonalities:completeness}, which we aim to answer by measuring how many consistency relations of our case study we are able to implement:
\begin{align*}
    &
    \mathvariable{definition\ ratio} = \frac{\mathtextspacearound{\# of defined consistency relations}}{\mathtextspacearound{\# of total consistency relations}}
\end{align*}
The more consistency relations we are able to express, the higher it is an indicator for the completeness of the approach and the language. 
It does, however, especially indicate completeness of the \commonalities language, such that we derive by argumentation whether restrictions in expressiveness exist only because of the language or already because of restrictions of the \commonalities approach.
The language especially serves as a means to draw conclusions about completeness of the approach.

\mnote{Practicality evaluation}
For the \commonalities approach to provide the benefit of inherently guaranteeing compatibility, it must be possible to define a consistency relation tree by means of the additional \conceptmetamodels and their \commonalities.
In this first place, we aim to identify whether such a tree can be defined at all.
We do not aim to systematically find conditions under which this is possible or even how the \commonalities approach and the \commonalities language can systematically support this.
Knowing whether the specification of such a tree is achievable at all is a preliminary for these further investigations, which we refer to as future work.
It identifies practicality of the approach, as considered in \autoref{eq:commonalities:practicality}.
To this end, we measure in our case study how many of the defined relations are cross-tree relations, i.e., violate the definition of a consistency relation tree:
\begin{align*}
    &
    \mathvariable{cross\mbox{-}tree\ ratio} = \frac{\mathtextspacearound{\# of cross-tree consistency relations}}{\mathtextspacearound{\# of defined consistency relations}}
\end{align*}
In the best case, this ratio is $0$, such that the relations actually form a consistency relation tree.
Referring to \autoref{def:relationtree} for consistency relation trees, we consider the graph induced by the relations defined by the manifestation relations of a \commonalities specification between \metaclasses of the \concretemetamodels and \conceptmetamodels, in which they are called \commonalities.
We only consider the actually defined consistency relations, as we cannot make statements about the relations that we do not express by \commonalities in the case study.

\mnote{Correctness evaluation}
Regarding the \commonalities language, we are most interested in finding indicators for improving usability of the \commonalities approach by providing a concise way of specification.
First of all, this requires that language operates correctly, i.e., that is actually delivers transformations that preserve consistency according to the defined consistency relations, as defined in \autoref{eq:language:correctness}.
This actually evaluates two correctness notions. 
First, it identifies whether the language implementation is correct at a technical level.
Second, it identifies whether the concepts for operationalizing \commonalities into transformations defined with the \reactionslanguage, as proposed in \autoref{chap:language:commonalities:operationalization}, are correct.
We measure this by executing several change scenarios and identifying whether the results are consistent to the specified relations:
\begin{align*}
    &
    \mathvariable{preservation\ ratio} = \frac{\mathtextspacearound{\# of successfull scenarios}}{\mathtextspacearound{\# of total scenarios}}
\end{align*}
In the best case, this metric evaluates to $1$, such that in all scenarios consistency can successfully be preserved.
In failure cases, we manually investigate the cause, especially distinguishing between conceptual issues in the operationalization of the \commonalities language and technical faults in the compiler implementation.

\mnote{Benefit evaluation}
As an essential benefit of the \commonalities language, we motivated the reduction of specification effort (see \autoref{chap:language:commonalities:benefits}).
This is of particular importance, because developing a \commonalities specification for consistency between two metamodels by means of existing tools for metamodel and transformation definition requires the definition of three artifacts compared to a single artifacts when defining an ordinary transformation.
The \commonalities language aims to resolve this issue.
We consider the specification effort by means of conciseness, i.e., the size of a specification with \commonalities in comparison to a specification of ordinary transformations between the metamodels, as defined in \autoref{eq:language:benefit}.
Since the \commonalities language compiles to \reactions and a comparable implementation of the case study already exists for them (see \autoref{chap:correctness_evaluation:categorization:case_studies}), we compare the size of a \commonalities specification with the size of a specification in the \reactionslanguage in terms of the \gls{SLOC} and measure the following metric:
\begin{align*}
    &
    \mathvariable{code\ ratio} = \frac{\mathtextspacearound{\# of \acrshort{SLOC} with \commonalities}}{\mathtextspacearound{\# of \acrshort{SLOC} with \reactions}}
\end{align*}
The lower the value of this metric, the more concise a specification in the \commonalities language can be expected to be compared to a specification in the \reactionslanguage.
We expect this insight in conciseness to correlate with the required specification effort.


\section{Prototypical Implementation}

\mnote{\vitruv framework}
For the conduction of the case study presented in the subsequent section, we have used a prototypical implementation of the \commonalities language and the realization of the case study with that language in the \vitruv framework (see \autoref{chap:foundations:multiview:vitruv})~\owncite{klare2020Vitruv-JSS}.
We have also employed this framework for the implementation of the our case study for evaluating concerns and approaches regarding correctness in \autoref{chap:correctness_evaluation:categorization}.
In addition, the \reactionslanguage (see \autoref{chap:foundations:transformations:reactions}), to which the \commonalities language compiles, is part of the \vitruv framework.

\mnote{\commonalities language}
The implementation of the \commonalities language conforms to the considerations discussed in \autoref{chap:language}.
It implements an internal specification of concepts, i.e., it allows the specification of each \commonality in one file together with all its manifestations and relations to them, according to the elements we have introduced in \autoref{fig:language:elements}.
The syntax conforms to the examples we have given in \autoref{lst:language:component_example} and \autoref{lst:language:class_example}, but provides even more sophisticated specializations of the depicted language constructs.
We have also defined an extensible set of general as well as case-study-specific operators to define manifestation conditions, as well as attribute and reference relations.

\mnote{\commonalities operationalization}
The specifications in the \commonalities language are compiled to actual Ecore metamodels for the \conceptmetamodels and specifications in the \reactionslanguage, according to \autoref{chap:language:commonalities:operationalization}.
Specifications of \reactions, in turn, are compiled to ordinary Java code that implements a specific \gls{API} of the \vitruv framework.
The framework orchestrates the transformations with a simple strategy that enqueues all transformations defined for the model that is modified by the current transformations and executes them as long as no further changes are made.
Since we aim to define \commonalities that represent a consistency relation tree, transformations should be inherently compatible and are thus likely to terminate with such an orchestration strategy (cf.~\autoref{chap:correctness_evaluation:categorization:discussion:limitations}).
The implementation of the framework with the \commonalities language as well as the \reactionslanguage is available in a GitHub repository~\owncite{vitruvFrameworkGithub}.


\section{Case Study}

\mnote{Domains and relations}
We have performed a case study based on the metamodels \gls{PCM}, \gls{UML} and Java, as introduced in \autoref{chap:foundations:case_studies:domains}.
The specification of \commonalities is based on two sets consistency relations, one for \gls{PCM} and object-oriented design, applying to both Java and \gls{UML}, and for \gls{UML} and Java, which we have both already introduced in \autoref{chap:foundations:case_studies:relations}.
In addition, we have used the consistency relations to implement a case study of transformations with the \reactionslanguage in \autoref{chap:correctness_evaluation} for evaluating our contributions regarding correctness of transformation networks.
Since the \commonalities language compiles to \reactions, this allows us to compare the two realizations.

\mnote{Relization with \commonalities}
The two sets of consistency relations are motivated by the two concepts of object-oriented design and component-based design, between which have already distinguished in the explanation of the \commonalities approach in \autoref{chap:improvement} and for which we have especially considered a hierarchic representation in \autoref{chap:improvement:commonalities:composition}.
We have thus implemented the case study with two according \conceptmetamodels, of which the one for object-oriented design defines \commonalities between \gls{UML} and Java, and the one for component-based design defines \commonalities between the object-oriented design \conceptmetamodel and \gls{PCM}.
The case study has been implemented with the \commonalities language in the master's thesis of \textcite{hennig2020ma}.
We summarize the case study of that thesis in the following.
Details on the implemented consistency relations and \commonalities can also be found there~\owncite[Sec. 3, A.2]{hennig2020ma}.

\begin{table}
	\small
	\centering
	\rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{l S[table-format=2] S[table-format=2] S[table-format=1] S[table-format=2, table-column-width=2.5em] r}
		\toprule
		\multirow{2}{*}{\bfseries Element Type} & {\multirow{2}{*}{\bfseries Total}} & \multicolumn{4}{c}{\bfseries Covered} \\
		\cmidrule(lr){3-6}
		& & \multicolumn{1}{c}{Direct} & \multicolumn{1}{c}{Implicit} & \multicolumn{2}{c}{Overall} \\
		\midrule
		\Metaclasses 				& 13	& 7		& 3	& 10	& \SI{77}{\percent}	\\
		Attributes 					& 27	& 19	& 1	& 20	& \SI{74}{\percent}	\\
		Containment References 		& 13	& 9		& 0	& 9		& \SI{69}{\percent}	\\
		Non-containment References 	& 4		& 2		& 2	& 4		& \SI{100}{\percent}	\\
		Enumerations				& 2		& 0		& 2	& 2		& \SI{100}{\percent}	\\
		\midrule
		Total 						& 59	& 37	& 8	& 45	& \SI{76}{\percent}	\\
		\bottomrule
	\end{tabular}
	\caption[Number of case study elements of \acrshort{UML}]{Numbers of elements from the \gls{UML} metamodel used in the case study. Adapted from~\owncite[Table 10.4]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:coverage_uml}
\end{table}

\begin{table}
	\small
	\centering
	\rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{l S[table-format=2] S[table-format=2] S[table-format=2] S[table-format=2, table-column-width=2.5em] r}
		\toprule
		\multirow{2}{*}{\bfseries Element Type} & {\multirow{2}{*}{\bfseries Total}} & \multicolumn{4}{c}{\bfseries Covered} \\
		\cmidrule(lr){3-6}
		& & \multicolumn{1}{c}{Direct} & \multicolumn{1}{c}{Implicit} & \multicolumn{2}{c}{Overall} \\
		\midrule
		\Metaclasses 				& 30	& 9		& 11	& 20	& \SI{67}{\percent}	\\
		Attributes 					& 13	& 11	& 0		& 11	& \SI{85}{\percent}	\\
		Containment References 		& 32	& 19	& 1		& 20	& \SI{63}{\percent}	\\
		Non-containment References 	& 1		& 0		& 0		& 0		& \SI{0}{\percent}	\\
		Enumerations				& 0		& 0		& 0		& 0		& \SI{100}{\percent}	\\
		\midrule
		Total 						& 76	& 39	& 12	& 51	& \SI{67}{\percent}	\\
		\bottomrule
	\end{tabular}
	\caption[Number of case study elements of Java]{Numbers of elements from the Java metamodel used in the case study. Adapted from~\owncite[Table 10.5]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:coverage_java}
\end{table}

\begin{table}
	\small
	\centering
	\rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{l S[table-format=2] S[table-format=2] S[table-format=1] S[table-format=2, table-column-width=2.5em] r}
		\toprule
		\multirow{2}{*}{\bfseries Element Type} & {\multirow{2}{*}{\bfseries Total}} & \multicolumn{4}{c}{\bfseries Covered} \\
		\cmidrule(lr){3-6}
		& & \multicolumn{1}{c}{Direct} & \multicolumn{1}{c}{Implicit} & \multicolumn{2}{c}{Overall} \\
		\midrule
		\Metaclasses 				& 16 & 7  & 2 		& 9 & \SI{56}{\percent}  \\
		Attributes 					& 15 & 7  & 1 		& 8 & \SI{53}{\percent} \\
		Containment References 		& 18 & 6  & 0 		& 6 & \SI{33}{\percent}  \\
		Non-containment References 	& 8  & 3  & 1  		& 4 & \SI{50}{\percent}  \\
		Enumerations 				& 1  & 0  & 1  		& 1 & \SI{100}{\percent}  \\
		\midrule
		Total 						& 58  & 23  & 5  	& 28 & \SI{48}{\percent}  \\
		\bottomrule
	\end{tabular}
	\caption[Number of case study elements of \acrshort{PCM}]{Numbers of elements from the \gls{PCM} metamodel used in the case study. Adapted from~\owncite[Table 10.3]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:coverage_pcm}
\end{table}

\mnote{Size of realized relations}
We have realized a subset of the consistency relations that we have introduced in \autoref{chap:foundations:case_studies:relations} and that we have realized with the \reactionslanguage in the case study presented in \autoref{chap:correctness_evaluation}.
\autoref{tab:commonalities_evaluation:coverage_uml}, \autoref{tab:commonalities_evaluation:coverage_java} and \autoref{tab:commonalities_evaluation:coverage_pcm} give an impression of the size of the implemented case study.
They depict the numbers of elements by type for the three metamodels that are relevant for the originally defined consistency relations, denoted as \emph{total} and the number of those that were realized in the case study, denoted as \emph{covered}.
We distinguish between elements that are \emph{directly} and \emph{implicitly} covered, according to whether they were actually defined as manifestation classes or features of them and passed to the operators ensuring consistency explicitly, or whether they were only accessed within the operators.
The number reflect the case study size by the absolute number of considered elements and the coverage of the originally presented complete consistency relations by the relative numbers.

\mnote{Implicitly covered elements}
Such implicitly covered elements concern, for example, primitive data types or enum literals, which have to be instantiated on demand but which are not explicitly represented within the \commonalities.
Implicit elements also cover structures of elements that are only represented by one element in the other metamodels.
For example, \gls{UML} represents the realization of an interface by a class through an indirect reference of a dedicated generalization element, i.e., the class references a generalization, which, in turn, references the implemented interface, whereas the \commonality and the Java representation have a direct reference to the implemented interface.
In that case, the generalization element is not explicitly referenced in the \commonality specification but only implicitly used within the operators for the implementation relation.
In Java, many \metaclasses are only implicitly covered, because primitive types, type references and modifiers are all represented as \metaclasses, but they are explicitly related to elements of other metamodels via \commonalities but only implicitly in terms of operators for attributes that represent references or modifiers.

\mnote{Coverage of complete consistency relations}
The case study sums up to a specification of $15$ \commonalities, of which $8$ belong to the object-oriented design \conceptmetamodel and $7$ belong to the component-based design \conceptmetamodel.
These \commonalities put $124$ elements of the \concretemetamodels into relation, which represent around \SI{64}{\percent} of the total $193$ elements that are relevant for the complete set of introduced consistency relations.
While the case study implementation covers most elements of \gls{UML} (\SI{76}{\percent}) and Java (\SI{67}{\percent}), it only covers \SI{48}{\percent} of the \gls{PCM} elements.
Most of the missing consistency relations are due to intended restrictions of the case study size or restrictions in expressiveness of the \commonalities language.
We further discuss the reasons in the subsequent results presentation.

\mnote{Reused test cases}
The implementations of all \commonalities are available in a corresponding GitHub repository of the \vitruv project~\cite{vitruvCBSEGithub}.
It also contains test cases, which we have reused from those that we have defined for the case study concerning the same consistency relations with the \reactionslanguage, presented in \autoref{chap:correctness_evaluation:categorization:case_studies}.
Since we only want to evaluate whether results are correct in regarding those consistency relations for which we have defined consistency preservation with \commonalities, we have reduced the tests to those for the according consistency relations in comparison to the tests summarized in \autoref{tab:correctness_evaluation:errors:test_cases}.
We have, however, also added further test cases such that in total more test cases for the case study implementation with the \commonalities language exist than for the implementation with the \reactionslanguage.
All these test cases perform changes that lead to the violation of a specific type of consistency relation and require the transformations to change the other models for restoring consistency, which are then validated by the test case.

\begin{table}
	\small
	\centering
	\rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{L{10em} S[table-format=3, table-column-width=6em] S[table-format=3, table-column-width=5em] r}
		\toprule
		\multicolumn{1}{l}{\bfseries Consistency Relation} & \multicolumn{1}{l}{\bfseries Test Cases} & \multicolumn{2}{c}{\bfseries Successful Test Cases} \\
		\midrule
		Package 			& 6		& 6		& \SI{100}{\percent} \\
		Class 				& 26	& 26	& \SI{100}{\percent} \\
		Class Method 		& 40	& 40	& \SI{100}{\percent} \\
		% 1 scenario disabled: multi constructor
		Constructor 		& 24	& 22	& \SI{92}{\percent} \\
		Field + Association	& 20	& 20	& \SI{100}{\percent} \\
		Interface 			& 10	& 10	& \SI{100}{\percent} \\
		Interface Method 	& 28	& 28	& \SI{100}{\percent} \\
		\midrule
		Total 				& 154	& 152	& \SI{99}{\percent} \\
		\bottomrule
	\end{tabular}
	\caption[Test case results for object-oriented design]{Test cases and their success rates for consistency relations in object-oriented design. Adapted from~\owncite[Table 10.2]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:tests_oo}
\end{table}

\begin{table}
	\small
	\centering
	\rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{L{10em} S[table-format=3, table-column-width=6em] S[table-format=3, table-column-width=5em] r}
		\toprule
		\multicolumn{1}{l}{\bfseries Consistency Relation} & \multicolumn{1}{c}{\bfseries Test Cases} & \multicolumn{2}{c}{\bfseries Successful Test Cases} \\
		\midrule
		Repository 				& 6		& 6		& \SI{100}{\percent} \\
		Interface		 		& 6		& 6		& \SI{100}{\percent} \\
		Signature + Parameter	& 48	& 48	& \SI{100}{\percent} \\
		Composite Data Type		& 48	& 48	& \SI{100}{\percent} \\
		Repository Component	& 6		& 6		& \SI{100}{\percent} \\
		% PCM/UML -> Java
		Provided Role 			& 12	& 8		& \SI{67}{\percent} \\
		\midrule
		\rowcolor{\firstlinecolor}
		Total 					& 126	& 122	& \SI{97}{\percent} \\
		\bottomrule
	\end{tabular}
	\caption[Test case results for component-based design]{Test cases and their success rates for consistency relations in component-based design. Adapted from~\owncite[Table 10.1]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:tests_cbs}
\end{table}

\mnote{Summary of test cases}
\autoref{tab:commonalities_evaluation:tests_oo} and \autoref{tab:commonalities_evaluation:tests_cbs} summarize the test cases together with their results applied to the case study implementation with the \commonalities language, which we discuss in the subsequent section.
The test cases are split into one set only concerning consistency relations for object-oriented design, i.e., those keeping only \gls{UML} and Java models consistent, and another set for component-based design, in which also \gls{PCM} models are kept consistent.
For every change scenario, such as the addition or modification of a specific type of element involved in a consistency relation, we consider one test case per change direction per model pair.
For object-oriented design this results in two test cases for each scenario, since each change can be performed in \gls{UML} and checked in Java and vice versa.
In component-based design, each change can be performed in any of the three models and propagated to any of the two other models, resulting in three test cases for each scenario.
In consequence, test case numbers are a multiple of $2$ for object-oriented design and a multiple of $6$ in component-based design.

\mnote{Detailed test cases and complex scenario}
In total, we have executed $284$ test cases.
They include $154$ test cases for keeping \gls{UML} and Java consistent with the object-oriented design \commonalities and $126$ test cases for keeping \gls{PCM}, \gls{UML} and Java consistent with \commonalities for object-oriented design and component-based design.
While these test cases use minimalist models that are sufficient for representing the consistency relation under test, we have also used the Media Store system model~\cite{strittmatter2016a}, which is a comprehensive case study system for the \gls{PCM} and which we have already used in the evaluation of our approaches for constructing correct transformation networks in \autoref{chap:correctness_evaluation}.
For this \gls{PCM} model, we simulate its construction by producing a change sequence that yields the models, which conforms to the \emph{Reconstructive Integration Strategy (RIS)} proposed by \citeauthor{langhammer2017a}~\cite{langhammer2017a,klare2020Vitruv-JSS}.
We have defined four additional test cases using this construction simulation, which validate that a \gls{UML} model is created and that it is consistent to different of the defined consistency relations, including components, interfaces, operation signatures and data types.

% * 15 Commonalities, 8 in OO, 7 in CBS

% Total elements relevant for case studies (as depicted in \autoref{chap:correctness_evaluation:compatibility:case_study}), directly covered elements (those as manifestations / participations in \commonalities) and indirectly covered elements (referenced within operators but not as participations, because they are only relevant when transferring information of other elements but not on their own).
% Those internal elements are primitive data types, enums etc., but also UML interface realizations due to indirect reference of generalization which cannot be mapped yet, same as for provided role in PCM

% Many Java elements internally covered, because primitive types, type references and modifiers are represented as metaclasses, which are not mapped on their own but only in context of an operator

% FROM LUKAS: 
% Of the total \textbf{193} identified element types, our commonalities cover \textbf{124} (\textbf{64.25\%}) elements in total, \textbf{99} of which are covered directly and \textbf{25} are covered internally by operators. The largest portion of elements that are not covered is associated with PCM (\textbf{52\%}). We mostly covered all UML and Java elements that we considered in our cases study (\textbf{98\%} and \textbf{96\%} respectively), but of the total identified elements we only cover \textbf{76\%} and \textbf{67\%}.

% MEDIA STORE

% * From PCM to UML
% * Only elements already supported (components, interfaces, data types, signatures with parameters)
% * Missing: provided and required roles


\section{Results and Interpretation}

\mnote{Coverage of complete case study}
We use the implemented case study and the conducted tests to answer the evaluation questions summarized in \autoref{tab:commonalities_evaluation:gqm}, or to at least find indicators for how their general answer is expected to be based on the data collected from the case study.
The questions are split into those especially concerning the \commonalities approach itself and those only concerning the \commonalities language.

\subsection*{\Commonalities Approach}

We have explained that we did not implement all consistency relations with the \commonalities language that we have realized with the \reactionslanguage in the evaluation for transformation network correctness in \autoref{chap:correctness_evaluation:categorization}, but only a sufficiently complex subset.
We selected consistency relations forming a coherent set that can be realized with reasonable effort, and such that we do not expect further insights regarding applicability, practicality and usability of the \commonalities approach and language.
To avoid a bias by defining an arbitrary subset of the consistency relations, which, by accident, can completely or almost completely realized with the \commonalities language, we consider the ratio of consistency relations realized with the \commonalities language in comparison to the complete consistency relations depicted in \autoref{chap:foundations:case_studies:relations}.
It results in the following metric values, derived from the values in \autoref{tab:commonalities_evaluation:coverage_uml}, \autoref{tab:commonalities_evaluation:coverage_java} and \autoref{tab:commonalities_evaluation:coverage_pcm}:
\begin{alignat*}{3}
    &
	\mathvariable{definition\ ratio}_{\mathvariable{sums}} &&= \SI{64}{\percent} \quad  &&\bigl(= \tfrac{45 + 51 + 28}{59 + 76 + 58}\bigr)\\
	& 
	\mathvariable{definition\ ratio}_{\mathvariable{average}} &&= \SI{64}{\percent} \quad &&\bigl(= \tfrac{\SI{76}{\percent} + \SI{67}{\percent} + \SI{48}{\percent}}{3} \bigr) \\
	&
	\mathvariable{definition\ ratio}_{\mathvariable{UML-Java}} &&= \SI{71}{\percent}
\end{alignat*}
We counted the elements of the metamodels affects by the consistency relations.
To avoid a bias by having different numbers of elements in the different metamodels, we have calculated the ratio both based on the sums of the elements across all metamodels ($\mathvariable{definition\ ratio}_{\mathvariable{sums}}$), as well as the equally weighted average of the coverage of all metamodels ($\mathvariable{definition\ ratio}_{\mathvariable{average}}$).
They do, however, both sum up to the same value of \SI{64}{\percent}.
Since \gls{UML} and Java represent those metamodels that are kept consistent by a single \conceptmetamodel for object-oriented design and can thus be considered a minimal application of the \commonalities approach for only two metamodels, we explicitly  calculated the ratio only for these two metamodels as well.
Since both ways of calculated introduced above yield the same value, we have only depicted the single result of \SI{71}{\percent}.

\mnote{Non-realizable relations}
The coverage ratios especially give an impression of how comprehensive the realized consistency relations are.
To evaluate completeness of the \commonalities approach and the language, it is of particular importance to identify how many of the consistency relations that we intended to implemented could not be realized.
In summary, we found that most consistency relations that we aimed to realize could actually be achieved, except for multi-valued types in \gls{PCM} and Java, which is due to current limitations of the language.
Multi-valued types are fields and parameters of a type with an upper bound in its multiplicity higher than one.
This can be expressed with explicit multiplicities in \gls{UML} and with collection data types in \gls{PCM}, whereas they have to be rolled out as explicit implementations of collections in Java.
The current implementation of the \commonalities language lacks an operator for that situation, which is, however, no conceptual limitation but can be added with some additional effort.
In addition, provided and required roles in \gls{PCM} as well as generalizations in \gls{UML} are currently not fully supported and in parts only covered implicitly, because the current implementation of the \commonalities language only supports explicit relations to containment references, but roles and generalizations contain ordinary references to the provided, required or implemented interfaces, which can up to now only be accessed implicitly within operators of the \commonalities language.
This is a technical limitation, which the current case study implementation avoids by implementing complex operators to support these situations, which is why the according test cases are actually successful, but the language lacks sufficient support for such relations.

\mnote{Omitted relations}
The remaining consistency relations were omitted on purpose, and are summarized in more detail in the master's thesis of \textcite[Sec. 3]{hennig2020ma}.
They comprise composite components in \gls{PCM}, which are comparable to basic components and only need to be distinguished by an according naming schema or the containment of assemblies of other components, of which at least the latter requires some effort to implement, but is not expected to be a conceptual issue.
In addition, systems and subsystems in \gls{PCM} are not considered, because they are almost equal to composite components with slightly different semantics.

\mnote{Approach and language completeness}
In summary, the case study results indicate that in answer to \autoref{eq:commonalities:completeness} the \commonalities approach itself is complete, as we have already expected because of the theoretical considerations by \textcite{stevens2020BidirectionalTransformationLarge-SoSym}.
The \commonalities language, however, currently has some limitations that prevent the realization of some consistency relation or at least made it more difficult than it should be.
We found these to be only technical limitations that can be solved by extending the language, such that they do not hide actual limitations of the underlying \commonalities approach.
The results emphasize the status of the \commonalities language implementation as a prototype, but still indicate possible completeness of such a language according to the concepts for such a language proposed in \autoref{chap:language}.

% NOT COVERED:
% For details on elements omitted from the case study, see \cite[Sec. 3]{hennig2020ma}
% Java: no multi-valued types (collections of elements in fields and parameters)
% PCM:
% * Composite Components: Same as basic ones, need to be distinguished (e.g. by naming schema, user interaction or containment of other components), but then are comparable to basic ones, so no further insights
% * Provided/Require Role, Generalization internally use non-containment references (discussed above)
% * System: no covered intentionally, is basically only a composite component
% * CollectionDataType: complicated to map between multiplicities in Java and Collection data types in Java and PCM. Other data types are already mapped. Since each type can only be related to one kind of data type, there are not further problems to be expected regarding a tree structure. It is basically doing and potentially limitations of existing operators of the language, but no conceptual problems.

\mnote{Practicality of \commonalities}
The central question to evaluate for the \commonalities approach concerns its practicality in terms of achieving a consistency relation tree with a \commonalities specification to benefits from the discussed guarantees in quality improvement.
We have discussed in \autoref{chap:improvement:commonalities:tree} that the defined consistency relations have to form a consistency relation tree and in \autoref{chap:language:commonalities:features} we found the graph induced by the operands of the operators putting \commonalities and their manifestations into relations is the one to consider for identifying a consistency relation tree.
Since in several \commonalities of our case study, elements have to be considered implicitly within the operators and not all of them are explicitly defined as operands, these elements have to be considered as well.
For that reason, we conducted the investigation of the defined relations to identify the graph as a consistency relation tree manually.
In this manual analysis, we found that none of the define relations leads to the violation of the definition of a consistency relation tree according to \autoref{def:relationtree}:
\begin{align*}
    &
    \mathvariable{cross\mbox{-}tree\ ratio} = 0
\end{align*}
Although restricted to a single case study, this at least serves as a first indicator for the practicality of the approach as asked in \autoref{eq:commonalities:practicality}, i.e., that it actually supports or at least enabled the specification of a consistency relation tree.
To mitigate the risk of mistakes performed in the manual analysis of consistency relations, the test results also serve as a further indicator that the relations form a tree.
Violations of such a tree structure can easily lead to incompatibilities, as discussed in \autoref{chap:compatibility}, which can then lead to non-termination, as discussed in \autoref{chap:errors}, especially with the simple orchestration strategy that we employed for the case study.
We have, however, not observed any non-termination in the test case.
The failing tests were due to other reasons, which we discuss in the following.
Although even without a tree structure the consistency relation can be compatible or even if they are incompatible it may not lead to failures during transformation execution, it still serves as an indicator for the consistency relations form a tree.
Even if this is not the case, the evaluation at least shows that the transformations behave correctly, thus no matter whether this actually achieved by defining a consistency relation tree or any other reason that makes the operationalization of \commonalities specifications likely to be correct, at the end it is only important that correctness is achieved.

% Regarding tree: Violations would easily lead to incompatibility and thus potentially non-termination with the selected simply orchestration strategy, which is not guaranteed to terminate. We have, however, not observed any non-termination -> potentially no incompatibilities -> potentially tree (but not necessarily!)


\subsection*{\Commonalities Language}

\mnote{Correctness of \commonalities language}
As a preliminary for any further insights on the \commonalities language, we first have to validate its correctness.
This covers the correct implementation of the language and its compilers, as well as correctness of concepts how to compile \commonalities into \reactions.
While the former can be seen as simple bug testing, the latter gives us insights in whether the operationalization concept is correct, which especially means that the language can be seen as an derivation of the \mappings language, from which we have reused most of the operationalization concepts (see \autoref{chap:language:commonalities:operationalization}).
To validate correctness, we consider the results of the test cases for those consistency relations of the case study that we have implemented with the \commonalities language.
According to \autoref{tab:commonalities_evaluation:tests_oo} and \autoref{tab:commonalities_evaluation:tests_cbs}, more than \SI{97}{\percent} of the test cases are successful:
\begin{align*}
    &
    \mathvariable{preservation\ ratio} \ge \SI{97}{\percent}
\end{align*}
In addition, the four test cases for the Media Store case study system also produce the expected results.
Regarding \autoref{eq:language:correctness}, this is a high indicator for correctness of the operationalization concept of the \commonalities language as well as its implementation, especially because the failures of the remaining test cases are caused by the used \vitruv framework and by incompleteness of the \commonalities language.

\mnote{Reasons for failing test cases}
In total, six test cases fail.
This concerns two tests cases for constructors in object-oriented design, which both implement the same scenario but once from Java to \gls{UML} and once vice versa.
In this test scenario, multiple constructors with different parameter lists are created.
The \vitruv framework first executed transformations for the insertion of both constructors and afterwards for the addition of parameters.
This leads to two undistinguishable constructors with empty parameter lists when first execution the transformation, such that when adding the parameters the two constructors cannot be distinguished anymore.
Processing the constructor additions one after another in the framework would solve the problem.
Anyway, the same problem would occur when using the \reactionslanguage.
Regarding provided roles in component-based design, four test cases fail because of the references to provided interfaces only being implicitly covered in operators.
We have already discussed before that the \commonalities language currently only supports relations for containment references, such that other references have to be processed with operators.
Provided roles are contained in components, which in turn reference the provided interface.
When a provided role is added to a component, this is processed by a relation in the component \commonality.
The operator for that relation also implicitly considers the reference to the interface within the role, but this may not yet be set.
When the interface of the role is set or changed later, this change is not propagated as no relation for it is defined in a \commonality, such that the according test cases fail.
In consequence, this is a result of technical incompleteness of the \commonalities language as discussed before, but not a matter of incorrectness of its operationalization.

% Depending on how we measure: Average of both categories, summ of all tests among both categories, but always higher than 97 percent, so does not matter. Interesting why the remining tests did not work.

% 4 media store tests: all work properly (packages, classes and interfaces, composite data types, operation signatures)
% ADD MEDIA STORE IN CASE STUDY DESCRIPTION

% Problem Provided Role: PCM -> Java and UML -> Java: created role initially empty and no reaction to changes of provided interface (internal handling) -> no reaction to contents of role, so interface not added in Java model.

% Provided role failures: Faulty definition of operator - provided interface of a role is only used in operator but not defined as parameter/participation, such that no reaction for its change is created
% Limited expressiveness: Language cannot express mapping between non-containment reference (in Java) to containment reference with object (role) + non-containment reference (interface) (in PCM).

% OO Constructor: Problem in \vitruv framework -- after two constructor creations, first both constructors are propagated before propagating the insertion of parameters. This results in two indistinguishable constructors (with empty parameter lists) in Java, which results in problems of the subsequent parameter propagation for one of them.
% Adding one constructor after another (either in the test, i.e., by the user, or as propagation of the framework) would solve the problem.

\begin{table}
	\small
	\centering
	%\rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{L{6em} C{9em} S[table-format=4, table-column-width=7em] S[table-format=5, table-column-width=3em] r}
		\toprule
		\multicolumn{1}{l}{\bfseries } & \multicolumn{1}{c}{\bfseries \reactions \textit{(omitted)}} & \multicolumn{1}{c}{\bfseries \commonalities} & \multicolumn{2}{c}{\bfseries Difference}\\
		\midrule
		Specifications 			& 2390 \textit{(302)}	& 514	& -1876 	& -\SI{78}{\percent}\\
		Utilities				& 2250 \textit{(445)}	& 2523	& 273 		& \SI{11}{\percent}\\
		\midrule
		\rowcolor{\firstlinecolor}
		Total					& 4640 \textit{(747)}	& 3037	& -1603 	& -\SI{53}{\percent}\\
		\bottomrule
	\end{tabular}
	\caption[Lines of code for a \commonalities and \reactions specification]{\acrshort{SLOC} in the \commonalities and \reactions specification for the consistency relations between \gls{UML} and Java. For \reactions, the numbers only cover the lines for consistency relations covered by the \commonalities specification, whereas those in parenthesis denote the lines for relations not covered by the \commonalities specification. Adapted from~\owncite[Table 10.9]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:reactions_comparison}
\end{table}

\mnote{Benefit of \commonalities language}
The \commonalities language is supposed to support the construction of a transformation network according to the \commonalities approach.
In comparison to applying the construction approach with ordinary modelling and transformation tools, it is supposed to reduce the specification effort, especially in the simple or initial case in which consistency between only two metamodels shall be specified.
The case study implementation contains a specification for two metamodels in terms of the object-oriented design \commonalities between \gls{UML} and Java.
We had already defined their consistency with a direct transformation by means of the \reactionslanguage in previous case studies for the \vitruv framework~\owncite{klare2020Vitruv-JSS}, which we have also employed for the evaluation in \autoref{chap:correctness_evaluation:categorization}.
\autoref{tab:commonalities_evaluation:reactions_comparison} compares the realization of consistency relations between \gls{UML} and Java by means of the \reactionslanguage and the \commonalities language in terms of \glspl{SLOC}.
Since there is no unique measure for \glspl{SLOC} for these languages, we have decided to format the code such that each statement for every grammar rule starts in a new line, according to the formatting used for \reactions~\owncite{klare2020Vitruv-JSS}.
Since not the complete specification is defined within the language artifacts itself but also within utilities written in Java or Java-like code, we also counted the \glspl{SLOC} in that code.
Since the \reactionslanguage allows to define arbitrary code within the \reactions, only few utility code is necessary, whereas the \commonalities language requires utility code already for all use case-specific operators.
Considering all codes together leads to a reduction in \glspl{SLOC} between \reactions and \commonalities of more than \SI{50}{\percent}:
\begin{align*}
    &
    \mathvariable{code\ ratio} = \SI{47}{\percent}
\end{align*}
Drawing conclusions of this metrics to the actual specification effort suffers from several biases.
First, the counted \glspl{SLOC} can only be considered an approximation, as, for example, the utilities are shared with other projects and thus they are not tailored to consistency between \gls{UML} and Java.
Second, whether conciseness in terms of \glspl{SLOC} actually leads to less specification effort is not evaluated but only assumed as an hypothesis.
In response to \autoref{eq:language:benefit}, the case study provides an indicator for achieving conciseness in comparison to the \reactionslanguage.
It is, however, not even necessary to actually improve conciseness, but to avoid an increase in specification effort, conciseness should at least not decrease.
Whether or not the actual value of around \SI{50}{\percent} in code size reduction is accurate and representative, it at least shows that we may not expect a drastic increase in code size, which improves the specification effort.



\section{Discussion and Validity}

Tree only considered for defined relations: potentially further relations would have violated tree structure. However, if relations cannot be defined by the approach at all, which would violate the tree structure, that would at least prevent the definition of tree violations.
Same for correctness: only considered for the relations that we were able to express (completeness)

Tree is what we want to achieve, but it is not necessary. Violations of the tree structure only introduce potential incompatibility and potential cycles of propagation, requiring synchronization. This must, however, not be problematic, first, because a cycle in the relations tree must not necessarily lead to a cycle between the elements in an instance, as the transformation may always select other elements that do not lead to a cycle, and second, because even if there is a cycle, it can be implemented properly (compatible and with synchronization, see chapter), such that it properly works as an ordinary transformation network built according to what we discussed in \autoref{part:correctness}.

Benefit: reactions are imperative, more declarative languages exist -> no fair comparison. But reactions already compared to ordinary code (refer to paper) and show reduction there, so they are verbose but not arbitrarily verbose
Only one case study: high bias
Correlation between conciseness and specification effort unclear

Many operator logic in utility code -> maybe this is the hard-to-develop part, so may not be beneficial to have less commonalities code if more complex logic is needed in operators/Utilities
However: Even no reduction or only slight increase would be fine, because we Commonalities give more guarantees (correctness, reusability) than ordinary networks with reactions. So the goal was only to mitigate the effort increase through the language, not to even reduce it.

Hard to develop case studies, even harder to find other implementations of case studies for transformation networks to compare with.
Already discussed for transformation network study, so we even profit from having the transformation network implementation used for our other evaluations.

Tree: Manually performed, thus easy to oversee something, make mistakes. But: Also runtime analysis


\section{Limitations and Future Work}
Limited to descriptive specification

Language does not provide inheritance for commonalities, repeated definition of names, repeated definition of shared information, e.g., between basic and composite components etc.

Limited set of operators, e.g., no generic operator for mapping attributes to references (e.g. visibility is EnumLiteral in UML, whereas it is a reference to a type instance in Java), complex pattern mappings, e.g., type reference in UML is direct reference, whereas in Java a reference contains a reference object, which then references a further object that references the type; or primitive types in Java represented as types and in UML as predefined instances of a generic primitive type type.

Movement of objects treated as removal and insertion leading to deletion of contained elements and values


Granularity of operators: open research question how to define a reusable set with appropriate degree of abstraction, such that only for few cases custom operators need to be defined. Especially necessary to define a metrics for that (what are "few cases"?). Currently left open in language design (see diagram with arbitrary operators) and implemented specific for case-study (as focus on structure of language, not on realization of manifestation relations).

Tree: Developer has to ensure that a tree is achieved. Can be improved by the language. Integrate compatibility approach from \autoref{chap:compatibility} into the language. Due to rather declarative specification, graph of consistency relations can be derived and analyzed. Assumptions have to be made on operators, which can do arbitrary stuff, e.g. that only the elements explicitly given to the operator are used, and no further navigation through the model is done within the operator. With that assumption, we can construct the graph from the commonalities specifications and operator arguments and apply the analysis.
Who is responsible for the tree structure? How does the language support its achievement?

\section{Summary}



% \begin{copiedFrom}{VoSE}

% \section*{Proof-of-Concept}

% We have proposed the \commonalities approach and a realizing language.
% We have explained that we expect them to improve understandability of transformations and to reduce problems of transformation networks, such as compatibility and modularity.
% Although we gave arguments that justify this expectation, it has to be evaluated empirically to increase evidence.
% However, before evaluating the benefits of our approach, we first have to investigate its feasibility.
% For that reason, we built an initial prototype of the language and applied it to a simple evaluation case as a proof-of-concept.
% %to show the feasibility of the concept.
% %This forms our contribution~\ref{contrib:proofofconcept}.

% % Evaluation Goal: Show feasibility of the idea

% % Evaluation Methodology: Build a proof-of-concept prototype of a language and apply it to a simple case

% \subsection*{Case Study}

% We have implemented a prototype of the \commonalities language, which allows to define \commonalities with simple attribute and reference mappings and to compose \commonalities.
% The syntax is an extension of the examples shown in \autoref{lst:language:class_example} and \autoref{lst:language:component_example}.
% The language comprises a compiler that derives a \conceptmetamodel, as well as a set of transformations from a specification in the language.
% The generated transformations are in turn defined in the \reactionslanguage~\cite{klare2016b}, which is a delta-based transformation language that is, just like the \commonalities language itself, part of the \vitruv approach~\cite{kramer2013b}.
% \vitruv is a view-based development approach that uses transformations to keep models consistent.
% The implementation of the \commonalities language can be found in the GitHub repository of the \vitruv project \cite{vitruvFrameworkGithub}. %\footnote{\label{githubfootnote}\url{https://github.com/vitruv-tools/Vitruv}}.

% We have applied the implementation to a simple case study that consists of four metamodels, each containing one \metaclass that represents a root element and one that represents a contained element. 
% Both elements have an identifier and a name in all metamodels, and an additional single-valued and multi-valued feature of integers in two of the metamodels.
% The root \metaclass additionally has a containment reference to the contained \metaclass.
% We have defined two \commonalities, one for the root element and one for the contained element, which redundantly represent the same concepts in all the metamodels.
% The root \commonality references the contained \commonality.
% This results in one \conceptmetamodel with four manifestations.

% To validate that the specifications in the \commonalities language are correctly defined and operationalized, we have
% %defined 8 test cases that 
% defined test cases that perform 21 different model modifications, which 
% %
% create and delete all possible types of elements and modify all attribute and reference values in instances of every metamodel.
% They cover the set of all possible modifications that can be performed on instances of those metamodels.
% This also includes change propagation across composed \commonalities.
% The tests successfully validate that the modifications are correctly propagated to all other models in all cases.
% The test cases and the used example metamodels are also available in the GitHub repository of the \vitruv project \cite{vitruvFrameworkGithub}. %\footnotemark[1].

% % \begin{itemize}
% %     \item First reference to concrete implementation here
% %     \item Refer to simple example implementation showing the ability to define and run the Commonalities approach
% % \end{itemize}

% \subsection*{Discussion}
% % Formerly: Threats to Validity

% %Maybe we can omit this section, but we need to discuss that it is really, really only a proof-of-concept (some reviewers do not understand the difference to a complete benefit, scalability and effectiveness evaluation if you do not tell them again and again).

% Our proof-of-concept validates the feasibility of the proposed \commonalities approach: 
% It demonstrates that it is possible to apply the concept of defining consistency relations between multiple metamodels  through a central metamodel in a simple scenario. It also shows that an operationalization can be derived that preserves consistency of all instances of such metamodels.
% %Our evaluation only serves as a proof-of-concept to validate feasibility of the approach that we present in this paper.
% %In consequence, 
% The results only give an indicator that the \commonalities concept can be applied and that a language with an internal concept definition can be designed.
% To further evaluate the capabilities of such an approach, the language would have to be extended to be able to define more complex relationships.
% Additionally, the approach has to be applied to larger parts of more complex metamodels and metamodels for different contexts to improve external validity of the results.
% This could also reveal whether the assumption of having a tree of \commonalities is practical in realistic scenarios.

% Since evaluating functional capabilities of the approach is only an---essential---first step, the evaluation of further properties such as applicability, appropriateness, effectiveness and scalability are part of ongoing work with further case studies.
% As a central benefit of our approach, we claim to improve understandability of relations between metamodels, but can only give arguments for that by now.
% An evaluation of that claim would require a user experiment that compares our approach to specifications of direct transformations between multiple metamodels.

% Finally, one might argue that defining \conceptmetamodels leads to additional effort, as for two metamodels it is necessary to define one additional metamodel and two transformations rather than only a single transformation.
% First, this is only true as long as only two metamodels are related by one \conceptmetamodel. 
% If three metamodels shall be related, there would be a network of three transformations, which are not necessarily compatible without using the \commonalities approach, and one metamodel with three transformations using the \commonalities approach.
% When the \commonalities approach is applied, the number of necessary transformations increases linearly with the number of metamodels that are related, whereas it increases quadratic without them.
% Second, the effort for defining transformations can be reduced by using an appropriate language to define \conceptmetamodels and transformations, as we have proposed in \autoref{chap:language}. Our language only requires developers to write one specification that contains both the \conceptmetamodel and all transformations to its manifestations.

% % \subsection{Limitations}
% % Contradictory Commonalities specifications?

% \end{copiedFrom} % VoSE


