\chapter{Evaluation and Discussion 
    \pgsize{25 p.}
}
\label{chap:commonalities_evaluation}

\mnote{Summary of contributions}
In the preceding chapters \ref{chap:classification}--\ref{chap:language}, we have discussed quality properties of transformation networks and how they can be systematically improved.
We have discussed the effect of the network topology on properties, and we have derived the \commonalities approach for constructing transformation networks, which uses the effects of topologies to optimize specific quality properties.
Finally, we have proposed the \commonalities language, which supports the process of applying the \commonalities approach to define a transformation network.

\mnote{Trade-off mitigation by construction}
The central benefit of the developed \commonalities approach and the supporting \commonalities language is given by construction.
The way in which the transformation network is defined inherently improves correctness, especially in terms of compatibility (see \autoref{chap:compatibility}), and reusability. 
These are contradicting quality properties in a network of transformations that are directly defined between the metamodels whose instances are to be kept consistent.
We have argued this trade-off mitigation in \autoref{chap:improvement:benefits:properties}.
In addition to this central benefit, we have discussed further benefits that we expect from both the \commonalities approach as well as the \commonalities language in \autoref{chap:improvement:benefits} and \autoref{chap:language:commonalities:benefits}.
We empirically evaluate these benefits with a case study presented in this chapter.

\mnote{Empirical evaluation of \commonalities approach}
In the discussions of \autoref{chap:improvement} and \autoref{chap:language}, two general issues affecting the \commonalities approach remained that may only be solved by empirical investigations.
First, although consistency relations and their preservation are only described in a different way by means of auxiliary models, it may be possible that the approach restricts the possible consistency relations that can be described in any way, especially under the goal of achieving a consistency relation tree (see \autoref{chap:improvement:commonalities:tree}).
Second, achieving a consistency relation tree with the approach is important to maximize the compatibility guarantee while ensuring maximal reusability (see \autoref{chap:improvement:commonalities:tree}), but it is unclear how far or under which conditions this tree can be achieved in practice.

\mnote{Empirical evaluation of \commonalities language}
In addition to the benefits of the \commonalities approach, the \commonalities language is expected to reduce the specification effort, which could increase with the \commonalities approach in comparison to an ordinary transformation network when employing existing tools for defining the auxiliary metamodels and transformations to them (see \autoref{chap:language:commonalities:benefits}).
We have thus developed a prototype of that language and evaluate its correctness, as well as the goal of reducing specification effort in a case study.


\section{Goals and Methodology}

\mnote{Completeness, applicability and benefits}
In this evaluation, we aim to validate relevant properties of the \commonalities approach and the \commonalities language that are not given by their construction but have to be analyzed empirically.
This especially concerns the applicability of the approach and specific benefits provided by the language, but also the general completeness of the approach, i.e., the ability to express every required set of consistency relations.
It is an extension of the preliminary case study on feasibility that we have conducted and presented in previous work~\owncite{klare2019models}.

\begin{table}
	\renewcommand{\arraystretch}{1.4}%
    \rowcolors{1}{\secondlinecolor}{\firstlinecolor}
    \begin{tabular}{L{8.2em} L{20em}}
        \toprule
        \rowcolor{\headinglinecolor}
        \goal{Approach} & 
            Show that transformation developers can use the \commonalities approach to specify consistency and its preservation between multiple models. \\
        \question[eq:commonalities:completeness]{Completeness} & 
			\questiontext{How far are the \commonalities approach and the \commonalities language capable of defining arbitrary consistency relations?} \\
        \metric & 
			\metrictext{Definition ratio: Ratio of consistency relations for which consistency can successfully be defined} \\
		\question[eq:commonalities:practicality]{Practicality} & 
            \questiontext{How far can a \commonalities specification achieve a consistency relation tree in practice?} \\
        \metric & 
            \metrictext{Cross-tree ratio: Number of cross-tree relations compared to the number of relations} \\
            \midrule
    \end{tabular}
    \rowcolors{1}{\secondlinecolor}{\firstlinecolor}
    \begin{tabular}{L{8.2em} L{20em}}
        \rowcolor{\headinglinecolor}
        \goal{Language} & 
			Show that transformation developers can define consistency in a concise way with the \commonalities language. \\
		\question[eq:language:correctness]{Correctness} & 
			\questiontext{Do transformations generated by specifications in the \commonalities language preserve consistency according to the defined relations?} \\
        \metric & 
            \metrictext{Preservation ratio: Ratio of scenarios in which consistency can successfully be preserved} \\
        \question[eq:language:benefit]{Benefit} & 
            \questiontext{How much more concise is a specification in the \commonalities language compared to a specification in the \reactionslanguage?} \\
        \metric & 
            \metrictext{Code ratio: Ratio between the \acrshort{SLOC} in a \commonalities specification compared to the \acrshort{SLOC} with a \reactions specification} \\
        \bottomrule
    \end{tabular}
    \caption[Goals, questions, metrics for \commonalities]{Goals, questions and metrics for \commonalities approach and language evaluation.}
    \label{tab:commonalities_evaluation:gqm}
\end{table}

\mnote{Empirical evaluation in case study}
In the following, we present an empirical evaluation based on a case study, in which we apply a prototypical realization of the \commonalities language to consistency relations and their preservation in the domain of component-based software engineering, which we have introduced in \autoref{chap:foundations:case_studies} and already employed for the evaluation of our contributions regarding the construction of correct transformation networks in \autoref{chap:correctness_evaluation:categorization}.
We summarize the general goals of the evaluation along with according questions and metrics as quantitative measures for answering them in \autoref{tab:commonalities_evaluation:gqm}.

\mnote{Completeness evaluation}
Regarding the \commonalities approach as such, we are interested in the possibility to be used by transformation developers to define consistency preservation.
In a first place, this comprises the validation of completeness according to \autoref{chap:classification:properties}.
We want to find out whether it is possible to define arbitrary consistency relations with the \commonalities approach. 
In fact, \citeauthor{stevens2020BidirectionalTransformationLarge-SoSym} shows that every multiary relation can be expressed by an auxiliary metamodel with binary relations between this auxiliary metamodel and the metamodels to describe consistency between~\cite{stevens2020BidirectionalTransformationLarge-SoSym}.
This means that also any set of binary relations, which induce a multiary relation as discussed in \autoref{chap:correctness:notions_consistency:monolithic_modular}, can be expressed by an auxiliary metamodel and binary relation between it and the metamodels to define consistency between.
This conforms to the general idea of the \commonalities approach and, if recursively applied, even to the hierarchic composition of \commonalities.
Despite this theoretical insight, we investigate whether such a specification is actually achievable in practice, especially under the specific goal of achieving a consistency relation tree in a specification of \commonalities.
Even if the \commonalities approach itself may not be restricted in expressiveness, the proposed \commonalities language may be because of the selected way in which \commonalities and their relations are defined.
This leads to \autoref{eq:commonalities:completeness}, which we aim to answer by measuring how many consistency relations of our case study we are able to define:
\begin{align*}
    &
    \mathvariable{definition\ ratio} = \frac{\mathtextspacearound{\# of defined consistency relations}}{\mathtextspacearound{\# of total consistency relations}}
\end{align*}
The more consistency relations we are able to define, the higher it is an indicator for the completeness of the approach and the language. 
It does, however, especially indicate completeness of the \commonalities language, such that we derive by argumentation whether restrictions in expressiveness exist only because of the language or already because of restrictions of the \commonalities approach.
The language especially serves as a means to draw conclusions about completeness of the approach.

\mnote{Practicality evaluation}
For the \commonalities approach to provide the benefit of inherently guaranteeing compatibility, it must be possible to define a consistency relation tree by means of the additional \conceptmetamodels and their \commonalities.
In this first place, we aim to identify whether such a tree can be defined at all.
We do not aim to systematically find conditions under which this is possible or even how the \commonalities approach and the \commonalities language can systematically support this.
Knowing whether the specification of such a tree is achievable at all is a prerequisite for these further investigations, which we refer to as future work.
It identifies practicality of the approach, as considered in \autoref{eq:commonalities:practicality}.
To this end, we measure in our case study how many of the defined relations are cross-tree relations, i.e., violate the definition of a consistency relation tree:
\begin{align*}
    &
    \mathvariable{cross\mbox{-}tree\ ratio} = \frac{\mathtextspacearound{\# of cross-tree consistency relations}}{\mathtextspacearound{\# of defined consistency relations}}
\end{align*}
In the best case, this ratio is $0$, such that the relations actually form a consistency relation tree.
Referring to \autoref{def:relationtree} for consistency relation trees, we consider the graph induced by the relations defined by the manifestation relations of a \commonalities specification between \metaclasses of the \concretemetamodels and \conceptmetamodels, in which they are called \commonalities.
We only consider the actually defined consistency relations, as we cannot make statements about the relations that we do not express by \commonalities in the case study.

\mnote{Correctness evaluation}
Regarding the \commonalities language, we are most interested in finding indicators for improving usability of the \commonalities approach by providing a concise way of specification.
First of all, this requires that the language operates correctly, i.e., that it actually generates transformations that preserve consistency according to the defined consistency relations, as defined in \autoref{eq:language:correctness}.
This actually evaluates two correctness notions. 
First, it identifies whether the language implementation is correct at a technical level.
Second, it identifies whether the concepts for operationalizing \commonalities into transformations defined with the \reactionslanguage, as proposed in \autoref{chap:language:commonalities:operationalization}, are correct.
We measure this by executing change scenarios and identifying whether the results are consistent to the specified relations:
\begin{align*}
    &
    \mathvariable{preservation\ ratio} = \frac{\mathtextspacearound{\# of successful scenarios}}{\mathtextspacearound{\# of total scenarios}}
\end{align*}
In the best case, this metric evaluates to $1$, such that in all scenarios consistency can successfully be preserved.
In failure cases, we manually investigate the cause, especially distinguishing between conceptual issues in the operationalization of the \commonalities language and technical faults in the compiler implementation.

\mnote{Benefit evaluation}
As an essential benefit of the \commonalities language, we have motivated the reduction of specification effort (see \autoref{chap:language:commonalities:benefits}).
This is of particular importance, because developing a \commonalities specification for consistency between two metamodels by means of existing tools for metamodel and transformation definition requires the definition of three artifacts compared to a single artifact when defining an ordinary transformation.
The \commonalities language aims to resolve this issue.
We consider the specification effort by means of conciseness, i.e., the size of a specification with \commonalities in comparison to a specification of ordinary transformations between the metamodels, as defined in \autoref{eq:language:benefit}.
Since the \commonalities language compiles to \reactions and a comparable implementation of the case study already exists for them (see \autoref{chap:correctness_evaluation:categorization:case_studies}), we compare the size of a \commonalities specification with the size of a specification in the \reactionslanguage in terms of the \gls{SLOC} and measure the following metric:
\begin{align*}
    &
    \mathvariable{code\ ratio} = \frac{\mathtextspacearound{\# of \acrshort{SLOC} with \commonalities}}{\mathtextspacearound{\# of \acrshort{SLOC} with \reactions}}
\end{align*}
The lower the value of this metric, the more concise a specification in the \commonalities language can be considered in comparison to a specification in the \reactionslanguage.
We expect this insight in conciseness to correlate with the required specification effort.


\section{Prototypical Implementation}

\mnote{\vitruv framework}
For conducting the case study, we have used a prototypical implementation of the \commonalities language and the realization of the case study with that language in the \vitruv framework (see \autoref{chap:foundations:multiview:vitruv}).
We have also employed this framework for the implementation of the our case study for evaluating concerns and approaches regarding correctness in \autoref{chap:correctness_evaluation:categorization}.
In addition, the \reactionslanguage (see \autoref{chap:foundations:transformations:reactions}), to which the \commonalities language compiles, is part of the \vitruv framework.

\mnote{\commonalities language}
The implementation of the \commonalities language conforms to the considerations discussed in \autoref{chap:language}.
It implements an internal specification of concepts, i.e., it allows the specification of each \commonality in one file together with all its manifestations and relations to them, according to the elements we have introduced in \autoref{fig:language:elements}.
The syntax conforms to the examples we have given in \autoref{lst:language:class_example} and \autoref{lst:language:component_example}, but provides even more sophisticated specializations of the depicted language constructs.
We have also defined a set of general as well as case-study-specific operators for manifestation conditions, as well as attribute and reference relations.

\mnote{\commonalities operationalization}
The specifications in the \commonalities language are compiled to Ecore metamodels for the \conceptmetamodels and specifications in the \reactionslanguage, according to \autoref{chap:language:commonalities:operationalization}.
\reactions, in turn, are compiled to ordinary Java code that implements a specific \gls{API} of the \vitruv framework.
The framework orchestrates the transformations with a simple strategy that enqueues all transformations defined for the model that is modified by the current transformations and executes them until no further changes are made.
Since we aim to define \commonalities that represent a consistency relation tree, transformations should be inherently compatible and are thus likely to terminate with such an orchestration strategy (see \autoref{chap:correctness_evaluation:categorization:discussion:limitations}).
The implementation of the framework with the \commonalities and \reactionslanguage is available in a GitHub repository~\owncite{vitruvFrameworkGithub}.


\section{Case Study}

\mnote{Domains and relations}
We have performed a case study based on the metamodels \gls{PCM}, \gls{UML} and Java, as introduced in \autoref{chap:foundations:case_studies}.
The specification of \commonalities is based on two sets of consistency relations, one for \gls{PCM} and object-oriented design, applying to both Java and \gls{UML}, and for \gls{UML} and Java, which we have both also introduced in \autoref{chap:foundations:case_studies}.
In addition, we have used the consistency relations to implement a case study of transformations with the \reactionslanguage in \autoref{chap:correctness_evaluation} for evaluating our contributions regarding correctness of transformation networks.
Since the \commonalities language compiles to \reactions, this allows us to compare the two realizations.

\mnote{Realization with \commonalities}
The two sets of consistency relations are motivated by the two concepts of object-oriented design and component-based design, between which have already distinguished in the explanation of the \commonalities approach in \autoref{chap:improvement} and for which we have especially considered a hierarchic representation in \autoref{chap:improvement:commonalities:composition}.
We have thus implemented the case study with two according \conceptmetamodels, of which the one for object-oriented design defines \commonalities between \gls{UML} and Java, and the one for component-based design defines \commonalities between the object-oriented design \conceptmetamodel and the \gls{PCM}.
The case study has been implemented with the \commonalities language in the Master's thesis of \textowncite{hennig2020ma}.
Details on the implemented consistency relations and \commonalities can also be found there~\owncite[Sec. 3, A.2]{hennig2020ma}.
In the following, we summarize the case study.


\begin{table}
	\small
	\centering
	\rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{l S[table-format=2] S[table-format=2] S[table-format=1] S[table-format=2, table-column-width=2.5em] r}
		\toprule
		\multirow{2}{*}{\bfseries Element Type} & {\multirow{2}{*}{\bfseries Total}} & \multicolumn{4}{c}{\bfseries Covered} \\
		\cmidrule(lr){3-6}
		& & \multicolumn{1}{c}{Direct} & \multicolumn{1}{c}{Implicit} & \multicolumn{2}{c}{Overall} \\
		\midrule
		\Metaclasses 				& 13	& 7		& 3	& 10	& \SI{77}{\percent}	\\
		Attributes 					& 27	& 19	& 1	& 20	& \SI{74}{\percent}	\\
		Containment References 		& 13	& 9		& 0	& 9		& \SI{69}{\percent}	\\
		Non-containment References 	& 4		& 2		& 2	& 4		& \SI{100}{\percent}	\\
		Enumerations				& 2		& 0		& 2	& 2		& \SI{100}{\percent}	\\
		\midrule
		Total 						& 59	& 37	& 8	& 45	& \SI{76}{\percent}	\\
		\bottomrule
	\end{tabular}
	\caption[Numbers of case study elements of \acrshort{UML}]{Numbers of elements from the \gls{UML} metamodel used in the case study. Adapted from~\owncite[Table 10.4]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:coverage_uml}
\end{table}

\begin{table}
	\small
	\centering
	\rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{l S[table-format=2] S[table-format=2] S[table-format=2] S[table-format=2, table-column-width=2.5em] r}
		\toprule
		\multirow{2}{*}{\bfseries Element Type} & {\multirow{2}{*}{\bfseries Total}} & \multicolumn{4}{c}{\bfseries Covered} \\
		\cmidrule(lr){3-6}
		& & \multicolumn{1}{c}{Direct} & \multicolumn{1}{c}{Implicit} & \multicolumn{2}{c}{Overall} \\
		\midrule
		\Metaclasses 				& 30	& 9		& 11	& 20	& \SI{67}{\percent}	\\
		Attributes 					& 13	& 11	& 0		& 11	& \SI{85}{\percent}	\\
		Containment References 		& 32	& 19	& 1		& 20	& \SI{63}{\percent}	\\
		Non-containment References 	& 1		& 0		& 0		& 0		& \SI{0}{\percent}	\\
		Enumerations				& 0		& 0		& 0		& 0		& \SI{100}{\percent}	\\
		\midrule
		Total 						& 76	& 39	& 12	& 51	& \SI{67}{\percent}	\\
		\bottomrule
	\end{tabular}
	\caption[Numbers of case study elements of Java]{Numbers of elements from the Java metamodel used in the case study. Adapted from~\owncite[Table 10.5]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:coverage_java}
\end{table}

\begin{table}
	\small
	\centering
	\rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{l S[table-format=2] S[table-format=2] S[table-format=1] S[table-format=2, table-column-width=2.5em] r}
		\toprule
		\multirow{2}{*}{\bfseries Element Type} & {\multirow{2}{*}{\bfseries Total}} & \multicolumn{4}{c}{\bfseries Covered} \\
		\cmidrule(lr){3-6}
		& & \multicolumn{1}{c}{Direct} & \multicolumn{1}{c}{Implicit} & \multicolumn{2}{c}{Overall} \\
		\midrule
		\Metaclasses 				& 16 & 7  & 2 		& 9 & \SI{56}{\percent}  \\
		Attributes 					& 15 & 7  & 1 		& 8 & \SI{53}{\percent} \\
		Containment References 		& 18 & 6  & 0 		& 6 & \SI{33}{\percent}  \\
		Non-containment References 	& 8  & 3  & 1  		& 4 & \SI{50}{\percent}  \\
		Enumerations 				& 1  & 0  & 1  		& 1 & \SI{100}{\percent}  \\
		\midrule
		Total 						& 58  & 23  & 5  	& 28 & \SI{48}{\percent}  \\
		\bottomrule
	\end{tabular}
	\caption[Numbers of case study elements of \acrshort{PCM}]{Numbers of elements from the \gls{PCM} metamodel used in the case study. Adapted from~\owncite[Table 10.3]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:coverage_pcm}
\end{table}

\mnote{Size of realized relations}
We have realized a subset of the consistency relations that we have introduced in \autoref{chap:foundations:case_studies} and that we have realized with the \reactionslanguage in the case study presented in \autoref{chap:correctness_evaluation}.
\autoref{tab:commonalities_evaluation:coverage_uml}, \autoref{tab:commonalities_evaluation:coverage_java} and \autoref{tab:commonalities_evaluation:coverage_pcm} give an impression of the size of the implemented case study.
They depict the numbers of elements by type for the three metamodels that are relevant for the originally defined consistency relations, denoted as \emph{total}, and those that were realized in the case study, denoted as \emph{covered}.
We distinguish between elements that are \emph{directly} and \emph{implicitly} covered, according to whether they were actually defined as manifestation classes or features of them and passed to the operators ensuring consistency explicitly, or whether they were only accessed within the operators.
The numbers reflect the case study size by the absolute number of considered elements and the coverage of the originally presented complete consistency relations by the relative numbers.

\mnote{Implicitly covered elements}
Such implicitly covered elements concern, for example, primitive data types or enumeration literals, which have to be instantiated on demand but which are not explicitly represented within the \commonalities.
Implicit elements also cover structures of elements that are only represented by one element in the other metamodels.
For example, \gls{UML} represents the realization of an interface by a class through an indirect reference of a dedicated generalization element, i.e., the class references a generalization, which, in turn, references the implemented interface, whereas the \commonality and the Java representation have a direct reference to the implemented interface.
In that case, the generalization element is not explicitly referenced in the \commonality specification but only implicitly used within the operators for the implementation relation.
In Java, many \metaclasses are only implicitly covered, because primitive types, type references and modifiers are all represented as \metaclasses, whereas they are represented as instances in the other metamodels (see~\owncite[Sec.~5.7.4]{klare2016b}) and thus only used implicitly within operators for attributes that represent references or modifiers.

\mnote{Coverage of complete consistency relations}
The implementation contains $15$ \commonalities, of which eight belong to the object-oriented design and seven to the component-based design \conceptmetamodel.
These \commonalities put $124$ elements of the \concretemetamodels into relation, which represent around \SI{64}{\percent} of the total $193$ elements that are relevant for the complete set of introduced consistency relations.
While the case study implementation covers most elements of \gls{UML} (\SI{76}{\percent}) and Java (\SI{67}{\percent}), it only covers \SI{48}{\percent} of the \gls{PCM} elements.
Most of the missing consistency relations are due to intended restrictions of the case study size or restrictions in expressiveness of the \commonalities language.
We further discuss the reasons in the subsequent results presentation.

\mnote{Reused test cases}
The implementations of all \commonalities are available in a corresponding GitHub repository of the \vitruv project~\owncite{vitruvCBSEGithub}.
It also contains test cases, which we have reused from those that we have defined for the case study with the \reactionslanguage, presented in \autoref{chap:correctness_evaluation:categorization:case_studies}.
Since we only want to evaluate whether results are correct regarding those consistency relations for which we have defined consistency preservation with \commonalities, we have reduced the tests to those for the according consistency relations in comparison to the tests summarized in \autoref{tab:correctness_evaluation:errors:test_cases}.
We have, however, also added further test cases such that in total more test cases for the case study implementation with the \commonalities language exist than for the implementation with the \reactionslanguage.
All these test cases perform changes that lead to the violation of a specific type of consistency relation and require the transformations to change the other models for restoring consistency, which are then validated by the test case.

\begin{table}
	\small
	\centering
	\rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{L{10em} S[table-format=3, table-column-width=6em] S[table-format=3, table-column-width=5em] r}
		\toprule
		\multicolumn{1}{l}{\bfseries Consistency Relation} & \multicolumn{1}{l}{\bfseries Test Cases} & \multicolumn{2}{c}{\bfseries Successful Test Cases} \\
		\midrule
		Package 			& 6		& 6		& \SI{100}{\percent} \\
		Class 				& 26	& 26	& \SI{100}{\percent} \\
		Class Method 		& 40	& 40	& \SI{100}{\percent} \\
		% 1 scenario disabled: multi constructor
		Constructor 		& 24	& 22	& \SI{92}{\percent} \\
		Field + Association	& 20	& 20	& \SI{100}{\percent} \\
		Interface 			& 10	& 10	& \SI{100}{\percent} \\
		Interface Method 	& 28	& 28	& \SI{100}{\percent} \\
		\midrule
		Total 				& 154	& 152	& \SI{99}{\percent} \\
		\bottomrule
	\end{tabular}
	\caption[Test case results for object-oriented design]{Test cases and their success rates for consistency relations in object-oriented design. Adapted from~\owncite[Table 10.2]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:tests_oo}
\end{table}

\begin{table}
	\small
	\centering
	\rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{L{10em} S[table-format=3, table-column-width=6em] S[table-format=3, table-column-width=5em] r}
		\toprule
		\multicolumn{1}{l}{\bfseries Consistency Relation} & \multicolumn{1}{c}{\bfseries Test Cases} & \multicolumn{2}{c}{\bfseries Successful Test Cases} \\
		\midrule
		Repository 				& 6		& 6		& \SI{100}{\percent} \\
		Interface		 		& 6		& 6		& \SI{100}{\percent} \\
		Signature + Parameter	& 48	& 48	& \SI{100}{\percent} \\
		Composite Data Type		& 48	& 48	& \SI{100}{\percent} \\
		Repository Component	& 6		& 6		& \SI{100}{\percent} \\
		% PCM/UML -> Java
		Provided Role 			& 12	& 8		& \SI{67}{\percent} \\
		\midrule
		\rowcolor{\firstlinecolor}
		Total 					& 126	& 122	& \SI{97}{\percent} \\
		\bottomrule
	\end{tabular}
	\caption[Test case results for component-based design]{Test cases and their success rates for consistency relations in component-based design. Adapted from~\owncite[Table 10.1]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:tests_cbs}
\end{table}

\mnote{Summary of test cases}
\autoref{tab:commonalities_evaluation:tests_oo} and \autoref{tab:commonalities_evaluation:tests_cbs} summarize the test cases together with their results when applied to the case study implementation with the \commonalities language, which we discuss in the subsequent section.
The test cases are split into one set only concerning consistency relations for object-oriented design, i.e., those keeping only \gls{UML} and Java models consistent, and another set for component-based design, in which also \gls{PCM} models are kept consistent.
For every change scenario, such as the addition or modification of a specific type of element involved in a consistency relation, we consider one test case per change direction per model pair.
For object-oriented design, this results in two test cases for each scenario, since each change can be performed in \gls{UML} and checked in Java and vice versa.
In component-based design, each change can be performed in any of the three models and propagated to any of the two other models, resulting in three test cases for each scenario.
In consequence, test case numbers are a multiple of two for object-oriented design and a multiple of six in component-based design.

\mnote{Detailed test cases and complex scenario}
In total, we have executed $284$ test cases.
They include $154$ test cases for keeping \gls{UML} and Java consistent with the object-oriented design \commonalities and $126$ test cases for keeping \gls{PCM}, \gls{UML} and Java consistent with \commonalities for object-oriented design and component-based design.
While these test cases use minimalist models that are sufficient for representing the consistency relation under test, we have also used the Media Store system model~\cite{strittmatter2016a}, which is a comprehensive case study system for the \gls{PCM} and which we have already used in the evaluation of our approaches for constructing correct transformation networks in \autoref{chap:correctness_evaluation}.
For this \gls{PCM} model, we simulate its construction by producing a change sequence that yields the models, which conforms to the \emph{Reconstructive Integration Strategy} proposed by \citeauthor{langhammer2017a}~\ownandothercite{klare2021Vitruv-JSS}{langhammer2017a}.
We have defined four additional test cases using this construction simulation, which validate that a \gls{UML} model is created and that it is consistent to the defined consistency relations, including components, interfaces, operation signatures and data types.

% * 15 Commonalities, 8 in OO, 7 in CBS

% Total elements relevant for case studies (as depicted in \autoref{chap:correctness_evaluation:compatibility:case_study}), directly covered elements (those as manifestations / participations in \commonalities) and indirectly covered elements (referenced within operators but not as participations, because they are only relevant when transferring information of other elements but not on their own).
% Those internal elements are primitive data types, enums etc., but also UML interface realizations due to indirect reference of generalization which cannot be mapped yet, same as for provided role in PCM

% Many Java elements internally covered, because primitive types, type references and modifiers are represented as metaclasses, which are not mapped on their own but only in context of an operator

% FROM LUKAS: 
% Of the total \textbf{193} identified element types, our commonalities cover \textbf{124} (\textbf{64.25\%}) elements in total, \textbf{99} of which are covered directly and \textbf{25} are covered internally by operators. The largest portion of elements that are not covered is associated with PCM (\textbf{52\%}). We mostly covered all UML and Java elements that we considered in our cases study (\textbf{98\%} and \textbf{96\%} respectively), but of the total identified elements we only cover \textbf{76\%} and \textbf{67\%}.

% MEDIA STORE

% * From PCM to UML
% * Only elements already supported (components, interfaces, data types, signatures with parameters)
% * Missing: provided and required roles


\section{Results and Interpretation}

\mnote{Coverage of complete case study}
We use the implemented case study and the conducted tests to answer the evaluation questions summarized in \autoref{tab:commonalities_evaluation:gqm}, or at least to find indicators for how their general answer is expected to be based on the data from the case study.
The questions are split into those especially concerning the \commonalities approach and those concerning the \commonalities language.

\subsection*{\Commonalities Approach}

We have explained that we did not implement all consistency relations with the \commonalities language that we have realized with the \reactionslanguage in the evaluation for transformation network correctness in \autoref{chap:correctness_evaluation:categorization}, but only a sufficiently complex subset.
We selected consistency relations forming a coherent set that can be realized with reasonable effort, and such that we do not expect further insights regarding applicability, practicality and usability of the \commonalities approach and language from the implementation of the omitted relations.
To avoid a bias by defining an arbitrary subset of the consistency relations, which, by accident, can completely or almost completely be realized with the \commonalities language, we consider the ratio of consistency relations realized with the \commonalities language in comparison to the complete consistency relations depicted in \autoref{chap:foundations:case_studies}.
It results in the following metric values, derived from the values in \autoref{tab:commonalities_evaluation:coverage_uml}, \autoref{tab:commonalities_evaluation:coverage_java} and \autoref{tab:commonalities_evaluation:coverage_pcm}:
\begin{alignat*}{3}
    &
	\mathvariable{definition\ ratio}_{\mathvariable{sums}} &&= \SI{64}{\percent} \quad  &&\bigl(= \tfrac{45 + 51 + 28}{59 + 76 + 58}\bigr)\\
	& 
	\mathvariable{definition\ ratio}_{\mathvariable{average}} &&= \SI{64}{\percent} \quad &&\bigl(= \tfrac{\SI{76}{\percent} + \SI{67}{\percent} + \SI{48}{\percent}}{3} \bigr) \\
	&
	\mathvariable{definition\ ratio}_{\mathvariable{UML-Java}} &&= \SI{71}{\percent}
\end{alignat*}
We counted the elements of the metamodels affected by the consistency relations.
To avoid a bias by having different numbers of elements in the different metamodels, we have calculated the ratio both based on the sums of the elements across all metamodels ($\mathvariable{definition\ ratio}_{\mathvariable{sums}}$), as well as the equally weighted average of the coverage of all metamodels ($\mathvariable{definition\ ratio}_{\mathvariable{average}}$).
They do, however, both sum up to the same value of \SI{64}{\percent}.
Since \gls{UML} and Java represent those metamodels that are kept consistent by a single \conceptmetamodel for object-oriented design and can thus be considered a minimal application of the \commonalities approach for only two metamodels, we explicitly  calculated the ratio only for these two metamodels as well.
Since both ways of calculation introduced above yield the same value, we have only depicted the single result of \SI{71}{\percent}.

\mnote{Non-realizable relations}
The coverage ratios especially give an impression of how comprehensive the realized consistency relations are.
To evaluate completeness of the \commonalities approach and the language, it is of particular importance to identify how many of the consistency relations that we intended to implemented could not be realized.
In summary, we found that most consistency relations that we aimed to realize could actually be achieved, except for multi-valued types in \gls{PCM} and Java, which is due to current limitations of the language.
Multi-valued types are fields and parameters of a type with an upper bound in its multiplicity higher than one.
This can be expressed with explicit multiplicities in \gls{UML} and with collection data types in \gls{PCM}, whereas they have to be rolled out as explicit implementations of collections in Java.
The current implementation of the \commonalities language lacks an operator for that situation, which is, however, not a conceptual limitation but can be added with some additional effort.
In addition, provided and required roles in \gls{PCM} as well as generalizations in \gls{UML} are currently not fully supported and in parts only covered implicitly, because the current implementation of the \commonalities language only supports explicit relations to containment references, but roles and generalizations contain ordinary references to the provided, required or implemented interfaces, which can up to now only be accessed implicitly within operators of the \commonalities language.
This is a technical limitation, which the current case study implementation avoids by implementing complex operators to support these situations, which is why the according test cases are actually successful, but the language lacks sufficient support for such relations.

\mnote{Omitted relations}
The remaining consistency relations were omitted on purpose and are summarized in more detail in the Master's thesis of \textowncite[Sec. 3]{hennig2020ma}.
They comprise \emph{composite components} in \gls{PCM}, which are comparable to basic components and only need to be distinguished by an according naming schema or the containment of assemblies of other components, of which at least the latter requires some implementation effort but is not expected to be a conceptual issue.
In addition, \emph{systems} and \emph{subsystems} are not considered, because they are composite components with slightly different semantics.

\mnote{Approach and language completeness}
In summary, the case study results indicate that in answer to \autoref{eq:commonalities:completeness} the \commonalities approach itself is complete, as we have already expected because of the theoretical considerations by \textcite{stevens2020BidirectionalTransformationLarge-SoSym}.
The \commonalities language, however, currently has some limitations that prevent the realization of some consistency relation or at least made it more difficult than it should be.
We found these to be only technical limitations that can be solved by extending the language, such that they do not hide actual limitations of the underlying \commonalities approach.
The results emphasize the status of the \commonalities language implementation as a prototype, but still indicate possible completeness of such a language according to the concepts for such a language proposed in \autoref{chap:language}.

% NOT COVERED:
% For details on elements omitted from the case study, see~\owncite[Sec.~3]{hennig2020ma}
% Java: no multi-valued types (collections of elements in fields and parameters)
% PCM:
% * Composite Components: Same as basic ones, need to be distinguished (e.g., by naming schema, user interaction or containment of other components), but then are comparable to basic ones, so no further insights
% * Provided/Require Role, Generalization internally use non-containment references (discussed above)
% * System: no covered intentionally, is basically only a composite component
% * CollectionDataType: complicated to map between multiplicities in Java and Collection data types in Java and PCM. Other data types are already mapped. Since each type can only be related to one kind of data type, there are not further problems to be expected regarding a tree structure. It is basically doing and potentially limitations of existing operators of the language, but no conceptual problems.

\mnote{Practicality of \commonalities}
The central question to evaluate for the \commonalities approach concerns its practicality in terms of achieving a consistency relation tree with a \commonalities specification to benefit from the discussed guarantees in quality improvement.
We have discussed in \autoref{chap:improvement:commonalities:tree} that the defined consistency relations have to form a consistency relation tree and in \autoref{chap:language:commonalities:features} we found the graph induced by the operands of the operators putting \commonalities and their manifestations into relations to be the one to consider for identifying a consistency relation tree.
Since in several \commonalities of our case study, elements have to be considered implicitly within the operators and not all of them are explicitly defined as operands, these elements have to be considered as well.
For that reason, we conducted the investigation of the defined relations to identify the graph as a consistency relation tree manually.
In this manual analysis, we found that none of the defined relations lead to the violation of the definition of a consistency relation tree according to \autoref{def:relationtree}:
\begin{align*}
    &
    \mathvariable{cross\mbox{-}tree\ ratio} = 0
\end{align*}
Although restricted to a single case study, this at least serves as a first indicator for the practicality of the approach as asked in \autoref{eq:commonalities:practicality}, i.e., that it actually supports or at least enabled the specification of a consistency relation tree.
To mitigate the risk of mistakes performed in the manual analysis of consistency relations, the test results also serve as a further indicator that the relations form a tree.
Violations of such a tree structure can easily lead to incompatibilities, as discussed in \autoref{chap:compatibility}, which can then lead to non-termination, as discussed in \autoref{chap:errors}, especially with the simple orchestration strategy that we employed for the case study.
We have, however, not observed any non-termination in the test cases.
The failing tests were due to other reasons, which we discuss in the following.
Although even without a tree structure the consistency relations can be compatible, or even if they are incompatible it may not lead to failures during transformation execution, it still serves as an indicator that the consistency relations form a tree.
Even if this is not the case, the evaluation at least shows that the transformations behave correctly, thus no matter whether this actually achieved by defining a consistency relation tree or any other reason that makes the operationalization of \commonalities specifications likely to be correct, at the end it is only important that correctness is achieved.

% Regarding tree: Violations would easily lead to incompatibility and thus potentially non-termination with the selected simply orchestration strategy, which is not guaranteed to terminate. We have, however, not observed any non-termination -> potentially no incompatibilities -> potentially tree (but not necessarily!)


\subsection*{\Commonalities Language}

\mnote{Correctness of \commonalities language}
As a preliminary for any further insights on the \commonalities language, we first have to validate its correctness.
This covers the correct implementation of the language and its compiler, as well as correctness of concepts how to compile \commonalities into \reactions.
While the former can be seen as simple bug testing, the latter gives us insights in whether the operationalization concept is correct, which especially means that the language can be seen as a derivation of the \mappings language, from which we have reused operationalization concepts (see \autoref{chap:language:commonalities:operationalization}).
To validate correctness, we consider the test case results for those consistency relations of the case study that we have implemented with the \commonalities language.
According to \autoref{tab:commonalities_evaluation:tests_oo} and \autoref{tab:commonalities_evaluation:tests_cbs}, more than \SI{97}{\percent} of them are successful:
\begin{align*}
    &
    \mathvariable{preservation\ ratio} \ge \SI{97}{\percent}
\end{align*}
In addition, the four test cases for the Media Store case study system also produce the expected results.
Regarding \autoref{eq:language:correctness}, this is a high indicator for correctness of the operationalization concept of the \commonalities language as well as its implementation, especially because the failures of the remaining test cases are caused by the used \vitruv framework and by incompleteness of the \commonalities language.

\mnote{Reasons for failing test cases}
In total, six test cases fail.
This concerns two tests cases for constructors in object-oriented design, which both implement the same scenario but once from Java to \gls{UML} and once vice versa.
In this test scenario, multiple constructors with different parameter lists are created.
The \vitruv framework first executes transformations for the insertion of both constructors and afterwards for the addition of parameters.
This leads to two indistinguishable constructors with empty parameter lists when first execution the transformation, such that when adding the parameters, the two constructors cannot be distinguished anymore.
Processing the constructor additions one after another in the framework would solve the problem.
Anyway, the same problem would occur when using the \reactionslanguage.
Regarding provided roles in component-based design, four test cases fail because of the references to provided interfaces only being implicitly covered in operators.
We have already discussed before that the \commonalities language currently only supports relations for containment references, such that other references have to be processed with operators.
Provided roles are contained in components, which in turn reference the provided interface.
When a provided role is added to a component, this is processed by a relation in the component \commonality.
The operator for that relation also implicitly considers the reference to the interface within the role, but this may not yet be set.
When the interface of the role is set or changed later, this change is not propagated as no relation for it is defined in a \commonality and thus no \reaction is generated for it, such that the according test cases fail.
In consequence, this is a result of technical incompleteness of the \commonalities language as discussed before, but not a matter of incorrectness of its operationalization.

% Depending on how we measure: Average of both categories, sum of all tests among both categories, but always higher than 97 percent, so does not matter. Interesting why the remaining tests did not work.

% 4 media store tests: all work properly (packages, classes and interfaces, composite data types, operation signatures)
% ADD MEDIA STORE IN CASE STUDY DESCRIPTION

% Problem Provided Role: PCM -> Java and UML -> Java: created role initially empty and no reaction to changes of provided interface (internal handling) -> no reaction to contents of role, so interface not added in Java model.

% Provided role failures: Faulty definition of operator - provided interface of a role is only used in operator but not defined as parameter/participation, such that no reaction for its change is created
% Limited expressiveness: Language cannot express mapping between non-containment reference (in Java) to containment reference with object (role) + non-containment reference (interface) (in PCM).

% OO Constructor: Problem in \vitruv framework -- after two constructor creations, first both constructors are propagated before propagating the insertion of parameters. This results in two indistinguishable constructors (with empty parameter lists) in Java, which results in problems of the subsequent parameter propagation for one of them.
% Adding one constructor after another (either in the test, i.e., by the user, or as propagation of the framework) would solve the problem.

\begin{table}
	\small
	\centering
	%\rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{L{6em} C{9em} S[table-format=4, table-column-width=6.8em] S[table-format=5, table-column-width=3em] r}
		\toprule
		\multicolumn{1}{l}{\bfseries } & \multicolumn{1}{c}{\bfseries \reactions \textit{(omitted)}} & \multicolumn{1}{c}{\bfseries \commonalities} & \multicolumn{2}{c}{\bfseries Difference}\\
		\midrule
		Specifications 			& 2390 \textit{(302)}	& 514	& -1876 	& \SI{-78}{\percent}\\
		Utilities				& 2250 \textit{(445)}	& 2523	& 273 		& \SI{11}{\percent}\\
		\midrule
		\rowcolor{\firstlinecolor}
		Total					& 4640 \textit{(747)}	& 3037	& -1603 	& \SI{-53}{\percent}\\
		\bottomrule
	\end{tabular}
	\caption[Lines of code for a \commonalities and \reactions specification]{\acrshort{SLOC} in the \commonalities and \reactions specification for the consistency relations between \gls{UML} and Java. For \reactions, the numbers only cover the lines for consistency relations covered by the \commonalities specification, whereas those in parenthesis denote the lines for relations not covered by the \commonalities specification. Adapted from~\owncite[Table 10.9]{hennig2020ma}.}
	\label{tab:commonalities_evaluation:reactions_comparison}
\end{table}

\mnote{Benefit of \commonalities language}
The \commonalities language is supposed to support the construction of a transformation network according to the \commonalities approach.
In comparison to applying the construction approach with ordinary modeling and transformation tools, it is supposed to reduce the specification effort, especially in the simple or initial case in which consistency between only two metamodels shall be specified.
The case study implementation contains a specification for two metamodels in terms of the object-oriented design \commonalities between \gls{UML} and Java.
We had already defined their consistency with a direct transformation by means of the \reactionslanguage in previous case studies for the \vitruv framework~\owncite{klare2021Vitruv-JSS}, which we have also employed for the evaluation in \autoref{chap:correctness_evaluation:categorization}.
\autoref{tab:commonalities_evaluation:reactions_comparison} compares the realization of consistency relations between \gls{UML} and Java by means of the \reactionslanguage and the \commonalities language in terms of \glspl{SLOC}.
Since there is no unique measure for \glspl{SLOC} for these languages, we have decided to format the code such that each statement for every grammar rule starts in a new line, according to the formatting used for \reactions~\owncite{klare2021Vitruv-JSS}.
Since not the complete specification is defined within the language artifacts itself but also within utilities written in Java or Java-like code, we also counted the \glspl{SLOC} in that code.
Since the \reactionslanguage allows to define arbitrary code within the \reactions, only few utility code is necessary, whereas the \commonalities language requires utility code already for all use-case-specific operators.
Considering all code together leads to a reduction in \glspl{SLOC} between \reactions and \commonalities of more than \SI{50}{\percent}:
\begin{align*}
    &
    \mathvariable{code\ ratio} = \SI{47}{\percent}
\end{align*}
Drawing conclusions of this metric to the actual specification effort suffers from several biases.
First, the counted \glspl{SLOC} can only be considered an approximation, as, for example, the utilities are shared with other projects and thus they are not tailored to consistency between \gls{UML} and Java.
Second, whether conciseness in terms of \glspl{SLOC} actually leads to less specification effort is not evaluated but only assumed as an hypothesis.
In response to \autoref{eq:language:benefit}, the case study provides an indicator for achieving conciseness in comparison to the \reactionslanguage.
It is, however, only necessary to avoid an increase in specification effort, thus conciseness should at least not decrease.
Whether or not the actual value of around \SI{50}{\percent} in code size reduction is representative, it at least shows that we may not expect a drastic increase in code size, which would improve the specification effort.



\section{Discussion and Validity}

\mnote{Insights and validity threats}
From the discussed case study and its results, we can derive several important insights.
They are even given although a single case study only gives indicators for specific properties. %, as it suffer from potential limitations especially in external validity.
We discuss threats to the validity of our results after a summary of important insights.

\subsection*{Insights}

\mnote{Practicality and specification effort}
With the empirical evaluation, we especially aimed to validate two properties.
First, we wanted to investigate practicality of the \commonalities approach in terms of being able to express arbitrary consistency relations and especially to achieve a tree structure that inherently guarantees certain quality properties.
Second, we aimed to validate the reduction of specification effort with the \commonalities language to ensure that in the simple case of defining consistency between two metamodels, specification effort does increase in comparison to a direct transformation between them.

\mnote{Practicality insights}
In the case study, we found by manual analysis of the defined \commonalities that a tree structure inherently guaranteeing compatibility was achieved.
There are several threats to the validity of generalizing this result to achievability of a tree structure in every case, which we discuss in the following subsection.
Although a tree is what we want to achieve to have definite guarantees for compatibility, the actual goal is to achieve correctness, which can also be achieved without a specification inducing such a tree topology.
Violations of a tree structure only introduce potential incompatibility, which can potentially lead to execution cycles.
This must, however, not be problematic, because a cycle in the relations must not necessarily lead to a cycle between corresponding elements in an instance, and because even if there is such a cycle, it can be implemented properly so that execution terminates consistently, like we aimed to achieve for ordinary transformation networks in \autoref{part:correctness}.
Thus, even if the results of our analysis of relations in the case study was erroneous, the execution of the transformations derived from the \commonalities specification still worked properly, i.e., it always terminated and led to consistent results in the executed test scenarios.
Thus, independent from whether a consistency relations tree was actually achieved or not, the approach led to a correct specification, which also provides optimal reusability by construction of the \commonalities approach, and thus mitigated the trade-off between these properties as intended.

\mnote{Benefit insights}
Regarding the \commonalities language, we were able to show a reduction in code size of about \SI{50}{\percent} for the consistency relations between \gls{UML} and Java in comparison to a specification with the \reactionslanguage.
Although this evaluation also suffers from several threats to validity, which we discuss in the following, it at least indicates that we must not expect a significant improvement in code size.
For two metamodels, a specification according to the \commonalities approach by means of the \reactionslanguage would require twice as many \reactions code plus the definition of the \conceptmetamodel in comparison to a direct \reactions specification between the metamodels.
Thus, a specification that requires at most two times the code lines required for a \reactions specification between the metamodels provides a benefit with respect to average realizations of the \commonalities approach.
Thus, even if specification effort and code lines are not linearly correlated, the reduction of code lines by \SI{50}{\percent} in comparison to an improvement by factor two will likely lead to less specification effort.


\subsection*{Threats to Validity}

\mnote{Results indicate statement}
In the following, we discuss different possible threats to the validity of the discussed results.
The restriction to one case study especially limits external validity, thus all results can only be seen as indicators for the statements that we make.
We will, however, discuss, for which reasons validity of the statements may be actually restricted, distinguished by construct, internal, conclusion and external validity~\cite{wohlin2012validity-Book}.

\paragraph{Construct Validity}
\mnote{Manual analysis conduction}
There are especially two threats regarding construct validity, which arise from the manual analysis of achieving a tree structure with \commonalities, as well as from the selection of consistency relations to implement.
The manual conduction of the analysis of the consistency relation graph induced by the \commonalities specification is prone to faults, as it lacks an explicit graph representation that can be analyzed automatically.
Violations of the tree structure would, however, likely have led to failures during execution.
The \reactions generated from \commonalities are not synchronizing, as discussed as a preliminary for transformations in networks (see \autoref{chap:synchronization}), thus in case there are cycles of consistency relations and thus transformations across which changes are propagated, the execution would likely lead to failures as missing synchronization and also potential incompatibilities prevent the transformations from finding consistent results.
In particular, in \autoref{chap:correctness_evaluation:categorization} we found that missing synchronization is the most severe issue that, in the case studies, led to a failure of every test case.

\mnote{Non-representative relations}
The selection of consistency relations that we have realized with the \commonalities language may be non-representative.
A different choice might have led to different results regarding all evaluation questions, including completeness of the approach and the language, the achievability of a tree structure, as well as correctness of the language compiler.
We did, however, argue why we performed that specific selection of consistency relations and why we do not expect the addition of other consistency relations to yield other results.
In addition, even if the actually realized relations may not be representative, at least the complete case study with all relations represents a sophisticated scenario.
It especially requires the usage of all elements provided by the \commonalities language, in comparison to preliminary studies in which only specific elements of the language were required and used to achieved feasibility results~\owncite{klare2019models}.

% While the complete relations present a realistic scenarios, which can thus be considered representative, the selection of relations we performed may be not.

% Tree only considered for defined relations: potentially further relations would have violated tree structure. However, if relations cannot be defined by the approach at all, which would violate the tree structure, that would at least prevent the definition of tree violations.
% Same for correctness: only considered for the relations that we were able to express (completeness)

% relations representative? may be bad choice and other would have led to different results, no completeness for other scenarios, maybe no correctness for other kinds of relations
% But: case study is even more sophisticated than many other studies (e.g., ATL transformation zoo) and all kinds of elements provided by commonalities language are used, thus likely to cover all relevant aspects

\paragraph{Internal Validity}
\mnote{Optimization for case study}
Internal validity may especially be affected regarding the results for properties of the \commonalities language.
First, the language was only a proof-of-concept before implementing the case study and was improved along with the case study realization.
Thus, there is the risk of optimizing the language for the case study.
This especially affects the operators, as several of them are specific for the case study, whereas the overall structure of the language is generic.
Even if this reduces validity, it does not affect the results for the evaluation of the \commonalities approach and the conciseness of the language, but only its completeness and correctness.

\mnote{Development by single person}
In addition, the case study was implemented by a single person, such that the results may be affected by the performance of that person.
This may affect completeness and conciseness of the approach.
Regarding completeness, another person may have been able to implement more relations, thus evaluation results may only become better when performed with a different person.
Conciseness of an implementation can vary in both directions when performed by different persons, which induces a bias in the results regarding conciseness.
It can be the case that the average developer produces less concise results than in our evaluation, which can affect generalizability of the results.
The goal of the language is, however, that specifications are not less concise than an implementation with ordinary transformations, which we have shown is at least possible, and which is even given if the results are biased due to the measured amount of improvement in conciseness.

\mnote{Baseline for conciseness}
Another threat is given by the comparison of \commonalities with \reactions for evaluating conciseness of the language.
The \reactionslanguage allows imperative, unidirectional specifications of transformations and provides high expressiveness by being rather verbose and providing only few abstractions in comparison to a general-purpose programming language.
A language at a higher abstraction language, such as the \mappings language, from which we have reused large parts of the compiler, or \qvtr, may provide a better baseline for comparison.
We have used the \reactionslanguage as a baseline, because the case study was already implemented and, in particular, evaluated with that language.
The case study implementation has already been compared with an implementation in ordinary Java code~\owncite{klare2021Vitruv-JSS}, which has shown a reduction in code size.
This shows that specifications in the \reactionslanguage are not arbitrarily verbose and for other languages such an evaluation does even not exist.
Since the goal of the evaluation was especially to show that \commonalities specifications do not drastically increase the specification effort, these results indicating that we do not have to expect an increase in code size by several times also indicate that such an increase in specification effort cannot be expected.

% Language improved during the case study so may partially (esp.\ regarding operators) be optimized for the study.
% This does however not affect results for the approach and conciseness, but may affect completeness and correctness of language
% Comparison of commonalities with reactions but they are rather verbose, so may be better to compare with declarative language such as mappings.
% Benefit: reactions are imperative, more declarative languages exist -> no fair comparison. But reactions already compared to ordinary code (refer to paper) and show reduction there, so they are verbose but not arbitrarily verbose

\paragraph{Conclusion Validity}
\mnote{Correlation between code lines and effort}
The correlations of evaluated metrics and performed statements are straightforward for completeness, correctness and the achievement of a tree topology.
The assumed correlation between conciseness of the code and specification effort is, however, a threat to conclusion validity.
Code that is more concise may even be harder to specify, because it can require more knowledge about language constructs and experience with using them.
In particular, much logic of the \commonalities language is defined in operators.
We especially observed a significant improvement in conciseness in the specification code, but not in the utilities code, to which the operators belong.
Thus, if the operators are the part that is hard to specify, the effort may even increase.
As discussed before, we do, however, not require a significant reduction in specification effort to gain any benefit from the \commonalities language, as the central benefit is already given by its guarantees regarding correctness and reusability.
In consequence, the language is only supposed to mitigate the increase in effort induced by the \commonalities approach as such, which is at least two times the effort, measured in terms of code lines, for a direct transformation between two metamodels, whereas in the case study the language reduced it by the same factor.
So even if there is a large bias in the relation of conciseness and specification effort, the results still indicate that effort increases with the \commonalities language.

\paragraph{External Validity}
\mnote{Restriction to one case study}
The central threat regarding external validity is the limitation to a single case study.
This may affect generalizability if other case studies produce different results regarding completeness, correctness and conciseness.
We did, however, mitigate this threat by not using a toy example but a sophisticated case study, including multiple realistic consistency relations and a hierarchic definition of them with \commonalities.
In addition, we do not expect practicality in terms of achieving a tree topology to depend on the actual case study, but only on the kinds of relations, which we expect to be representative in the study as discussed for construct validity.
Finally, the effort for setting up a case study and to set up the baseline for a comparison with ordinary transformation is rather high.
At least, we were able to use an independently developed baseline that we have used for our evaluations in \autoref{chap:correctness_evaluation:categorization} to evaluate conciseness of the \commonalities language.

% Only one case study, generalization unclear
% But: no toy example, hierarchic relations, practicality does not so much depend on domains but kind of relations
% Hard to develop case studies, even harder to find other implementations of case studies for transformation networks to compare with.
% Already discussed for transformation network study, so we even profit from having the transformation network implementation used for our other evaluations.


\section{Limitations and Future Work}

\mnote{Assumptions and evaluation results}
The \commonalities approach as well as the \commonalities language have been developed particularly for the specification of descriptive specifications of consistency (see \autoref{chap:improvement:concepts:specification}) and with specific goals of quality improvement that require a tree topology of the specified relations.
These assumptions as well as the discussed evaluation results yield limitations of the proposed approach and language.
We discuss them in the following and derive opportunities for future work.

\paragraph{Tree Achievement}
\mnote{Proving compatibility}
The essential benefits of the \commonalities approach regarding correctness guarantees arise from the likeliness of defining a tree of consistency relations.
Although the evaluation indicates that such a tree is achievable or even if it is not achieved, it may ease the achievement of a correct transformation network, it is finally still up to the developer to ensure correctness.
The language supports him or her in achieving it, but it would be beneficial to finally make the language ensure correctness.
We have sketched in \autoref{chap:language:commonalities:features} how the graph of consistency relations can be derived from the operands of relation operators in the \commonalities language.
It requires that operators only use model elements that were explicitly passed to them as operands.
The approach for proving compatibility, which we have presented in \autoref{chap:compatibility}, can then be applied to these relations.
Since the relations are not expressed as \gls{OCL} constraints but as arbitrarily complex operators written in Java, redundancy of relations cannot easily be determined.
Thus, the approach may only be used to validate if the relations represent a consistency relation tree, but this is sufficient as achieving a tree is the goal anyway.
Performing such an integration in future work would further improve the benefits of the language by giving the developer explicit feedback whether he or she defined a topology that actually guarantees the benefits provided by the \commonalities approach.
% Tree: Developer has to ensure that a tree is achieved. Can be improved by the language. Integrate compatibility approach from \autoref{chap:compatibility} into the language. Due to rather declarative specification, graph of consistency relations can be derived and analyzed. Assumptions have to be made on operators, which can do arbitrary stuff, e.g., that only the elements explicitly given to the operator are used, and no further navigation through the model is done within the operator. With that assumption, we can construct the graph from the commonalities specifications and operator arguments and apply the analysis.
% Who is responsible for the tree structure? How does the language support its achievement?

\paragraph{Declarative Specification}
\mnote{Applicability to prescriptive relations}
We have motivated the \commonalities approach as a reasonable way of thinking about and specifying common concepts of different metamodels.
In \autoref{chap:improvement:concepts:specification}, we have discussed that this especially fits for descriptive specifications of consistency, i.e., those where metamodels actually share common concepts, often in terms of redundancies.
Other consistency specifications, which may prescriptively define more complex dependencies, may not fit into such a notion of common concepts, which can make it difficult to apply the \commonalities approach to them or which may lead to specifications that do not inherently induce a tree topology.
We have already considered in \autoref{chap:improvement:application} how \commonalities specifications can be combined with other transformation networks, be they defined with \commonalities or ordinary transformations, which allows to combine different kinds of specifications for different purposes and to apply \commonalities only where they fit properly.
In future work, it would thus be of particular interest to apply these ideas of combining specifications and evaluate the feasibility of these ideas.
In addition, the further application of the approach to different case studies can reveal whether the restriction to declarative specifications is actually relevant or whether the approach can also be applied well to other specifications, despite our motivation.

% Intended for descriptive specification: finally does not matter, but prescriptive specification may not have that dedicated common concepts, but more arbitrary relations than common concept which usually represent redundancies. Then the kind of specification may not fit that well and may be more unlikely to achieve a tree structure.
% Future work: evaluate

\paragraph{Language Extensions}
\mnote{Capabilities and abstraction of operators}
The limitations we have found in the evaluation were mostly caused by limitations of the current implementation of the \commonalities language.
Even in the Master's thesis, in which the case study was conducted, several language extensions had to be made to support the parts of the case study that we have presented before~\owncite[Sec. 9]{hennig2020ma}.
The current limitations concern the availability and complexity of operators, such as missing operators for relating attributes to references, or complex pattern matching for indirect references that led to the test failures, and reusability, e.g., in terms of inheritance, which currently leads to repetitions when specifying similar concepts.
While these limitations should be addressed in future work by conceptual and technical extensions of the \commonalities language, it also induces a research question regarding the operators.
Currently, the operators are suited for the implemented case study, but it is an open question how a reusable set of operators at an appropriate level of abstraction can or should be defined, such that relevant, recurring cases can be realized with a predefined operator set.
This is currently left open in the language design, as we did not make any restrictions regarding the operators (see \autoref{fig:language:elements}), but should be considered as a general future research question.

% Several limitations in case study due to limitations of language expressiveness. Even in previous thesis multiple extensions for this case study necessary~\owncite{hennig2020ma}.
% Language does not provide inheritance for commonalities, repeated definition of names, repeated definition of shared information, e.g., between basic and composite components etc.

% Limited set of operators, e.g., no generic operator for mapping attributes to references (e.g., visibility is EnumLiteral in UML, whereas it is a reference to a type instance in Java), complex pattern mappings, e.g., type reference in UML is direct reference, whereas in Java a reference contains a reference object, which then references a further object that references the type; or primitive types in Java represented as types and in UML as predefined instances of a generic primitive type type.

% Granularity of operators: open research question how to define a reusable set with appropriate degree of abstraction, such that only for few cases custom operators need to be defined. Especially necessary to define a metrics for that (what are "few cases"?). Currently left open in language design (see diagram with arbitrary operators) and implemented specific for case-study (as focus on structure of language, not on realization of manifestation relations).

% Movement of objects treated as removal and insertion leading to deletion of contained elements and values

\paragraph{Evidence Improvement}
\mnote{External validity by case studies}
A central drawback of the presented evaluation is the limited evidence due to the restriction to a single case study affecting generalizability of the results.
Although we have intensively argued why the results are still valuable indicators for the properties that we have evaluated, it still remains a threat in external validity.
Thus, it is important to provide further evidence on the results by applying the approach and the language to further case studies.
This can also be used to evaluate the assumptions we have made for the language, as we have discussed before.
Finally, since the evaluation presented in \autoref{chap:correctness_evaluation:categorization} lacks similar drawbacks in external validity, case studies in future work can be combined for both, such that consistency relations are elicited and validated by test cases only once.
This also allows to compare the results, for example, to further validate the specification effort of the \commonalities language.


\section{Summary}

\mnote{\commonalities approach and language}
In the preceding chapters, we have presented the \commonalities approach and the \commonalities language for mitigating trade-off decisions between quality properties of transformation networks induced by the topology of that network.
We have discussed how this mitigation can be achieved by an appropriate construction approach for transformation networks and how it can be supported by a proper language under the assumption of achieving a specific kind of tree topology.

\mnote{Evaluation results and application area}
To evaluate whether this assumption is achievable and thus how complete and practicable the approach is, and how far the language actually supports the specification, we have conducted an empirical evaluation at a case study.
The evaluation indicates that the approach is actually applicable in scenarios in which metamodels share common concepts and that the language provides a concise way of specifying consistency.
Since the approach is only supposed to be applied in specific situations, it is, however, necessary to combine such a specification with other ordinary specifications of transformation networks.
In consequence, the \commonalities approach depicts a solution for specific consistency relations, for which it provides more guarantees regarding certain quality properties than ordinary transformation networks.
In general, it must be combined with other transformations, such that correctness of the combination must again be ensured by means discussed in \autoref{part:correctness}.


% \begin{copiedFrom}{VoSE}

% \section*{Proof-of-Concept}

% We have proposed the \commonalities approach and a realizing language.
% We have explained that we expect them to improve understandability of transformations and to reduce problems of transformation networks, such as compatibility and modularity.
% Although we gave arguments that justify this expectation, it has to be evaluated empirically to increase evidence.
% However, before evaluating the benefits of our approach, we first have to investigate its feasibility.
% For that reason, we built an initial prototype of the language and applied it to a simple evaluation case as a proof-of-concept.
% %to show the feasibility of the concept.
% %This forms our contribution~\ref{contrib:proofofconcept}.

% % Evaluation Goal: Show feasibility of the idea

% % Evaluation Methodology: Build a proof-of-concept prototype of a language and apply it to a simple case

% \subsection*{Case Study}

% We have implemented a prototype of the \commonalities language, which allows to define \commonalities with simple attribute and reference mappings and to compose \commonalities.
% The syntax is an extension of the examples shown in \autoref{lst:language:class_example} and \autoref{lst:language:component_example}.
% The language comprises a compiler that derives a \conceptmetamodel, as well as a set of transformations from a specification in the language.
% The generated transformations are in turn defined in the \reactionslanguage~\owncite{klare2016b}, which is a delta-based transformation language that is, just like the \commonalities language itself, part of the \vitruv approach~\cite{kramer2013b}.
% \vitruv is a view-based development approach that uses transformations to keep models consistent.
% The implementation of the \commonalities language can be found in the GitHub repository of the \vitruv project~\owncite{vitruvFrameworkGithub}. %\footnote{\label{githubfootnote}\url{https://github.com/vitruv-tools/Vitruv}}.

% We have applied the implementation to a simple case study that consists of four metamodels, each containing one \metaclass that represents a root element and one that represents a contained element. 
% Both elements have an identifier and a name in all metamodels, and an additional single-valued and multi-valued feature of integers in two of the metamodels.
% The root \metaclass additionally has a containment reference to the contained \metaclass.
% We have defined two \commonalities, one for the root element and one for the contained element, which redundantly represent the same concepts in all the metamodels.
% The root \commonality references the contained \commonality.
% This results in one \conceptmetamodel with four manifestations.

% To validate that the specifications in the \commonalities language are correctly defined and operationalized, we have
% %defined 8 test cases that 
% defined test cases that perform 21 different model modifications, which 
% %
% create and delete all possible types of elements and modify all attribute and reference values in instances of every metamodel.
% They cover the set of all possible modifications that can be performed on instances of those metamodels.
% This also includes change propagation across composed \commonalities.
% The tests successfully validate that the modifications are correctly propagated to all other models in all cases.
% The test cases and the used example metamodels are also available in the GitHub repository of the \vitruv project~\owncite{vitruvFrameworkGithub}. %\footnotemark[1].

% % \begin{itemize}
% %     \item First reference to concrete implementation here
% %     \item Refer to simple example implementation showing the ability to define and run the Commonalities approach
% % \end{itemize}

% \subsection*{Discussion}
% % Formerly: Threats to Validity

% %Maybe we can omit this section, but we need to discuss that it is really, really only a proof-of-concept (some reviewers do not understand the difference to a complete benefit, scalability and effectiveness evaluation if you do not tell them again and again).

% Our proof-of-concept validates the feasibility of the proposed \commonalities approach: 
% It demonstrates that it is possible to apply the concept of defining consistency relations between multiple metamodels  through a central metamodel in a simple scenario. It also shows that an operationalization can be derived that preserves consistency of all instances of such metamodels.
% %Our evaluation only serves as a proof-of-concept to validate feasibility of the approach that we present in this paper.
% %In consequence, 
% The results only give an indicator that the \commonalities concept can be applied and that a language with an internal concept definition can be designed.
% To further evaluate the capabilities of such an approach, the language would have to be extended to be able to define more complex relationships.
% Additionally, the approach has to be applied to larger parts of more complex metamodels and metamodels for different contexts to improve external validity of the results.
% This could also reveal whether the assumption of having a tree of \commonalities is practical in realistic scenarios.

% Since evaluating functional capabilities of the approach is only an---essential---first step, the evaluation of further properties such as applicability, appropriateness, effectiveness and scalability are part of ongoing work with further case studies.
% As a central benefit of our approach, we claim to improve understandability of relations between metamodels, but can only give arguments for that by now.
% An evaluation of that claim would require a user experiment that compares our approach to specifications of direct transformations between multiple metamodels.

% Finally, one might argue that defining \conceptmetamodels leads to additional effort, as for two metamodels it is necessary to define one additional metamodel and two transformations rather than only a single transformation.
% First, this is only true as long as only two metamodels are related by one \conceptmetamodel. 
% If three metamodels shall be related, there would be a network of three transformations, which are not necessarily compatible without using the \commonalities approach, and one metamodel with three transformations using the \commonalities approach.
% When the \commonalities approach is applied, the number of necessary transformations increases linearly with the number of metamodels that are related, whereas it increases quadratic without them.
% Second, the effort for defining transformations can be reduced by using an appropriate language to define \conceptmetamodels and transformations, as we have proposed in \autoref{chap:language}. Our language only requires developers to write one specification that contains both the \conceptmetamodel and all transformations to its manifestations.

% % \subsection{Limitations}
% % Contradictory Commonalities specifications?

% \end{copiedFrom} % VoSE


