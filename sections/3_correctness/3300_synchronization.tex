\chapter{Constructing Synchronizing Transformations
   \pgsize{20 p.}
}
\label{chap:synchronization}

\todo{Vermeidbarkeit hängt insb. auch von der verwendeten Sprache ab. Z.B. sind Mappings / QVT-R analyisierbar, aber Reactions / QVT-O nicht.}

\todo{Ergebnis sollte sein: Synchronisierungseigenschaft ist erreichbar per Konstruktuion}

Problem statement: Ordinary transformations may be correct if used on their own (according to Stevens), but in context of a transformation network, when other transformation have modified the "target" model as well, they do not lead to a consistent result anymore, i.e., they are not correct.
Start with example of duplicated creation and overwrite.

Define ordinary transformations to take deltas in model 1 and produce deltas in model 2
Say that unidirectional synchronizing transformations take deltas in both models and update the deltas in one of them.
Refer to fine-grained formalization regarding compatibility, where consistency relations are directional, thus each directional preservation rule preserves consistency according to the consistency relations in one direction.
Having synchronizing unidirectional transformation, executing both preserves consistency to both unidirectional consistency relations. However, their must be some kind of conformance of the unidirectional transformation to each other (define how this conformance looks like!), so that executing each once does not lead to violations in the other direction. In general, that may not be possible. In fact, each unidirectional transformation should consider the unidirectional consistency relations of both directions.

So:
Ordinary unidirectional transformation for Rr: m1, m2, d1 -> d2, such that (d1(m1), d2(m2)) consistent to all relations in Rr (Rl respectively)
Synchronizing unidirectional transformation: m1, m2, d1, d2 -> d2', such that (d1(m1), d2'(m2)) consistent to all relations Rr and consistent to all relations in Rl to which is was consistent before (thus no violation of further consistency relations)

Direct consequence: Executing one transformation after the other ensures that models are consistent to alle relations in Rr and relation

Based on that, we derive how we can use languages that take deltas in model 1 and produce them in model 2 to emulate synchronizing unidirectional transformations that are able to manage deltas in both models and produce deltas in one of them.
For that, we make the case distinction and derive the creation pattern.
For each change merge case, we consider that we somehow "merge" the changes. In general, the change of the transformation to m2 will overwrite the previous change to m2. Then we consider that there is another consistency relation affected by the new change. We show whether/why not the other consistency relation can be violated by that change and discuss how to avoid that.


\begin{copiedFrom}{DocSym}

\section{Binary Transformation Interoperability}

Multi-model consistency preservation can be a achieved by combining binary transformations to graphs, %of transformations, 
with the transformations being executed transitively.
Since all binary transformations are developed independently of each other, it is necessary that they interoperate properly in a \emph{non-intrusive} way, thus without the necessity for the developer to understand and modify them, which we refer to as \emph{black-box combination}.

Even under the assumption that, in contrast to our introductory motivation, all specifications are free of contradictions, it is easy to see that problems arise when combining binary transformations by transitively executing them.
For example, consider the relations in \autoref{fig:prologue:binary_combination_example}.
If a component is added to the \ac{ADL}, causing a \ac{UML} class creation due to \ref{fig:prologue:binary_combination_example:R1}, which in turn causes a Java class creation due to \ref{fig:prologue:binary_combination_example:R2}, the transformation for relation \ref{fig:prologue:binary_combination_example:R3} does not know that an appropriate class was already created, if the transformations are treated as black boxes.
Consequently, the transformation will create the same class again, which may override the existing one, depending on the implementation and execution order.
A simple solution for this example would be to have all transformations use a common trace model and check for existing elements before creating them in a transformation.
Nevertheless, independently developed transformations will usually not assume that %this only applies if the transformation considers possibly preexisting transformation results, which it will not do in general if it does not assume other transformations to create corresponding elements.
other transformations may already have created corresponding elements.
Additionally, the trace model must allow the transformation engine to retrieve transitive traces.
However, it is unclear if transitive resolution of traces can always be performed, as it can depend on whether the transitive trace belongs the considered consistency relation or another.
%If, in another scenario, the transformation in the example was actually supposed to create an additional class, it would have to ignore the existing trace.

As can be seen in the example, especially the correct handling of trace information in interdependent transformations has to be researched.
This applies not only to element creations, but also other change types, such as attribute or reference changes, especially if they are multi-valued.
In our thesis, we will therefore apply transitively executed binary transformations in different case studies to identify these and potential further problems.
We then want to come up with a catalog of such problems %preventing the black-box combination of transformations 
together with solution patterns for them.
For example, to avoid duplicate element creations, a simple pattern could be to always check for already existing traces for that consistency relation in the transformations.
In consequence, the integration of those patterns into a transformation language or the application of them as a transformation developer is supposed to achieve black-box combinability of the transformations.

\end{copiedFrom} % DocSym


\begin{copiedFrom}{ICMT}

To ensure that a network of \acp{BX} operates properly, potential mistakes %, as identified in the previous section, 
must be avoided.
%\todoHeiko{Klarmachen, dass wir hier keine vollumfänglichen Lösungsstrategien präsentieren, sondern das, was man im Prinzip auf den Ebenen tun muss. Nur für die unterste Ebene gibt es ein Konzept}
We evaluate our categorization regarding correctness and completeness %for that 
in a case study that combines independently developed transformations.
In that case study, we classify occurring failures with our categorization and trace them back to a causal mistake.
To identify whether such a classification is correct, we need to be able to fix the mistake and validate that the failure disappears.
%To investigate whether the classification of revealed mistakes is correct, we need to be able to fix them. %the classification of a mistake was correct and if another mistake was potentially hidden by the fixed one.
%Therefore, we do not provide complete solution strategies, but instead discuss how mistakes at the different levels can be avoided in general as our contribution \ref{contrib:avoidance}.
Therefore, we discuss general strategies to avoid mistakes at the different levels as our contribution \ref{contrib:avoidance} and apply them in the evaluation.
%, we discuss how mistakes at the different levels can be avoided in general, but do not provide complete solutions % solution strategies
%in this work.

%At the system level, mistakes can only be avoided by careful requirements elicitation. 
%Since occurring mistakes on that level represent non-conformance with a usually informal notion of consistency, such mistakes cannot be automatically avoided or detected.
At the global level, mistakes occur due to non-conformance with an informal notion of consistency and %cannot be detected automatically but 
can only be avoided by careful requirements elicitation. 
We therefore have to assume that global level mistakes are reliably avoided by the developers.
Analytic approaches~\cite{klare2018docsym}
can ensure that specifications at the modularization and operationalization level are free of faults.
%This can be applied on both the modularization and the operationalization level.
Nevertheless, %under the assumption that transformations are developed independently, 
the drawback of such an approach is that it works a-posteriori, when transformations are combined to a network. %, so transformations would have to be adapted %after their specification 
%when they are combined to a network
We, in contrast, want to achieve avoidance of interoperability issues a-priori, so that transformations can be developed independently and combined afterwards.
It is easy to see that mistakes at the modularization level cannot be avoided a-priori. 
%If modular transformations are developed independently, 
Ensuring that transformations are non-contradictory %, i.e. that they rely on the same notion of a global consistency specification, 
would require developers to have knowledge about the other transformations, which breaks the assumption of independent development.
%This breaks our assumption that developers have restricted domain knowledge, each defining one modular consistency specification.
%
Finally, mistakes regarding element matching at the operationalization level are domain-independent. 
This enables the development of generic mechanisms to ensure interoperability at the operationalization level by construction, without knowing about other transformations.

In the following, we discuss one strategy to avoid mistakes at the modularization and one to avoid those at the operationalization level.
Developers can use these strategies to build networks that are free of faults, or can use them to fix mistakes if failures occur.

% MOVED TO BEGINNING OF SECTION
% We evaluate our categorization in a case study combining independently developed transformations. 
% For that, we need to fix mistakes in order to investigate whether their classification was correct. %the classification of a mistake was correct and if another mistake was potentially hidden by the fixed one.
% Therefore, we do not provide complete solution strategies, but instead discuss how mistakes at the different levels can be avoided in general as our contribution \ref{contrib:avoidance}.

%We therefore assume that mistakes on modularization level are avoided as well and investigate, under this assumption, whether the operationalization can be develop interoperable by construction.

% \begin{itemize}
%     \item Problems on all three levels must be avoided
%     \item On all levels, possibility to use model checking for finding faults when combining a set of transformations (cf. \cite{klare2018docsym}
%     \item Detecting mistakes on level 1 is hard, because one would have to compare the specification against a natural, usually unspecified notion of consistency
%     \item Drawback: works a-posteriori, so transformations would have to be adapted afterwards to be used together
%     \item Therefore: approach for a-priori avoidance of interoperability issues necessary
%     \item Problem: on level 2 no a-priori avoidance of problems possible, or overall knowledge from level 1 necessary -> breaks our assumption of independent development
%     \item But: On level 3 possibility to develop mechanisms and patterns to ensure interoperability on that level by construction, because it only concerns the operationalization of specifications. In contrast to the consistency specifications, which are domain specific, the operationalization follows a generic pattern for which generic interoperability solutions can be derived
%     \item We assume interoperability on level 2 for our approach so that there are no interactions between mistakes on the level 2 and 3 (no precise enough)
% \end{itemize}

\end{copiedFrom} % ICMT


\section{Ensuring Interoperability of Executed Transformations 
    \pgsize{15 p.}
}
Goal: Avoidance strategies for interoperability mistakes, i.e. achieving synchronization of transformations (MA Torsten / Timur)
\label{chap:prevention:interoperability}

\begin{copiedFrom}{ICMT}

% FORMERLY: \subsection{Matching Elements in Operationalizations}
\subsection{Matching Elements}
\label{chap:prevention:interoperability:matching}

To avoid failures due to mistakes at the operationalization level, transformations must respect that other transformations may have already created elements.
In the binary case, this is unnecessary.
A single incremental \ac{BX} can assume that elements are either created by the user, %and then are input of the transformations
or were created by the transformation itself.
To identify corresponding elements, transformation languages usually use trace models, which are created by the transformations.
When \acp{BX} are combined to networks, %elements may also be created by other transformations.
%In consequence, 
direct trace links may be missing because a sequence of other transformations created the elements and trace links only indirectly across elements in other models.
%Thus, it is necessary to establish direct trace links between corresponding elements.´
In this scenario, corresponding elements can be matched by information at three levels:
%Such element matching can be performed on three levels:
\begin{enumerate}
    \item \emph{Explicit unique}: The information that elements correspond is unique and represented explicitly, e.g., within a trace model. %Existing transformation languages usually use this technique.
    \item \emph{Implicit unique}: The information that elements correspond is unique, but represented implicitly, e.g., in terms of key information within the models such as element names. %types and element names.
    \item \emph{Non-unique}: If no unique information exists, heuristics must be used, e.g. based on ambiguous information or transitive resolution of indirect trace links.
\end{enumerate}
\todo{Give examples for each case to show that they actually occur}

Indirect trace links, which link elements transitively across other models, usually exist for elements that correspond, because other transformations have already created them.
Nevertheless, indirect trace links cannot be used to unambiguously identify such elements.
An element can correspond to multiple elements in another model, which is why most transformation languages offer tagging of trace links with additional information to identify the correct element.
%For example, a component in an architecture description could be mapped to two classes in an object-oriented design, one providing the component implementation and one providing utilities.
%The relevant corresponding element can be retrieved if the traces are tagged with the information that one class is the implementation and one is a utility.
For example, a language may tag trace links with the transformation rule they were instantiated in.
This is helpful in the bidirectional case, but when links are resolved transitively, these tags have been created by other, independently developed transformations, and are thus unknown.
%If such tags would be considered, transformations would depend on tags of other transformations and could thus not be developed independently anymore.
Therefore, resolving indirect trace links is only a heuristic, but does not unambiguously retrieve corresponding elements.

% Explain how to match rules on three different levels, what the levels can provide etc.

% \begin{enumerate}
%     \item Direct Correspondences
%     \item Key information
%     \item Heuristics: Indirect correspondences, potentially ambiguous information
% \end{enumerate}

Finally, it is up to the transformation engine or the transformation developer %, depending on the provided abstraction level, 
to ensure that elements are correctly matched.
In contrast to the bidirectional case, direct trace links cannot be assumed in case of networks of \acp{BX}.
Therefore, key information within the models must always be considered to identify matching elements.
Whenever direct trace links or unique key information exists, relevant elements can be unambiguously matched.
In all other cases, heuristics must be used, which potentially leads to failures.

\end{copiedFrom} % ICMT


\begin{insight}[Synchronization]
    When constructing synchronizing transformations, both models may have been and need to be modified in contrast to ordinary bidirectional transformations, which update only one of the models.
    Having ordinary transformations and consistency preservation rules for both directions, executing only one or one after another does not necessarily lead to a consistent result, thus the transformations are not correct in context of a transformation network when both models may have been modified.
    We, however, found that their sequential execution leads to a consistent result for all possible combinations of changes, if identity of elements is handled correctly.
    In contrast to ordinary incremental transformation, which assume that elements were created by the user or the transformation itself, in a transformation networks other transformation may have already created appropriate elements.
    In consequence, a transformation needs to identify if an element already exists upon its creation.
    To achieve that it needs to define key information for identifying that element.
    With that addition, executing ordinary incremental transformations in both directions, each of the consistency preservation rules being correct, the emulated synchronizing transformation is correct.
    In consequence, synchronizing transformations can be constructed with existing transformation languages not considering synchronization and without knowing about other transformations to combine them with.
\end{insight}

\todo{Is this true? We can have cycles there, so it may not be correct. Just consider the confluence case?}