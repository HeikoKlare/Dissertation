\chapter{Constructing Synchronizing Transformations
   \pgsize{20 p.}
}
\label{chap:synchronization}

\todo{Vermeidbarkeit hängt insb. auch von der verwendeten Sprache ab. Z.B. sind Mappings / QVT-R analysierbar, aber Reactions / QVT-O nicht.}

\todo{Ergebnis sollte sein: Synchronisierungseigenschaft ist erreichbar per Konstruktuion}

Transformations are the central artifacts of which a transformation network is composed.
We have introduced them as \emph{synchronizing transformations} in \autoref{def:synchronizingtransformation}, which are combinations of a consistency rule together with a consistency preservation rules that preserves it.
Correctness of such a transformation could then be defined as the property of the consistency preservation rule to preserve consistency of given models according to the consistency relation (cf.\ \autoref{def:synchronizingtransformationcorrectness}).
In theory, a correct transformation can simply be achieved by adhering to that definition.

A consistency preservation rule according to \autoref{def:consistencypreservationrule} receives two models and two changes, one for each of the models, and returns two changes, i.e.:
\begin{align*}
    \consistencypreservationrule{\consistencyrelation{CR}{}} : (\metamodelinstanceset{M}{1}, \metamodelinstanceset{M}{2}, \changeuniverse{\metamodel{M}{1}}, \changeuniverse{\metamodel{M}{2}}) \rightarrow (\changeuniverse{\metamodel{M}{1}}, \changeuniverse{\metamodel{M}{2}})
\end{align*}
We used this rather general notion of a consistency preservation rule between two metamodels to support that both models may have been modified, which is inevitable in a transformation network.
Additionally, both models may need to be modified to properly consistency.
It would, however, be a cumbersome task to define the behavior of the transformation, or more precisely its consistency preservation rule, for all potential pairs of changes in both models.
Furthermore, existing transformation languages usually specify unidirectional consistency preservation rules, thus they only support the propagation of changes made in one model to the other, but not to process changes made to both models at once.
\begin{align*}
    \consistencypreservationrule{\consistencyrelation{CR}{},\rightarrow} : (\metamodelinstanceset{M}{1}, \metamodelinstanceset{M}{2}, \changeuniverse{\metamodel{M}{1}}) \rightarrow \changeuniverse{\metamodel{M}{2}}\\
    \consistencypreservationrule{\consistencyrelation{CR}{},\leftarrow} : (\metamodelinstanceset{M}{1}, \metamodelinstanceset{M}{2}, \changeuniverse{\metamodel{M}{2}}) \rightarrow \changeuniverse{\metamodel{M}{1}}
\end{align*}

\mnote{First option: Independent execution and merge}
In consequence, we usually have two unidirectional consistency preservation rules that define how changes are propagated from one model to the other and vice versa, but this is not equivalent to a synchronizing transformation.
Imagine models $\model{m}{1}$ and $\model{m}{2}$ and changes to them $\change{\metamodel{M}{1}}$ and $\change{\metamodel{M}{2}}$.
If we now applied two unidirectional consistency preservation rules individually, we would apply the first to $\model{m}{1},\model{m}{2}$ and $\change{\metamodel{M}{1}}$, returning $\change{\metamodel{M}{2}}'$, and the second one to $\model{m}{1},\model{m}{2}$ and $\change{\metamodel{M}{2}}$, returning $\change{\metamodel{M}{1}}'$.
It is, however, not guaranteed whether $\tupled{\change{\metamodel{M}{1}}' \concatfunction \change{\metamodel{M}{1}}(\model{m}{1}), \change{\metamodel{M}{2}}' \concatfunction \change{\metamodel{M}{2}}(\model{m}{2})}$ is consistent.

\mnote{Second option: Sequential execution}
Another option would be to sequentialize the execution, thus first generating $\change{\metamodel{M}{2}}'$ as before by applying one consistency preservation rule to $\model{m}{1},\model{m}{2}$ and $\change{\metamodel{M}{1}}$.
Afterwards, the second rule is applied to $\change{\metamodel{M}{1}}(\model{m}{1}),\change{\metamodel{M}{2}}'(\model{m}{2})$ and $\change{\metamodel{M}{2}}$.
This means that $\change{\metamodel{M}{2}}$ is not applied to $\model{m}{2}$ anymore, to which the changes were made originally, but needs to applied to $\change{\metamodel{M}{2}}'(\model{m}{2})$.
It is, however, not clear whether the change can still be applied to that state, i.e., whether $\change{\metamodel{M}{2}}$ is defined for $\change{\metamodel{M}{2}}'(\model{m}{2})$.
An example may be that $\change{\metamodel{M}{2}}'$ removes an element from $\model{m}{2}$, which $\change{\metamodel{M}{2}}$ changes.
\todo{Revise change definition to be partial}

We, however, want to ensure that both original changes are applied to the models and consistency preservation rules can react to them.

\begin{itemize}
    \item We assume consistency preservation rules according to fine-grained consistency relations introduced for compatibility
    \item So a synchronizing transformation considers fine-grained relations, in fact a transformation then consists of multiple relations, two for each fine-grained relation (each direction). Their combination induces the \modellevelconsistencyrelation for the two metamodels.
    \item Although the consistency preservation rule may in practice also be defined in terms fine-grained rules, which together with the fine-grained consistency rules then forms what is often called \emph{transformation rules}, we do not need to have a more fine-grained notion here.
    \item The transformation then is still correct as defined before, when the preservation rule preserves consistency to the relation, but now according to all fine-grained relations (and thus also the induced monolithic one) instead to the single model-level one.
    \item To reflect the notion of unidirectional consistency preservation rules, as often defined in transformation languages, which are still synchronizing, i.e., are able to react to changes made to both models, we may define:
\end{itemize}
\begin{align*}
    \consistencypreservationrule{\consistencyrelationset{CR}_{\rightarrow},\rightarrow} : (\metamodelinstanceset{M}{1}, \metamodelinstanceset{M}{2}, \changeuniverse{\metamodel{M}{1}}, \changeuniverse{\metamodel{M}{2}}) \rightarrow \changeuniverse{\metamodel{M}{2}})\\
    \consistencypreservationrule{\consistencyrelationset{CR}_{\leftarrow},\leftarrow} : (\metamodelinstanceset{M}{1}, \metamodelinstanceset{M}{2}, \changeuniverse{\metamodel{M}{1}}, \changeuniverse{\metamodel{M}{2}}) \rightarrow \changeuniverse{\metamodel{M}{1}})
\end{align*}

Now we can define correctness as before as the rule for one direction ensuring that models are consistent to that direction.
We may also define the following property:
\begin{definition}{Inverse-preserving Synchronizing Transformation}%Unidirectional Consistency Preservation Rule}
    Let T be a synchronizing transformation for two metamodels $\metamodel{M}{1}$ and $\metamodel{M}{2}$, consisting of the two consistency rule sets $\consistencyrelationset{CR}_{\rightarrow}$ and $\consistencyrelationset{CR}_{\leftarrow}$ and consistency preservation rules $\consistencypreservationrule{\consistencyrelationset{CR}_{\rightarrow},\rightarrow}$ as well as $\consistencypreservationrule{\consistencyrelationset{CR}_{\leftarrow},\leftarrow}$.
    T is \emph{inverse-preserving} if, and only if, executing one of the consistency preservation rules ensures that all consistency relations of the opposite direction, to which the models were consistent before, the resulting models are still consistent to.
    For one of the directions, this is given by the following (the other direction analogously):
    \begin{align*}
        & \forall \model{m}{1} \in \metamodelinstanceset{M}{1} : \forall \model{m}{2} \in \metamodelinstanceset{M}{2}: \forall \change{\metamodel{M}{1}} \in \changeuniverse{\metamodel{M}{1}} : \forall \change{\metamodel{M}{2}} \in \changeuniverse{\metamodel{M}{2}} : \\
        & 
        \forall \consistencyrelation{CR}{} \in \consistencyrelationset{CR}_{\leftarrow}:
        \tupled{\change{\metamodel{M}{2}}(\model{m}{2}),\change{\metamodel{M}{1}}(\model{m}{1})} \consistenttomath \consistencyrelation{CR}{} \\
        & 
        \Rightarrow \tupled{\consistencypreservationrule{\consistencyrelationset{CR}_{\rightarrow},\rightarrow}(\model{m}{1},\model{m}{2},\change{\metamodel{M}{1}},\change{\metamodel{M}{2}})(\model{m}{2}), \change{\metamodel{M}{1}}(\model{m}{1})} \consistenttomath \consistencyrelation{CR}{}
    \end{align*}
\end{definition}

This is a reasonable property, because the consistency relations in both directions are usually not disaligned, but only give the freedom to define different behaviors in both directions, such as more options in one direction than in the other to support different kinds of abstraction.
However, it should not be the case that preserving consistency in one direction violates consistency relations in the other direction if transformations are defined properly.

The given definition ensures that if a transformation is inverse-preserving, then executing the two unidirectional transformations one after another restore consistency to all consistency relations, because no directional rule is allowed to violate consistency that was already ensured in the other direction.
\todo{Define, how execution "one after another" looks like}

\begin{proposition}
    \todo{show that a inverse-preserving synchronizing transformation results in consistent state after both directions are executed once}
\end{proposition}

In fact, it is not easy to ensure that two unidirectional transformations are inverse-preserving, even if the consistency relations in both directions are the same, which we will also see in our evaluation of errors in \autoref{chap:errors}.
This problem, however, already arises when defining bidirectional transformations.
They may derive two unidirectional preservation rules from one specifications, thus that they are inherently inverse-preserving, or they may allow individual specification of the directions and provide some support for checking that they conform to each other, e.g., in the sense that they are inverse-preserving.
This is, however, an isolated and existing topic of research and a challenge that already has to be solved for a single bidirectional transformation rather than a network, which is why we do not discuss this problem in more detail here.

Still, there is a gap to practical approaches for defining transformations, as existing approaches do not support the synchronization scenario, i.e., they are not able to process changes in both models, but only in one of them.
Actually, existing transformations usually assume that changes are either made by the developer and are then to be propagated to the other model by the transformation, or they are made by the transformation in reaction to changes to the other model.
The case that user modify multiple models is sometimes also referred to as a synchronization scenario (although the term is sometimes even used for the simple case of incremental update).
If we consider that scenario, we will refer to it as \emph{concurrent editing} to avoid confusion.
Although the two cases have in common that both instead of only one model involved in a transformation may have been modified, they have a specific difference.
While user changes to both models can be arbitrary conflicting, changes performed by other transformations in a network should, in the best case, not be conflicting, especially if the underlying relations are compatible, as discussed in \autoref{chap:compatibility}.
For example, if a user changes an element A, whose information needs to be propagated to element B, but removes element B as well, this cannot be easily resolved, apart from potentially removing element A as well.
However, as we know from existing approaches for concurrent editing with tools like Git, conflict resolution is not an easy task~\todo{add cite for difficulty of conflict resolution}.
Such a scenario may not occur in a transformation network, because if transformations remove elements that are to be updated by others, there will obviously be some conflicts in the transformations, potentially imposed by contradictions in the underlying consistency relations.

An ordinary unidirectional consistency preservation rule looks as follows:
\begin{align*}
    \consistencypreservationrule{\consistencyrelation{CR}{},\rightarrow} : (\metamodelinstanceset{M}{1}, \metamodelinstanceset{M}{2}, \changeuniverse{\metamodel{M}{1}}) \rightarrow \changeuniverse{\metamodel{M}{2}}
\end{align*}
\todo{Go on here: map this to synchronizing ones and the inverse-preserving property}



\begin{itemize}
    \item 
    \item Define unidirectional consistency preservation rules as above
    \item Define correctness of unidirectional consistency preservation rules
    \item Say that we want to investigate what happens when we apply CPR to m1, d(m2) with m1, m2 consistent instead of to m1, m2
\end{itemize}



Even if we consider that one may only define a consistency preservation rule, which then induces the consistency relation as its image, thus being correct by construction, the rule may not behave as expected.


Problem statement: Problem is a practical one, not a theoretical one.
Ordinary transformations may be correct if used on their own (according to Stevens), but in context of a transformation network, when other transformation have modified the "target" model as well, they do not lead to a consistent result anymore, i.e., they are not correct.
Start with example of duplicated creation and overwrite.

Define ordinary transformations to take deltas in model 1 and produce deltas in model 2
Say that unidirectional synchronizing transformations take deltas in both models and update the deltas in one of them.
Refer to fine-grained formalization regarding compatibility, where consistency relations are directional, thus each directional preservation rule preserves consistency according to the consistency relations in one direction.
Having synchronizing unidirectional transformation, executing both preserves consistency to both unidirectional consistency relations. However, their must be some kind of conformance of the unidirectional transformation to each other (define how this conformance looks like!), so that executing each once does not lead to violations in the other direction. In general, that may not be possible. In fact, each unidirectional transformation should consider the unidirectional consistency relations of both directions.

So:
Ordinary unidirectional transformation for Rr: m1, m2, d1 -> d2, such that (d1(m1), d2(m2)) consistent to all relations in Rr (Rl respectively)
Synchronizing unidirectional transformation: m1, m2, d1, d2 -> d2', such that (d1(m1), d2'(m2)) consistent to all relations Rr and consistent to all relations in Rl to which is was consistent before (thus no violation of further consistency relations)

Direct consequence: Executing one transformation after the other ensures that models are consistent to alle relations in Rr and relation

Based on that, we derive how we can use languages that take deltas in model 1 and produce them in model 2 to emulate synchronizing unidirectional transformations that are able to manage deltas in both models and produce deltas in one of them.
For that, we make the case distinction and derive the creation pattern.
For each change merge case, we consider that we somehow "merge" the changes. In general, the change of the transformation to m2 will overwrite the previous change to m2. Then we consider that there is another consistency relation affected by the new change. We show whether/why not the other consistency relation can be violated by that change and discuss how to avoid that.


\begin{copiedFrom}{DocSym}

\section{Binary Transformation Interoperability}

Multi-model consistency preservation can be a achieved by combining binary transformations to graphs, %of transformations, 
with the transformations being executed transitively.
Since all binary transformations are developed independently of each other, it is necessary that they interoperate properly in a \emph{non-intrusive} way, thus without the necessity for the developer to understand and modify them, which we refer to as \emph{black-box combination}.

Even under the assumption that, in contrast to our introductory motivation, all specifications are free of contradictions, it is easy to see that problems arise when combining binary transformations by transitively executing them.
For example, consider the relations in \autoref{fig:prologue:binary_combination_example}.
If a component is added to the \ac{ADL}, causing a \ac{UML} class creation due to \ref{fig:prologue:binary_combination_example:R1}, which in turn causes a Java class creation due to \ref{fig:prologue:binary_combination_example:R2}, the transformation for relation \ref{fig:prologue:binary_combination_example:R3} does not know that an appropriate class was already created, if the transformations are treated as black boxes.
Consequently, the transformation will create the same class again, which may override the existing one, depending on the implementation and execution order.
A simple solution for this example would be to have all transformations use a common trace model and check for existing elements before creating them in a transformation.
Nevertheless, independently developed transformations will usually not assume that %this only applies if the transformation considers possibly preexisting transformation results, which it will not do in general if it does not assume other transformations to create corresponding elements.
other transformations may already have created corresponding elements.
Additionally, the trace model must allow the transformation engine to retrieve transitive traces.
However, it is unclear if transitive resolution of traces can always be performed, as it can depend on whether the transitive trace belongs the considered consistency relation or another.
%If, in another scenario, the transformation in the example was actually supposed to create an additional class, it would have to ignore the existing trace.

As can be seen in the example, especially the correct handling of trace information in interdependent transformations has to be researched.
This applies not only to element creations, but also other change types, such as attribute or reference changes, especially if they are multi-valued.
In our thesis, we will therefore apply transitively executed binary transformations in different case studies to identify these and potential further problems.
We then want to come up with a catalog of such problems %preventing the black-box combination of transformations 
together with solution patterns for them.
For example, to avoid duplicate element creations, a simple pattern could be to always check for already existing traces for that consistency relation in the transformations.
In consequence, the integration of those patterns into a transformation language or the application of them as a transformation developer is supposed to achieve black-box combinability of the transformations.

\end{copiedFrom} % DocSym


\begin{copiedFrom}{ICMT}

To ensure that a network of \acp{BX} operates properly, potential mistakes %, as identified in the previous section, 
must be avoided.
%\todoHeiko{Klarmachen, dass wir hier keine vollumfänglichen Lösungsstrategien präsentieren, sondern das, was man im Prinzip auf den Ebenen tun muss. Nur für die unterste Ebene gibt es ein Konzept}
We evaluate our categorization regarding correctness and completeness %for that 
in a case study that combines independently developed transformations.
In that case study, we classify occurring failures with our categorization and trace them back to a causal mistake.
To identify whether such a classification is correct, we need to be able to fix the mistake and validate that the failure disappears.
%To investigate whether the classification of revealed mistakes is correct, we need to be able to fix them. %the classification of a mistake was correct and if another mistake was potentially hidden by the fixed one.
%Therefore, we do not provide complete solution strategies, but instead discuss how mistakes at the different levels can be avoided in general as our contribution \ref{contrib:avoidance}.
Therefore, we discuss general strategies to avoid mistakes at the different levels as our contribution \ref{contrib:avoidance} and apply them in the evaluation.
%, we discuss how mistakes at the different levels can be avoided in general, but do not provide complete solutions % solution strategies
%in this work.

%At the system level, mistakes can only be avoided by careful requirements elicitation. 
%Since occurring mistakes on that level represent non-conformance with a usually informal notion of consistency, such mistakes cannot be automatically avoided or detected.
At the global level, mistakes occur due to non-conformance with an informal notion of consistency and %cannot be detected automatically but 
can only be avoided by careful requirements elicitation. 
We therefore have to assume that global level mistakes are reliably avoided by the developers.
Analytic approaches~\cite{klare2018docsym}
can ensure that specifications at the modularization and operationalization level are free of faults.
%This can be applied on both the modularization and the operationalization level.
Nevertheless, %under the assumption that transformations are developed independently, 
the drawback of such an approach is that it works a-posteriori, when transformations are combined to a network. %, so transformations would have to be adapted %after their specification 
%when they are combined to a network
We, in contrast, want to achieve avoidance of interoperability issues a-priori, so that transformations can be developed independently and combined afterwards.
It is easy to see that mistakes at the modularization level cannot be avoided a-priori. 
%If modular transformations are developed independently, 
Ensuring that transformations are non-contradictory %, i.e. that they rely on the same notion of a global consistency specification, 
would require developers to have knowledge about the other transformations, which breaks the assumption of independent development.
%This breaks our assumption that developers have restricted domain knowledge, each defining one modular consistency specification.
%
Finally, mistakes regarding element matching at the operationalization level are domain-independent. 
This enables the development of generic mechanisms to ensure interoperability at the operationalization level by construction, without knowing about other transformations.

In the following, we discuss one strategy to avoid mistakes at the modularization and one to avoid those at the operationalization level.
Developers can use these strategies to build networks that are free of faults, or can use them to fix mistakes if failures occur.

% MOVED TO BEGINNING OF SECTION
% We evaluate our categorization in a case study combining independently developed transformations. 
% For that, we need to fix mistakes in order to investigate whether their classification was correct. %the classification of a mistake was correct and if another mistake was potentially hidden by the fixed one.
% Therefore, we do not provide complete solution strategies, but instead discuss how mistakes at the different levels can be avoided in general as our contribution \ref{contrib:avoidance}.

%We therefore assume that mistakes on modularization level are avoided as well and investigate, under this assumption, whether the operationalization can be develop interoperable by construction.

% \begin{itemize}
%     \item Problems on all three levels must be avoided
%     \item On all levels, possibility to use model checking for finding faults when combining a set of transformations (cf. \cite{klare2018docsym}
%     \item Detecting mistakes on level 1 is hard, because one would have to compare the specification against a natural, usually unspecified notion of consistency
%     \item Drawback: works a-posteriori, so transformations would have to be adapted afterwards to be used together
%     \item Therefore: approach for a-priori avoidance of interoperability issues necessary
%     \item Problem: on level 2 no a-priori avoidance of problems possible, or overall knowledge from level 1 necessary -> breaks our assumption of independent development
%     \item But: On level 3 possibility to develop mechanisms and patterns to ensure interoperability on that level by construction, because it only concerns the operationalization of specifications. In contrast to the consistency specifications, which are domain specific, the operationalization follows a generic pattern for which generic interoperability solutions can be derived
%     \item We assume interoperability on level 2 for our approach so that there are no interactions between mistakes on the level 2 and 3 (no precise enough)
% \end{itemize}

\end{copiedFrom} % ICMT


\section{Ensuring Interoperability of Executed Transformations 
    \pgsize{15 p.}
}
Goal: Avoidance strategies for interoperability mistakes, i.e. achieving synchronization of transformations (MA Torsten / Timur)
\label{chap:prevention:interoperability}

\begin{copiedFrom}{ICMT}

% FORMERLY: \subsection{Matching Elements in Operationalizations}
\subsection{Matching Elements}
\label{chap:prevention:interoperability:matching}

To avoid failures due to mistakes at the operationalization level, transformations must respect that other transformations may have already created elements.
In the binary case, this is unnecessary.
A single incremental \ac{BX} can assume that elements are either created by the user, %and then are input of the transformations
or were created by the transformation itself.
To identify corresponding elements, transformation languages usually use trace models, which are created by the transformations.
When \acp{BX} are combined to networks, %elements may also be created by other transformations.
%In consequence, 
direct trace links may be missing because a sequence of other transformations created the elements and trace links only indirectly across elements in other models.
%Thus, it is necessary to establish direct trace links between corresponding elements.´
In this scenario, corresponding elements can be matched by information at three levels:
%Such element matching can be performed on three levels:
\begin{enumerate}
    \item \emph{Explicit unique}: The information that elements correspond is unique and represented explicitly, e.g., within a trace model. %Existing transformation languages usually use this technique.
    \item \emph{Implicit unique}: The information that elements correspond is unique, but represented implicitly, e.g., in terms of key information within the models such as element names. %types and element names.
    \item \emph{Non-unique}: If no unique information exists, heuristics must be used, e.g. based on ambiguous information or transitive resolution of indirect trace links.
\end{enumerate}
\todo{Give examples for each case to show that they actually occur}

Indirect trace links, which link elements transitively across other models, usually exist for elements that correspond, because other transformations have already created them.
Nevertheless, indirect trace links cannot be used to unambiguously identify such elements.
An element can correspond to multiple elements in another model, which is why most transformation languages offer tagging of trace links with additional information to identify the correct element.
%For example, a component in an architecture description could be mapped to two classes in an object-oriented design, one providing the component implementation and one providing utilities.
%The relevant corresponding element can be retrieved if the traces are tagged with the information that one class is the implementation and one is a utility.
For example, a language may tag trace links with the transformation rule they were instantiated in.
This is helpful in the bidirectional case, but when links are resolved transitively, these tags have been created by other, independently developed transformations, and are thus unknown.
%If such tags would be considered, transformations would depend on tags of other transformations and could thus not be developed independently anymore.
Therefore, resolving indirect trace links is only a heuristic, but does not unambiguously retrieve corresponding elements.

% Explain how to match rules on three different levels, what the levels can provide etc.

% \begin{enumerate}
%     \item Direct Correspondences
%     \item Key information
%     \item Heuristics: Indirect correspondences, potentially ambiguous information
% \end{enumerate}

Finally, it is up to the transformation engine or the transformation developer %, depending on the provided abstraction level, 
to ensure that elements are correctly matched.
In contrast to the bidirectional case, direct trace links cannot be assumed in case of networks of \acp{BX}.
Therefore, key information within the models must always be considered to identify matching elements.
Whenever direct trace links or unique key information exists, relevant elements can be unambiguously matched.
In all other cases, heuristics must be used, which potentially leads to failures.

\end{copiedFrom} % ICMT


\begin{insight}[Synchronization]
    When constructing synchronizing transformations, both models may have been and need to be modified in contrast to ordinary bidirectional transformations, which update only one of the models.
    Having ordinary transformations and consistency preservation rules for both directions, executing only one or one after another does not necessarily lead to a consistent result, thus the transformations are not correct in context of a transformation network when both models may have been modified.
    We, however, found that their sequential execution leads to a consistent result for all possible combinations of changes, if identity of elements is handled correctly.
    In contrast to ordinary incremental transformation, which assume that elements were created by the user or the transformation itself, in a transformation network other transformation may have already created appropriate elements.
    In consequence, a transformation needs to identify if an element already exists upon its creation.
    To achieve that, it needs to define key information for identifying that element.
    With that addition, executing ordinary incremental transformations in both directions, each of the consistency preservation rules being correct, the emulated synchronizing transformation is correct.
    In consequence, synchronizing transformations can be constructed with existing transformation languages not considering synchronization and without knowing about other transformations to combine them with.
\end{insight}

\todo{Is this true? We can have cycles there, so it may not be correct. Just consider the confluence case?}