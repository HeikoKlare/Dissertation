\begin{copiedFrom}{SoSym MPM4CPS}

\subsection{Finding Redundancies in Transformations}
\label{chap:prevention:compatibility:redundancies}
\todo{Originally this was a section instead of a subsection, thus it does not fit into the structure anymore}

In the decomposition procedure, enumerating possibly redundant predicates and proving that such predicates are redundant are uncoupled tasks. The latter task can be regarded as a black box embedded in the former one: only the result of the redundancy test matters. As a consequence, the decomposition procedure allows the use of various strategies to prove that a predicate is redundant. There is no perfect strategy due to the limitations on the decidability of OCL expressions. In this article, we opt for a strategy that allows the decomposition procedure to be fully automated. We first discuss how predicates can be compared to prove redundancy. Then, an approach that translates OCL constraints (in predicates) to first-order logic formulae and uses an automated theorem prover is introduced. Finally, the translation rules from OCL to first-order logic are presented along with their limitations.

\subsubsection{Intensional Comparison of Predicates}

Whatever the strategy, the \textit{redundancy test} takes a couple $(E, \tupled{E_1, \dots, E_n})$ as an input and returns \textsc{true} if the predicate $E$ was proven redundant because of the sequence of predicates $\tupled{E_1, \dots, E_n}$, \textsc{false} otherwise. As stated in \autoref{def:leftequalredundancy}, a consistency relation is considered left-equal redundant if its removal from the set of consistency relations leads to an equivalent set and relates the same kinds of elements at the left side. For the relation to be redundant, there must be an alternative sequence of relations that already fulfills the role of the initial relation. This also applies to the property graph: for a predicate to be removed, there must exist another sequence of predicates relating the same properties that is strict enough not to weaken the consistency specification. Weakening the consistency specification means allowing models that would have been considered non-consistent before the removal of the predicate. 
Since we only consider predicates that relate the same properties the additional requirement of left-equal redundancy in comparison to general redundancy in \autoref{def:redundancy} is always fulfilled. In the following, we thus only discuss redundancy rather then left-equal redundancy, as it is always given by construction.
As illustrated in \autoref{fig:correctness:prevention:comparison_validinstances}, a predicate $E$ can only be removed if all instances matching the predicate also match predicates $\tupled{E_1, \dots, E_n}$.

Therefore, a redundancy test is equivalent to the comparison of two sets of instances. However, a predicate may be fulfilled by infinitely many model elements. For example, the predicate ensuring that the income of a person and the salary of an employee are equal is valid for infinitely many integer pairs. It is impossible to compare these sets element per element (i.e., extensionally). 
Since consistency relations in the decomposition procedure are defined intensionally, by means of predicates, anyway, the redundancy test compares sets in their intensional specification.
%Consequently, the redundancy test must compare sets intensionally (i.e., by comparing the way sets are defined). This is a consequence of the fact that consistency relations in the decomposition procedure are also defined intensionally, by means of predicates. 
As a result, the redundancy test uses the description of the possibly redundant predicate and the candidate alternative sequence of predicates to decide whether the predicate is redundant.  
In QVT-R, predicates are expressed as OCL constraints. As part of the construction of the property graph, these constraints are already represented as hyperedge labels. That is, comparing predicate definitions in the decomposition procedure amounts to perform a static analysis of these labels and QVT-R relation conditions (\texttt{when} and \texttt{where} clauses). In order to prove redundancy, the static analysis has to rely on a rigorous framework to reason about OCL constraints. This is provided by various formal methods in the field of software verification.

\begin{figure}
    \centering
    \input{figures/correctness/prevention/comparison_of_valid_instances}
    \caption{The hyperedge $E$ is redundant, because all instances valid according to $E$ are already valid according to the alternative sequence $E_1, \dots, E_n$ of hyperedges.}
    \label{fig:correctness:prevention:comparison_validinstances}
\end{figure}

\subsubsection{Encoding Redundancy in First-Order Formulae}

In this article, the strategy we use to prove redundancy is based on first-order logic, a well-suited and expressive mathematical language for decision procedures. The idea is to set up a first-order formula that is valid (i.e., true under every interpretation) if and only if the redundancy test is positive. To this end, the formula embeds OCL expressions (translated into first-order logic as well) contained in predicates. Then, a theorem prover evaluates the validity of the formula. 
%Theorem provers are software programs able to prove the validity of a first-order sentence.

The choice of first-order logic is motivated by the nature of OCL: there exists a general translation of OCL into first-order logic~\cite{beckert2002ocltranslation}. This result was later refined in~\cite{berardi2005umlreasoning} in order to show that OCL formulae are essentially full first-order formulae. What this means is that OCL does not form a fragment of first-order logic and needs all its expressiveness. First-order logic being undecidable in general, this also implies that not all redundant formulae can be proven valid. Therefore, the results obtained by the decomposition procedure are highly dependent on the performance of the theorem prover. Even with quantifiers and variables, the gap between programming languages and first-order sentences remains significant. OCL is composed of arithmetic operations, strings, arrays, etc. The meaning of language constructs must also be integrated into formulas. To this effect, it is possible to replace binary variables in first-order formulae with a Boolean sentence expressed in a given theory. Theories use all kinds of objects such as strings, floats, sequences, etc. With theories, the satisfiability problem equates to assign values to variables in first-order sentences such that the evaluation of sentences makes the whole formula \textsc{true}. For instance, the formula $(a \times b = 10) \wedge (a + b > 0)$ is satisfiable given the assignment $\{a = 2, b = 5\}$.
This extension is known as \textit{satisfiability modulo theories} (SMT). First-order formulae for the SMT problem are called \textit{SMT instances}. Some theorem provers come with built-in theories, they are thus called \textit{theory-based theorem provers}. In the context of the decomposition procedure, we translate constructs in OCL constraints with corresponding constraints into built-in theories of the prover. By doing so, the mapping between OCL and first-order logic is easier to achieve. % OUTLINE 2 parts

\paragraph{Modeling as a Horn Clause}

For any two models, consistency depends on condition elements in predicate-based consistency relations, which themselves depend entirely on property values for which predicate functions evaluate to \textsc{true}. As a result, redundancy can be tested by comparing descriptions of predicate functions. This information is contained in the input of the redundancy test. Let $\pi = (\propertysettuple{P}{\classtuple{C}{l}}, \propertysettuple{P}{\classtuple{C}{r}}, f_\pi)$ be a predicate for two class tuples $\classtuple{C}{l}$ and $\classtuple{C}{l}$. During the construction of the property graph, a hyperedge composed of all properties in $\propertysettuple{P}{\classtuple{C}{l}}$ and $\propertysettuple{P}{\classtuple{C}{r}}$ is labeled with the description of the predicate function $f_\pi$.

In terms of predicate functions, the predicate $E$ can be replaced by a sequence of predicates $\tupled{E_1, \dots, E_n}$ under the following condition: for any set of models, $f_E$ evaluates to \textsc{true} whenever $f_{E_1} \wedge \dots \wedge f_{E_n}$ evaluates to \textsc{true}. If this condition is met, the consistency specification is neither strengthened nor weakened after the removal of $E$. The specification is not strengthened because the removal of a predicate can only allow more sets of models to be consistent. It is not weakened either because all property values that match $\bigwedge f_{E_i}$ also match $E$. As a consequence, $E$ is redundant. That is, solutions of $\bigwedge f_{E_i}$ form a subset of solutions of $E$. This is consistent with~\autoref{fig:correctness:prevention:comparison_validinstances}. The redundancy test can be encoded as a formula in the following way:
\begin{align*}
    \formulaskip &
    (f_{E_1} \wedge \dots \wedge f_{E_n}) \Rightarrow f_{E}
\end{align*}

The formula above is called a \textit{Horn clause}. Horn clauses form an important fragment of logic in the field of automated reasoning. Terms on the left-hand side of the clause are called \textit{facts}, whereas the term on the right-hand side is called \textit{goal}. The implication represents the deduction of the goal from the facts. The assignment of values to variables in the Horn clause also models the instantiation of properties (i.e., the assignment of property values). If the Horn clause is valid, then the alternative sequence of predicates can replace the initial predicate whatever the instantiation of metamodel elements (i.e., whatever the models).

One last detail is to be taken into consideration for the translation of predicate functions. Horn clauses are usually described without quantifiers. In a Horn clause, all variables are implicitly universally quantified. Given that predicate functions are made up of OCL expressions, they contain local QVT-R variables. Consistency depends upon pattern matching, i.e., the existence of a valid assignment of variables. Therefore, QVT-R variables in the goal clause have to be existentially quantified.

\begin{example}
\autoref{fig:correctness:prevention:dual_propertygraph_re} depicts the dual of the property graph derived from the motivational example in \autoref{fig:prologue:three_persons_example}. The dual contains four connected components, including three with one predicate only. Compatibility is already proven for these three components because they are trivial trees. The other component is made up of three predicates and contains a cycle ($\{1, 2, 3\}$).
Let $3$ be the possibly redundant predicate. Then, the alternative combination of predicates is composed of $1$ and $2$. This leads to the following formula in which $3$ is the goal and $1$ and $2$ are the facts:
\begin{align*}
    &\left[(\propdisplay{\small Person::firstname} = f1) \wedge (\propdisplay{\small Person::lastname} = l1)\right.\\
    &\left.\formulaskip \wedge (\propdisplay{\small Resident::name} = f1 + ``\text{\textvisiblespace}" + l1)\right]\\
    \wedge & \left[(\propdisplay{\small Person::firstname} = f2) \wedge (\propdisplay{\small Person::lastname} = l2)\right.\\
    &\left.\formulaskip \wedge (\propdisplay{\small Employee::name} = f2 + ``\text{\textvisiblespace}" + l2)\right]\\
    \Rightarrow & \left(\exists n : (\propdisplay{\small Resident::name} = n) \wedge (\propdisplay{\small Employee::name} = n)\right)
\end{align*}
QVT-R variables have been renamed to avoid conflicts. This is necessary because they are no longer isolated as they were before in two distinct QVT-R relations. According to the SMT solver, the formula above is valid. Therefore, predicate $3$ can be removed from the property graph and its dual. There are then only two predicates left in this component. It is inherently compatible. As all independent subsets of predicates are compatible, the consistency specification is compatible.
\end{example}
    
\paragraph{Redundancy Test}

\begin{figure*}
    \centering
    \resizebox{\linewidth}{!}{\input{figures/correctness/prevention/redundancy_test}}
    \caption{Redundancy test, from OCL expressions to the SMT solver}
    \label{fig:correctness:prevention:redundancytest}
\end{figure*}

Redundancy can be proven by checking that the Horn clause derived from predicate functions is valid (i.e., true under every interpretation). Because the whole decomposition procedure is automated, the theorem prover, namely an SMT solver, embedded in the procedure is also automated. 
The solver takes an SMT instance as an input and answers whether it is satisfiable insofar as possible.
Proving that a Horn clause $H$ is valid is actually equivalent to proving that its negation $\neg H$ is unsatisfiable. Therefore, we prove that the SMT instance $f_{E_1} \wedge \dots \wedge f_{E_n} \wedge \neg f_{E}$ is unsatisfiable. The SMT solver can provide three possible outcomes:

\begin{description}
    \item[Satisfiable.] If $\neg H$ is satisfiable, then $H$ is not valid. This means that an interpretation exists (i.e., an instantiation of properties) that fulfills the possibly redundant predicate but not the alternative sequence of predicates. Thus, the predicate is not redundant and cannot be removed.
    \item[Unsatisfiable.] If $\neg H$ is unsatisfiable, then $H$ is valid. When the alternative sequence is fulfilled, so is the predicate. It is redundant and can be removed.
    \item[Unknown.] First-order logic being undecidable, not all formulae can be proven valid. When a theorem prover is unable to evaluate the satisfiability of a formula, it returns \textit{Unknown}. By application of the conservativeness principle, the redundancy test is considered negative. As a result, the predicate is not removed.
\end{description}

\subsubsection{Translation}

Translation refers to the process of mapping OCL expressions of QVT-R relations to SMT instances. In the context of the decomposition procedure, this is facilitated by the fact that QVT-R uses a subset of OCL called \textit{EssentialOCL}~\cite{qvt}, a side-effect free sublanguage that provides primitives data types, data structures and operations to express constraints on models. Many constructs of OCL have a direct equivalent in theories of the theorem prover. More complex constructs can often be mapped through the combination of primitive constructs. Note that there also exist constructs that cannot be translated. Language constructs of SMT solvers are described using the SMT-LIB specification, a standard that provides among others an input language for solvers~\cite{smtlib2017}. This language uses a syntax similar to that of Common Lisp. The translation is recursive: each OCL expression depends on the translation of its subexpressions. A complete reference of translated constructs has been developed in a master's thesis~\cite{pepin2019ma}.

\paragraph{Primitive Data Types}

OCL defines five primary data types: integers, reals, booleans, strings and unlimited naturals. These data types are mapped with Ecore when parsing QVT-R transformations. The mapping between Ecore data types and Z3 data types (called \textit{sorts}) is described in \autoref{tab:primitivedatatypes}. It is straightforward, except for \textit{UnlimitedNatural}, a data type to represent multiplicities. \textit{UnlimitedNatural} and \textit{Integer} are different in that the former can take an infinite value whereas the latter cannot. IntSort in Z3 cannot be infinite. In this case, a workaround is to represent an \textit{UnlimitedNatural} as a couple (IntSort, BoolSort) where the value equals $\infty$ if the Boolean is \textsc{true}. %, or equal to the integer otherwise.

\begin{table}
\renewcommand{\arraystretch}{1.2}%
\setlength\tabcolsep{2 pt}
\begin{tabular}{L{2.4cm} L{2.4cm} L{3.0cm}}
\toprule
\textbf{OCL Data Type} & \textbf{Ecore Data Type} & \textbf{SMT Data Type} \\
\midrule
    Integer & \texttt{EInt} & IntSort \\
    Real    & \texttt{EDouble} & RealSort \\
    Boolean & \texttt{EBoolean} & BoolSort \\
    String  & \texttt{Estring} & StringSort \\
    UnlimitedNatural & \texttt{EInt} & IntSort \textit{(without infinity)}\\
\bottomrule
\end{tabular}
\caption{Mapping between primitive types representations} % in OCL, Ecore and Z3}
\label{tab:primitivedatatypes}
\end{table}

\paragraph{Data Structures}
Primitive data structures in OCL are called \textit{collections}. There are four types of collections based on the combination of two features, the first defining whether elements are ordered and the second whether duplicate elements are allowed. Among those four collection types, two are currently supported: sequences (ordered, duplicates allowed) and sets (non-ordered, no duplicates). In QVT-R, collections are used either as literals or as types for a special kind of properties: role names.

\subparagraph{Collection Literals}
Collection literals are OCL expressions that represent data structures with constant and predefined values (e.g., \lstinline|Sequence{1, 4, 9}| or \lstinline|Set{2, 5}|). In SMT solving, the fundamental theory to represent a collection of values is the theory of \textit{arrays}. Arrays are maps that relate a set of indexes (domain) and a set of values (codomain). They are immutable, purely functional data structures. Unlike OCL data structures, there is no notion of size in arrays. To overcome this limitation, we translate collections to algebraic data types in the SMT input language. Data types are composed of an array (collection values) and an integer storing the collection size. It is noteworthy that collection literals rarely occur in consistency relations. In general, collections are groups of objects resulting from references in metamodels.

\subparagraph{Collections from Role Names}
In QVT-R property template items, properties are either attributes (like \propdisplay{Person::name}) or role names. A role name is an alias for objects at the end of the reference owned by the class of the pattern. If the upper bound of the reference multiplicity is greater than one (e.g., \texttt{0..*}), then the role name may represent a collection of objects. The nature of the collection depends on whether the end is ordered or unique or both. Even if the content of the collection is unknown, it is possible to reason about role names by means of the theory of \textit{uninterpreted functions}~(UF). A role name $r$ of a class $c$ can be represented as a function of $c$ (e.g., $r(c)$). By abstracting the semantics of functions, uninterpreted functions help to reason about model elements without knowing all their details. For example, two role names are equal if both belong to objects that have been proven to be equal themselves.

\paragraph{Operations}

OCL also provides many operations on primitive data types and data structures, such as arithmetic operations or string operations. Following the object-oriented structure of OCL, every operation has a source and zero or more arguments. For example, the \texttt{+} operation denotes an addition when the source is an integer but a concatenation when the source is a string.
We translated operations regarding arithmetics, booleans, conversion operators, equality operators, order relations, collections and strings~\cite{pepin2019ma}.

%\paragraph{Untranslatable Operations}
Some OCL operations are said to be \textit{untranslatable}, because it is impossible to find a mapping between them and features of state-of-the-art SMT solvers. As a result, there are QVT-R relations that cannot be processed by the decomposition procedure. For instance, the string operations \lstinline{toLower} and \lstinline{toUpper} cannot be easily translated without numerous user-defined axioms in current SMT solvers. Although decision procedures for such a case exist~\cite{veanes2012transducers}, they are not yet integrated into solvers.


\subsubsection{Summary}
In this section, we have presented an approach to evaluate redundancy of a predicate in a property graph (respectively its dual) for the decomposition procedure, also depicted in \autoref{fig:correctness:prevention:redundancytest}.
The approach translates the OCL expressions of predicates into logic formulae and generates Horn clauses for a potentially redundant predicate and its alternative predicates.
If an SMT solver proves unsatisfiability of that clause, the checked predicate is redundant and can be removed.

\end{copiedFrom} % SoSym MPM4CPS