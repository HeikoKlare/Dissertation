\chapter{Evaluation and Discussion 
    \pgsize{60 p.}
}
\label{chap:correctness_evaluation}

\mnote{Several statements validated by proof}
In the preceding chapters \ref{chap:correctness}--\ref{chap:errors}, we have discussed several aspects of a well-defined notion of consistency and correctness of its preservation in transformation networks.
Based on the assumptions we made, we were able to prove several statements regarding decidability of problems, correctness, and the properties and effects of approaches we proposed, such as the analysis of compatibility or the construction of synchronizing transformations.
Thus, several insights presented so far have been validated by proof.
Still, there are several interesting and relevant questions that we will validate by empirical evaluation at case studies.
These especially concern the applicability of our approaches and also, at least implicitly, the appropriateness of our formalism, which we evaluate in case studies.

\mnote{Consistency and correctness notion}
We do not provide an evaluation of the consistency and correctness notions proposed in \autoref{chap:correctness}.
That formal foundation was derived from our motivation and assumptions by argumentation.
Thus, a meaningful evaluation would be a user study in which the reasonability of the assumptions we made regarding the process of defining consistency in transformations networks is validated.
Since we have based our work on well-motivated assumptions and since such an evaluation would be overly complex, we have decided not to perform it as part of this thesis and focus on statements that we can derive from the assumptions in Chapters~\ref{chap:compatibility}--\ref{chap:errors}.

\mnote{Compatibility evaluation}
The compatibility notion and the formal approach to validate it for given consistency relations that we have proposed in \autoref{chap:compatibility} is proven correct.
The practical approach was derived from the formal one such that it is also supposed to be correct, although this is not formally proven.
We apply the approach to a case study of several sets of consistency relations to first evaluate correctness, which especially concerns correctness of the implementation but also validates the construction of the practical out of the formal approach.
Second, we evaluate applicability in terms of the degree of conservativeness, i.e., how often the approach is not able to prove compatibility although compatibility is given.

\mnote{Error categorization and synchronization evaluation}
The properties of a bidirectional transformation to be synchronizing were proven to be correct in \autoref{chap:synchronization}.
The approach to achieve these properties was, however, derived by argumentation.
In a second case study, we thus combine existing transformations, which were not supposed to be used in a transformation network and thus are not synchronizing, nor fulfill other correctness notions of transformation networks.
We use this case study to evaluate completeness and correctness of the categorization of errors presented in \autoref{chap:errors} and also identify the relevance of the different mistake types regarding how often they occur and thus how prone they are to be made by transformation developers.
We also evaluate practical relevance of the orchestration problem by investigating how often the orchestration fails because of that problem instead of actual mistakes in the transformations.
Additionally, we apply our approach for making ordinary transformation synchronizing, depicted in \autoref{chap:synchronization}, regarding correctness, i.e., whether it actually resolves failures due to transformations not being synchronizing. % it is able to achieve the necessary property of transformations to be synchronizing.
We validate its applicability regarding whether it is able to resolve all faults due to missing synchronizing.
We will especially find that transformations not being synchronizing is the most relevant mistake type, that most other mistakes are due to incompatibilities, and that, at least in the considered case studies, the orchestration problem is not practically relevant.
Finally, our approach for achieving synchronization of ordinary transformations is able to resolve most of the issues, at least in the considered case studies.

\mnote{Orchestration evaluation}
Finally, we haven proven several statements regarding the orchestration of transformations in \autoref{chap:orchestration}, especially the undecidability of the orchestration problem.
We have also proven correctness of the proposed conservative application algorithm.
The fulfillment of the motivational property of the algorithm to support the process of finding errors when the algorithm fails to find consistent models is, however, only argued.
We thus provide a scenario-based discussion to evaluate the usefulness of the strategy.

% \mnote{Evaluation of applicability by empirical evaluation in case study}
% This involves the investigation of how often the conservative algorithms for analyzing compatibility and orchestrating transformations succeed and whether the approach for constructing synchronizing transformations is sufficient.
% In addition, we will identify how relevant the different correctness notions are regarding how prone they are to not being fulfilled and thus the probability that developers may make different kinds of mistakes.
% We will especially find that transformations not being synchronizing is the most relevant mistakes that can be made and that most other mistakes are due to incompatibilities.
% Thus, applying our approaches for constructing synchronizing transformations and analyzing compatibility would solve most issues, at least in the considered case studies.

\mnote{GQM plans}
For each of these topics, we provide a plan according to the \gls{GQM} approach, for which the original idea was presented by \textcite{basili1984GQM-TSE}.
We define goals that we want to achieve with our evaluation, derive questions that we answer to identify whether we have achieved the underlying goal, and define metrics whose results we use to get a quantitative measure for answering the questions.

%\todo{Discuss that the formalism is proven correct. We only valide the error classification and the prevention 
%strategies.
%Additional goal: Find how likely specific kinds of errors are to know how relevant the different error categories are.
%}

%We have shown that we cannot define an orchestration that is always correct and optimal. However, we presented techniques to optimize as far as possible.
%We evaluate here, in how many cases this is sufficient in practice. To do so, we have the case study (Torsten / Timur) where we identified issues. We map them to our approaches and show that at least in this case study almost all problems would have been detected with them.

% \begin{itemize}
%     \item Correctness notion argued, nothing to evaluate: could be evaluated in user study that assumptions for that notion regarding the process are reasonable, but out of scope
%     \item Compatibility (Correctness and Usefulness/Conservativeness): evaluated regarding correctness and degree of conservativeness in dedicated case study in first section. Dedicated case study because other transformation language (QVT-R) with focus on relations. Open question how to extract the relations from other transformation specifications. Operational (imperative) specifications lack explicit relation specification. Maybe derive them from fixed points, but unclear how to evaluate them. In worst case, can only be applied to declarative languages (threat to validity / limitation in evaluation)
%     \item Errors and Synchronization (Completeness, Correctness, Relevance): Case study in which we identified errors when combining independently developed transformations and check whether the classification is correct. We correct the mistakes according to the categorization and especially applied the patterns for making the transformation synchronizing to find whether that solves the problem of transformations not being correct in the context of a network. Additionally, we want to find how often specific types of errors occurs to have an indicator for their severity and how relevant the errors we solve by our synchronization pattern are.
%     \item Orchestration (Usefulness): Regarding orchestration, we have proven the proposed strategy to be correct. We, however, provide a scenario-based discussion to evaluate the usefulness of the strategy to find the cause for a network not being able to resolve a change.
% \end{itemize}

% \todo{Vorgeschlagene Struktur jedes Kapitels:
% 1. Goals and Methodology
% (2. Case Study)
% 3. (Prototypical) Implementation
% 4. Results
% 5. Discussion mit Threads
% - Limitations dann einmal allgemein diskutieren, nicht pro Thema
% }

\mnote{Publication of evaluations}
We have published parts of these evaluations in previous work~\owncite{klare2019icmt,klare2020compatibility-report,gleitze2021orchestration-FASE}. The case studies for our error categorization and achievement of synchronization have been conducted in two Master's theses~\owncite{syma2018ma,saglam2020ma}. The case study for validating the approach to prove compatibility has been conducted in another Master's thesis~\owncite{pepin2019ma}. We will explicitly refer to the according publications in the individual evaluations.

\input{sections/3_correctness/3610_evaluation-compatibility.tex}
\input{sections/3_correctness/3620_evaluation-errors.tex}
\input{sections/3_correctness/3630_evaluation-orchestration.tex}
\input{sections/3_correctness/3640_evaluation_conclusion.tex}

