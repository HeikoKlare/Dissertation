\chapter{Future Work
    \pgsize{5 p.}
}
\label{chap:futurework}

We have discussed different topics that were assigned to the areas of constructing correct transformation networks and improving quality of transformation networks.
In both areas, we have identified multiple limitations and other starting points for future work, which we present in the following.


\section{Correctness of Transformation Network}

For the correctness of transformation networks, we have presented a formal notion based on a well-defined formalism and derived different properties of correct transformation networks.
This thesis especially provided a general formalization of the overall problem and a division into smaller sub-problems, for which it provided individual contributions and insights.
Based on them, each of the topics provides much space for future work, which we especially derive from the limitations discussed in the evaluation in \autoref{chap:correctness_evaluation}.
We first discuss two general topic for future, which arise from the overall assumptions of this thesis, before we proposed specific topics for the discussed sub-problems.

\paragraph{Multiary Relations and Transformations}
\label{chap:futurework:correctness:multiary}
As discussed in \autoref{chap:introduction:objective:assumptions}, we assume a development process in which modular transformations are developed and reused independently.
In \autoref{chap:correctness}, we have then introduced our central formalism, based on which we defined correctness of transformation networks.
We decided to focus on transformation that rely on a binary notion of consistency.
While this is a limitation, since not every multiary consistency relation can be decomposed into binary ones (see~\cite{stevens2020BidirectionalTransformationLarge-SoSym}), for most considerations we made this limitation is actually only for easy of understanding but without loss of generality.
Thus, most statements also apply to networks of transformations, of which each related more than two models.
We must, however, validate in future work that and for which statements this generalization is valid.

\paragraph{Concurrent Editing}
\label{chap:futurework:correctness:concurrent}
We explicitly assumed that a user only changes one model, for which consistency has to be preserved.
Although, from a conceptual point of view, networks of synchronizing transformations can also handle concurrent edits in multiple models, as the transformations need to be synchronizing anyway, the process of dealing with problems must be different.
While failures that occur without concurrent user edits in different models indicate faults within the transformations, concurrent edits can also lead to failures just because conflicting changes were made.
Thus, our contributions do not yet solve the problem of concurrent edits.
This topic requires further investigation in future work, also incorporating existing work on considering concurrent updated in single transformations, such as \cite{xiong2013SynchronizingConcurrentUpdates-SoSym,xiong2009parallelUpdates-ICMT}.


\subsection{Compatibility}

In \autoref{chap:correctness_evaluation:compatibility:discussion:limitations}, we have discussed several limitations of the current realization and implementation of the proposed approach to analyze compatibility of consistency relations, which represent relevant opportunities for future work.
In the following, we first discuss future work at the conceptual core of the idea, processes to use it and finally its realization.

\paragraph{Effects on Orchestration Problem}
\label{chap:futurework:correctness:compatibility:orchestration}
In \autoref{chap:compatibility:informal}, we have motivated the defined notion of compatibility with the goal of reducing the ability of transformations not to find consistent models after changes.
We have discussed the resulting problem more precisely as the orchestration problem in \autoref{chap:orchestration}.
In fact, compatibility ensures that the ability of not finding a consistent orchestration due to the orchestration problem decreases, thus reducing the ability that transformation network fail or do not terminate.
While we have shown this at examples in this work, we will empirically evaluate in future work how compatibility affects the ability of transformation networks to find consistent models and, if possible, even formally prove and analyze that effect. 

% Relation to issues in consistency repair: Further issues were identified in \cite{klare2019icmt}: This work is concerned with compatibility of consistency relations. Transformations also contain repair routines that restore consistency. They depend on their relations being compatible, as they may otherwise not be able to find correct solutions (refer to the example where relations require an endlessly large model to be consistent). So now we should research, what the actual remaining problems in the consistency restorers (operationalization level) are if transformations respectively their relations are assumed compatible.

\paragraph{Relaxation of Redundancy Notion}
\label{chap:futurework:correctness:compatibility:redundancy}
In \autoref{chap:compatibility:formal_approach:redundancy}, we have introduced the specific notion of \emph{left-equal redundancy} (see \autoref{def:leftequalredundancy}), since an intuitive notion of redundancy is not strong enough to be compatibility-preserving.
That stronger notion was derived from counterexamples for redundancy being compatibility-preserving.
In our evaluation in \autoref{chap:correctness_evaluation:compatibility}, we have also shown in a case study that this notion is not too strong to be applicable, thus preventing our approach from proving compatibility.
Still, there might be a weaker notion than left-equal redundancy that is still strong enough to be compatibility-preserving.
Additionally, in other case studies our notion may still be too strong.
Thus, we still aim to find the weakest possible notion of redundancy that is still compatibility-preserving, if it exists. 
This especially involved finding scenarios in which our notion of left-equal redundancy is too restrictive.

\paragraph{Interactive Process}
\label{chap:futurework:correctness:compatibility:process}
Our proposed approach enables a user to check a transformation network regarding compatibility of its consistency relations.
If the approach identifies a given network as compatible, it is actually compatible as the algorithm operates conservatively.
However, the approach is not able to prove incompatibility. If the approach does not identify a network as compatible, it may be incompatible or not.
For that reason, we aim to define a holistic process for approach application, which integrates further information given by the user into the process of proving compatibility.
Since the approach operates inductively, it can simply allow the transformation developer to perform single induction steps.
If the algorithm is not able to prove compatibility, i.e., if it is not able to find further redundant relations, it can present the network, in which the algorithm already removed some redundant relations, to the transformation developer.
He or she is then asked to declare a cycle of consistency relations as compatible, for which the algorithm is not able to prove it, or which are even not compatible but should still be considered as they are.
Afterwards, the algorithm could proceed with finding further redundant relations to prove compatibility, based on the decision of the developer.
As a result, the approach would be applicable to more scenarios in which compatibility is intentionally not given or in which the algorithm on its own is not able to prove it.

% Process (framework) based on the approach: User can currently get the result that a network is compatible. If the approach does not find a solution, the network may be compatible or not. There should be a process that presents the user the information about how far reduction of the network was possible, for which cycles redundancy could not be proven. Finally, the user may be able to manually mark relations are compatible (i.e., there may be a relation that introduces restrictions on the condition elements of other relations for which consistent models can be created, but this is intended). This could also be integrated into the approach, such as a cycles manually declared as compatible could be resolved by removing the most general relation and proceeding with the algorithm.

\paragraph{Validation of Operationalization Alternatives}
\label{chap:futurework:correctness:compatibility:alternatives}
Our approach transformation \gls{QVTR} relations and their \gls{OCL} expressions into first-order logic formulae and uses an \gls{SMT} solver to evaluate their satisfiability.
Such a theorem prover, however, is limited in the cases he is able to analyze, as we already discussed in \autoref{chap:correctness_evaluation:compatibility:discussion:limitations}.
This can restrict applicability of the approach and in the scenarios considered in our evaluation in \autoref{chap:correctness_evaluation:compatibility}, it was even the only limitation regarding applicability.
To circumvent or mitigate that limitations, it is possible to implement the approach in \autoref{chap:compatibility:practical_approach} by means of other formal methods. 
For example, interactive theorem provers can potentially prove redundancy of consistency relations in more cases. 
Another possibility is the use of multiple formal methods next to \gls{SMT} solvers, as some formal methods can provide proofs in cases in which others cannot.
Although this improve the effort for developing the translations, the simultaneous use of different symbolic computation tools can increase the chances of finding redundancy proofs.
Additionally, it may even be beneficial to simplify the \gls{OCL} statements transformed into logic formulae where possible, like discussed in \textcite{cuadrado2019OclOptimization-SoSym}.
On the one hand, this can improve the chance of success of the \gls{SMT} solver.
On the other hand, it can make it easier for a transformation developer to understand the reasons why the algorithm failed, if the expressions the algorithm worked on are simpler.
%\todo{Evaluate whether it is benefitial to improve or simplify the OCL statements, which are then transformed into first-order logic formulae. There are approaches to optimize statements, especially for the case that they were automatically create~\cite{cuadrado2019OclOptimization-SoSym}.}

% For other implementations:
%         - Plug in other formal methods into the procedure
%         - Interactive theorem provers may prove redundancy in more cases
%             - Tradeoff: no more automation

\paragraph{Completion of Operationalized Approach}
\label{chap:futurework:correctness:compatibility:completion}
In \autoref{chap:compatibility:practical_approach} we have presented our practical compatibility analysis approach with the parts of \gls{OCL} operations and \gls{QVTR} relations it currently supports.
We will extend the operations for which translations to logic formulae are defined in future work, so that we can apply the approach to more sophisticated case studies.
This will provide further indicators for the general applicability of the approach.
% Moreover, \gls{SMT} solvers come with heuristics (sometimes called \textit{strategies}) to fine-tune their performances. Strategies should be chosen according to the nature of tested SMT instances, i.e.. consistency specifications. Thus, a better integration of the SMT solver can improve the realization of the current approach for proving compatibility in transformation networks.

% For the implementation of the current procedure:
%         - [OK] Fine-tune the solving strategy of the SMT solver
%         - [OK] Further translation of OCL to first-order formulae

% \iffalse
% \begin{itemize}
%     \item Process (framework) based on the approach: User can currently get the result that a network is compatible. If the approach does not find a solution, the network may be compatible or not. There should be a process that presents the user the information about how far reduction of the network was possible, for which cycles redundancy could not be proven. Finally, the user may be able to manually mark relations are compatible (i.e., there may be a relation that introduces restrictions on the condition elements of other relations for which consistent models can be created, but this is intended). This could also be integrated into the approach, such as a cycles manually declared as compatible could be resolved by removing the most general relation and proceeding with the algorithm.
%     \item Relation to issues in consistency repair: Further issues were identified in \cite{klare2019icmt}: This work is concerned with compatibility of consistency relations. Transformations also contain repair routines that restore consistency. They depend on their relations being compatible, as they may otherwise not be able to find correct solutions (refer to the example where relations require an endlessly large model to be consistent). So now we should research, what the actual remaining problems in the consistency restorers (oprationalization level) are if transformations respectively their relations are assumed compatible.
% \end{itemize}

%     For the implementation of the current procedure:
%         - Fine-tune the solving strategy of the SMT solver
%         - Further translation of OCL to first-order formulae
        
%     For other implementations:
%         - Plug in other formal methods into the procedure
%         - Interactive theorem provers may prove redundancy in more cases
%             - Tradeoff: no more automation
        
%     Integration into cyber-physical systems?
%     Integration into Vitruvius, relation with other ideas developed in \cite{klare2018docsym}?
% \fi


\subsection{Synchronization and Categorization}

In \autoref{chap:correctness_evaluation:categorization:discussion:limitations}, we have discussed several limitations of our proposed approaches and current finding regarding synchronization of bidirectional transformations and the categorization of possible mistakes, faults and failures in transformations networks, which were especially revealed by the evaluation. 
In the following, we discuss these opportunities for future work in terms of practical application improvements, conceptual progress and additional necessary evaluations.

\paragraph{Language-integrated Synchronization}
\label{chap:futurework:correctness:synchronization:integration}
In \autoref{chap:synchronization:achieving:identification}, we proposed an approach for constructing synchronizing transformations by means of existing bidirectional transformation languages.
We applied this approach in the evaluation, but due to the repeated implementation of the same pattern, the approach is costly and error prone.
In future work, we thus want to investigate how we can integrate the patterns for constructing synchronizing transformations into existing transformation languages, such as the \reactionslanguage used in the evaluation.
In particular, we want to investigate how well \gls{QVTR} fits for that purpose, as it already provides the possibility to define keys for matching existing elements~\cite[7.10.2.]{qvt}, which represents the essential idea of the proposed approach.

\paragraph{Semantic Matching}
\label{chap:futurework:correctness:synchronization:semantic_matching}
To identify existing elements for synchronization and also to express consistency relations for validating compatibility, we consider syntactic constraints, such as matching names.
Although it requires the transformation developer to know about the semantics of the elements to define that they have to be syntactically matched, this process would be even more valuable if the matching was performed on more semantic information.
For example, if two transformations use different naming schemes for transforming elements, they will not be matched and thus elements that are supposed to represent the same are actually represented multiple times.
In \autoref{chap:compatibility}, we discussed the case of swapping first name and last name, which leads to the existence of each person twice, which would intuitively be considered incompatible, but without further information about the semantics of the names, this can never be validated automatically.
Thus, mapping all elements to a common semantic representation could improve such a matching process.
In \autoref{chap:commonalities}, we will present an approach that proposes to describe transformations in terms of descriptions of the common elements of the metamodels, such representing their common semantics.

\paragraph{Interaction with User}
\label{chap:futurework:correctness:synchronization:user_interaction}
In \autoref{chap:introduction:objective:assumptions}, we explicitly excluded the consideration of interactions with the user in semi-automated transformations in this thesis.
Still, it is an important property of consistency preservation processes to involve users for making decision wherever information is missing to run the transformations fully automated.
For example, a software developer will usually have to decide whether a class he implements is supposed to represent a component or not.
While the options from which a user can select can be represented in terms of different consistency relations pairs at the level of relations, their realization in consistency preservation rules becomes problematic.
If multiple transformations let the user make the same decision, such as both transformations between \gls{UML} and \gls{PCM} as well as between Java and \gls{PCM} let him decide whether a class represents a component, it is unnecessary and annoying for the user to make this decision repeatedly, but, more importantly, he can make contradicting decisions in both cases.
How this can be avoided and how interactions with the user can be aligned across multiple transformations will be part of our future work.

\paragraph{Alignment of Consistency Preservation Rules}
\label{chap:futurework:correctness:synchronization:cpr_alignment}
In \autoref{chap:orchestration:decidability}, we have discussed that one reason for not finding a consistent orchestration of transformations is that their consistency preservation rules make contradicting selections of different options to restore consistency according to the consistency relations.
Unfortunately, we were not able to systematically derive further issue within consistency preservation rules that may prevent from finding a consistent orchestration and we did especially not find a useful notion of correctness for a set of consistency preservation rules to properly work together.
While finding consistent orchestration is difficult due to the undecidability of the orchestration problem anyway, in this thesis we focused on how to conservatively deal with this situation.
Still, it would be useful to a systematic understanding of how consistency preservation rules influence the ability to find consistent orchestrations and whether there are further issues except the selection of contradicting options.

%Andere Ursachen dafür, dass keine konsistente Orchestrierung gefunden wird, außer Optionsselektion?

\paragraph{Synchronization Transformation Construction Case Study}
\label{chap:futurework:correctness:synchronization:case_study}
Finally, in \autoref{chap:correctness_evaluation:categorization}, we discussed two case studies to validate different properties of our proposed error categorization as well as the approach for constructing synchronizing transformations.
Although we were able to derive valuable conclusions, the case study was bias by the fact that two of three transformations were not designed to be synchronizing and, as part of the case study, fixed to be synchronizing during that study.
Still, it would be valuable to perform a case study with a focus on the construction of synchronizing transformations to improve evidence on the ability of correctly and completely achieving synchronizing transformations with our proposed approach.


\subsection{Orchestration}

\begin{copiedFrom}{MODELS Orchestration}

We have formalised our findings on execution bounds and the behaviour of the proposed execution strategy to prove the insights and expected properties of the strategy.
In consequence, this paper provides fundamental knowledge about the design space and relevant design goals of transformation network execution strategies.
While the statements on correctness and well-definedness are proven, those on the usefulness of the strategy in terms of providing provenance were derived by argumentation.
To improve evidence of the results, the authors plan to apply the strategy to realistic use cases, involving larger networks of more complex transformations.

Furthermore, the authors want to examine how the strategy can be further optimised:
It might, for example, be improved by selecting the next candidate transformation more carefully, taking the network topology and nature of the changes into account.
Since early executed transformations will be executed most often, it might make sense to start with those that are most likely not to cause conflicts.
\citeauthor{etien2012Chaining-AMT} present heuristics for identifying such transformations~\cite{etien2010Combining-SAC,etien2012Chaining-AMT}, which might prove valuable in this regard.
%
Finally, this paper only discussed networks of binary transformations.
The presented execution strategy, however, does not rely on the transformations being binary and may work just as well for networks with multi-ary ones.
Future research could investigate whether there are relevant differences when applying the execution strategy to networks of multi-ary transformations.


\end{copiedFrom} % MODELS Orchestration

In \autoref{chap:orchestration:algorithm}, we have proposed the provenance algorithm for orchestration in transformation network, which deals with the orchestration problem by executing transformations in a well-defined way that it supposed to improve the ability of identifying the reasons whenever the algorithm fails.
We have discussed limitations, especially regarding evidence of evaluation results for the proposed properties of that approach in \autoref{chap:correctness_evaluation:orchestration:discussion:limitations}.
In the following, we discuss how we want to address these limitations in future work.

\paragraph{Controlled Experiment}
\label{chap:futurework:correctness:orchestration:experiment}
While statements on the correctness and well-definedness of the approach have been proven, its usefulness was only validated in a scenario-based discussion, which especially suffers from potential threats to construct validity, as it is unclear whether the metrics we investigates actually reflect usefulness in terms of the strategy in terms of reducing the time and error when identifying faults in transformation network.
We have already discussed in \autoref{chap:correctness_evaluation:orchestration:goals} that a controlled experiment could significantly improve evidence by presenting the information delivered by our approach and by other strategies to different groups of developers and evaluating how long they take to find and fix faults in both situations.

\paragraph{Well-defined Design Property}
\label{chap:futurework:correctness:orchestration:property}
The algorithm guarantees to find consistent models as long as the transformations fulfill the property of begin reactive converging.
Unfortunately, this property can neither be guaranteed nor analyzed easily.
Thus, a different property that can at least be analyzed at design time would be beneficial.
Such a property can, however, easily restrict expressiveness of transformations, as we have discussed in \autoref{chap:orchestration:decidability:restriction}.
Still, finding such a property would be a valuable contribution and thus serves as a starting found for future work.

\paragraph{Transformation Selection Order}
\label{chap:futurework:correctness:orchestration:selection}
In the scenario-based evaluation of the proposed algorithm, we found that the order in which transformations are selected may further reduce the number of transformations that need to be investigated to find a fault whenever the algorithm fails (see \autoref{chap:correctness_evaluation:orchestration:discussion}).
More precisely, we proposed to first execute transformations that close cycles in the graph of executed transformations to ensure that small simple cycles are closed as early as possible.
While this insight was based on argumentation, evaluating or, in the best case, proving benefits of such a selection order could further improve its evidence.

\paragraph{Fault Identification Process}
\label{chap:futurework:correctness:orchestration:process}
With the proposed algorithm, we aimed to improve the process of finding faults in transformations in terms of reducing the effort for the transformation developer.
In practice, a failure may however not occur when a transformation developer tests a transformation network, which allows him to directly identify and fix the fault.
Instead, a transformation network may be in productive use, thus a failure occurs when a user of that networks applies the transformations to preserve consistency.
Then, a holistic process is required for reporting and fixing such a errors, which needs to define the responsibilities.
Additionally, such a process will not be just-in-time, thus the project in which the transformation network is applied needs to be able to deal with the fact that consistency cannot be preserved for some time.
Such a process is, for example, also part of the research in the \vitruv project (see~\cite{klare2020Vitruv-JSS}), to which the results of this thesis contribute.

% \todo{User study for usage/process of specifying transformation networks. Are such networks really used? Are transformations reused? Is this not the case because of missing methodology or because no one wants to use it?}


\section{Quality of Transformation Networks}