\chapter{Foundations and Notation
    \pgsize{10 p.}
}
\label{chap:foundations}

\mnote{Foundations overview}
In this chapter, we introduce fundamental concepts and notations that we use throughout this thesis.
We introduce modeling in terms of a notion of models and methods in which they are used, and depict important formalisms and frameworks for modeling. % namely the \gls{MOF} standard and its realization in \gls{EMF}.
We introduce the idea of multi-view modeling and in particular the \vitruv approach, which we employ for evaluations in this thesis, as well as the approach it was inspired by.
Finally, we introduce model transformations, in particular bidirectional transformations and languages to describe them. % and one specific language we use for the realization of our contributions.
After introducing the case studies used for our evaluations and, partly, for explanations of our contributions, we depict the mathematical notations that we use in this thesis.


%%%
%% MODELING
%%%
\section{Modeling}
\label{chap:foundations:modeling}

\mnote{Models and their usage}
This thesis researches the employment of transformations to keep multiple models that are used to describe a single software systems consistent.
Therefore, we first introduce a notion of models and how to use them.


\subsection{Models and Model Theory}
\label{chap:foundations:modeling:models}

\mnote{General model notion}
Models are a ubiquitous concept, which is used throughout many technical and non-technical domains.
The term \emph{model} is used differently in various contexts from informal depictions to mathematical formalizations~\cite{stachowiak1973modelltheorie-Book}.
In his work about general model theory, \citeauthor{stachowiak1973modelltheorie-Book} characterizes models by three criteria: representation, abstraction and pragmatics~\cite[p.~131--133]{stachowiak1973modelltheorie-Book}.

\begin{properdescription}
\item[Representation:] \mnote{Representation of an original}
The \emph{representation} characteristic requires a model to be a mapping or representation of some \emph{original}.
An original must not necessarily be a natural, existing entity, but can also be any kind of concept, which can, again, be a model~\cite[p.~131]{stachowiak1973modelltheorie-Book}.
We always consider models that are representations of any kind of software or software-intensive technical system under construction.
This characteristic requires that a model does not contain any information not related to the system, such that, if system and model could be represented by a set of explicit properties, we would be able to define a mapping, or, more precisely, a homomorphism between them.

\item[Abstraction:] \mnote{Subset of properties of an original}
The \emph{abstraction} characteristic requires a model to, in general, only represent a subset of the properties of its original.
Properties are limited to those, which seem relevant the creator of the model~\cite[p.~132]{stachowiak1973modelltheorie-Book}.
This abstraction should be driven by the pragmatics of the model, defined as the third characteristics.
For example, an architecture model of a software system may only represent properties relevant for some information need at the architectural level, which could, for example, abstract from behavior or implementation details.

\item[Pragmatics:] \mnote{Defined for specific purpose}
The \emph{pragmatic} characteristic requires a model to be designed for a specific purpose, such that it can only be related to its original for specific users, for specific points in time and for specific operations~\cite[pp.~132]{stachowiak1973modelltheorie-Book}.
Models of software systems can, for example, have the purpose of depicting or editing the system structure or its behavior, or of performing some analysis or simulations for specific properties of the system.
The pragmatics influences the abstraction, as a specific purpose implies a certain information need to be provided by a proper abstraction.
\end{properdescription}

\mnote{Notion in software engineering}
While this is a rather general notion of a model, it also fits to the one relevant for software engineering, as depicted in the examples.
One appropriate definition for models in the domain of software design has been given by \citeauthor{rumbaugh2005objectoriented-Book}:
\enquote{A model is an abstraction of something for the purpose of understanding it before building it}~\cite[p.~15]{rumbaugh2005objectoriented-Book}.
This fits well to the notion of making predictions about the systems upfront, such as the already mentioned Palladio Simulator making performance predictions about a software systems based on an architectural model of it.
Models may, however, not only be used to understand the system, but also to build it, especially when considering code as a model as well.


\subsection{Metamodels and Languages}
\label{chap:foundations:modeling:metamodels}

\mnote{Metamodels and instance-of relations}
To automatically or semi-automatically process models, such as compiling source code, these models need to follow some specification, which can be considered a model that defines how a valid model for a specific purpose looks like.
Such a model of a model is often denoted as a \emph{metamodel}.
Models and their metamodels induce an \emph{instance-of} relationship, such that a metamodel can be considered the type of model, and a model is considered an instance of a metamodel.
This conforms to the notion of type and instance level known from programming.
The grammar of a programming language, such as the Java language specification~\cite{gosling2018jls-specification}, can be considered a metamodel for programs of that language.

\mnote{Metamodels as sets of models}
In a simple notion, a metamodel can be considered a set of models, such that a model is an instance of that metamodel if it is contained in that set. This is sometimes also simply referred to as \emph{model sets}~\cite{stevens2020BidirectionalTransformationLarge-SoSym}.
Usually, metamodels will be described with some formalism, which we discuss in more detail in \autoref{chap:foundations:formalisms}.
Such a formalism defines the elements of which a metamodel consists and how these elements are instantiated in the models, along with some constraints that a model has to fulfill to be considered a valid instance.

\mnote{Modeling languages}
Models, especially in software engineering, are often understood as structures of objects and relations between them, which can be depicted in \gls{UML} class diagrams.
Although this notion fits well to how we consider models and how we later define them more precisely, the elements of models must also have a meaning, i.e., a semantics~\cite{harel2004semantics-Computer}, in the specific context they are used for.
This semantics is given by the pragmatics characteristic of \citeauthor{stachowiak1973modelltheorie-Book}'s classification.
For models in software engineering, this semantics is usually defined by \emph{modeling languages} and tools defined for that modeling language, in which these models are defined and used.
These languages and tools, for example, transform models into another representation, i.e., into another model, for which the semantics is known, such as code, whose execution semantics is given by its compilation to machine code for some, potentially virtual, machine whose execution semantics is known.
This is known as \emph{transformational semantics}~\cite{pepper1987transformationalSemantics-SSPC}.

\mnote{Parts of modeling languages}
A modeling language consists of a specification of abstract and concrete syntax, as well as its static and dynamic semantics~\cite[p. 26]{voelter2013DslEngineering}.
\begin{properdescription}
    \item[Abstract Syntax:] The abstract syntax defines a data structure containing the relevant information about a system or program, usually in terms of a tree of graph.
    \item[Concrete Syntax:] A concrete syntax is the notation in which a user can express models, such as a textual or graphical representation.
    \item[Static Semantics:] The static semantics is a set of constraints that a model has to fulfill, which can, for example, include a type system, in addition to conforming to its syntax specification.
    \item[Execution semantics:] The execution semantics define the semantics of a program or model when it is executed. This can also be given by a transformation to another model.  
\end{properdescription}

\mnote{Domain-specific languages}
\textcite{voelter2013DslEngineering} use the term \emph{\gls{DSL}} instead of modeling language, which we have already referred to in \autoref{chap:introduction} at the example of \gls{XML}.
\Glspl{DSL} are supposed to increase productivity and conciseness for specifying models in a specific domain~\cite[p.~30]{voelter2013DslEngineering} in comparison to using a \emph{\glspl{GPL}}.
A language is, however, not either domain-specific or general-purpose, but domain-specificity of a language is a gradual notion~\cite[p.~30]{voelter2013DslEngineering}.
\Glspl{DSL} being designed for a specific domain are usually assumed to have restricted expressiveness~\cite[Chap.~2]{fowler2010dsls-Book}.
The term \emph{domain} can have different meanings.
\citeauthor{voelter2013DslEngineering} distinguish between \emph{technical} and \emph{application domain} \glspl{DSL}, although emphasizing that there is no clear border between them~\cite[p.~26]{voelter2013DslEngineering}.
In the context of this work, we can distinguish \glspl{DSL} used by software developers and \glspl{DSL} used by developers of software development tools.
\glspl{DSL} for software developers can again be separated into rather generic \glspl{DSL}, such as \gls{UML} for general software design and \gls{PCM} for general performance prediction, and rather application specific \glspl{DSL}, such as MATLAB/Simulink~\cite{simulink} or AUTOSAR~\cite{scheid2015autosar} in automotive software development.
\glspl{DSL} for software development tool developers cover languages for specifying transformations and editors to be used for developing software and keeping software models consistent.
Thus, in this work, especially transformation languages used by developers of transformation networks to support software development are relevant, whereas languages of software developers are used to define the models which the transformation then have to kept consistent.

\mnote{Metamodels as abstract syntax}
Since we do not consider domain-specificity of a language, we only use the general term \emph{modeling language}.
Metamodels are often only referred to as the abstract syntax of models~\cite[p.~27]{voelter2013DslEngineering}, whose semantics is defined by the modeling language it is used in.
In this thesis, we use a notion of models and metamodels that we define more precisely in \autoref{chap:networks:models}, which does also not reflect the semantics of the models explicitly.
Some semantics of models is, however, represented implicitly by the transformations preserving consistency.


\subsection{Model-Driven Software Development}
\label{chap:foundations:modeling:mdsd}

\mnote{Abstraction in software development}
\gls{MDSD} is a general term for the idea of increasing abstraction in software development by using models instead of or in addition to program code~\cite{atkinson2003mdd-Software}.
It also appears as \emph{model-driven software engineering} or simply \emph{model-driven development}~\cite{atkinson2003mdd-Software}.
It has been seen as the natural continuation of increasing abstraction, like achieved with more powerful compiler and higher abstraction in programming languages before, by automating repetitive tasks such as support for persistence or interoperability~\cite{atkinson2003mdd-Software}.
This especially includes that models are not only considered additional documentation artifacts, but central entities of the development process, from which even code can be derived.

\mnote{Development processes}
The \gls{MDA}~\cite{mda} proposed a standard for an \gls{MDSD} process, in which abstract, platform-independent and thus highly reusable and portable models of a system are used to generate code for different platforms.
It explicitly distinguishes between computation-independent, platform-independent and platform-specific models.
\citeauthor{voelter2013mdsd-Book} propose a more sophisticated process for \gls{MDSD}, in which repetitive and generic code is separated from individual code, such that repetitive code can be automatically generated and extended by individual code~\cite[Fig.~2.1]{voelter2013mdsd-Book}.

\mnote{Everything is a model}
We consider \gls{MDSD} with an even more generic process using any models to describe a system under construction, which do not only serve documentation purposes but which all or of which most contain at least some information that is not represented in the other models, while still sharing common information that, as a central part of the motivation of this thesis, need to be kept consistent.
Thus, we especially do not split the code into repetitive and individual code, as we also treat code as model, which can be changed like the other models.
In this thesis, for example, we employ a metamodel for Java code~\cite{heidenreich2010jamopp-SLE}.
This follows the notion of \citeauthor{bezivin2005sosym} that \enquote{everything is a model}~\cite{bezivin2005sosym}.



%%%
%% MODELING FORMALISMS / FRAMEWORKS
%%%
\section{Modeling Formalisms and Frameworks}
\label{chap:foundations:formalisms}

\subsection{Meta-Object Facility}
\label{chap:foundations:formalisms:mof}
Discuss \gls{MOF}, especially \gls{EMOF} and how it is used to model things;
Discuss levels of UML;
Say why MOF is the relevant formalism for us which we base our considerations on.

Many relevant tools use MOF-compliant models, such as AUTOSAR or SysML.

Modeling Levels M1--M3

Elements of metamodels: types of objects, types of relations and attributes
Metaclass (also class, type of an object)
Reference (also association in UML, multiplicities, directionality)
Attribute (properties of an element, in general both metaclass as well as reference!, have data type with value range)

\begin{figure}
    \centering
    \input{figures/prologue/foundations/emof.tex}
    \caption[Simplified EMOF metamodelling language]{Simplified class diagram showing central \metaclasses of the EMOF metamodelling language~\cite[p. 27]{mof} (dotted lines denote indirect inheritance). Adapted from \cite[Fig. 2.2]{kramer2017a}.}
    \label{fig:foundations:emof}
\end{figure}


Other formalisms such as multi-level or deep modeling, which precisely separates ontological and linguistic modelling and, in the extreme case, allows in arbitrary number of levels. Idea already presented in early 2000s~\cite{atkinson2003mdd-Software}.
Goal is also to reduce accidental complexity introduced by artifical boundary to two modeling levels~\cite{atkinson2008reducingAccidentalComplexity-SoSym}.
This is complementary to the accidental complexity introduced by replicating information across different models, which we aim to manage with consistency preservation mechanism, as it concerns the accidental complexity within the single models due to restricted modeling capabilities.
Still, we focus on the modeling levels defined by UML as they are still state-of-practice in programming (single type and instance level) as well as in modeling at least considering mature tools like EMF (explained in following), whereas multi-level modeling has gained attention in the last years~\cite{atkinso2014multilevel-MLM} and tools are not as mature or at least not that widely adopted and sophisticated.



\subsection{EMF and Ecore}
\label{chap:foundations:formalisms:ecore}
Discuss \gls{EMF}, Ecore and the relation EMOF

Say that we define an own modelling formalism without precise specifications of the elements models consist of. We therefore rely on EMOF as the most general relevant standard for a modeling formalism.

Add graphics of relevant part of EMOF metamodel here, from Max' Diss

\begin{figure}
    \centering
    \input{figures/prologue/foundations/ecore.tex}
    \caption[Simplified Ecore metamodelling language]{Simplified class diagram showing central \metaclasses of the Ecore metamodelling language~\cite[p. 97]{steinberg2009emf}. Adapted from \cite[Fig. 2.3]{kramer2017a}.}
    \label{fig:foundations:ecore}
\end{figure}


%\subsection{Differences}
\label{chap:foundations:formalisms:differences}

Discuss differences between Ecore and EMOF, especially those relevant for the changes later and how the differences in general manifest in our formal framework

FROM MAX:
Different information and case distinctions are necessary to describe all possible model changes for modelling languages that follow the Essential Meta Object Facility (EMOF) standard or the Ecore variant. 
Both meta-modelling languages and the differences between them are described in \autoref{chap:foundations:modeling:models}.
Only two differences have a major effect on our change modelling language and the specifications language that use them:
\begin{longenumerate}%[1.]
\item In EMOF, properties can be typed using \metaclasses or using other data types, but in Ecore these are distinguished as references and attributes.
\item Ecore requires that all elements except for a root element are contained in exactly one container and EMOF only requires that all elements have at most one container~\cite[pp.\ 31-32]{mof}.
\end{longenumerate}
If we only consider these two differences, then Ecore can be seen as a refinement of EMOF, which only adds a more fine-grained distinction of properties and further containment restrictions.
Because of this refinement relation, we will first describe which information is necessary to represent model changes of EMOF-based models and then add further information and distinctions for Ecore-based models.
Finally, we briefly explain how we made all this information available in practice using a change modelling language.


%\subsection{Simplification}
\label{chap:foundations:formalisms:simplification}

Discuss how far we simplify the modeling concepts (or maybe do that later in the notation / formalization discussion at the end of foundations or in networks chapter)


TOOLING:
Many tools for EMF, such as editor frameworks, transformation languages, language workbenches etc.
Transformation languages discussed in following.
Language workbenches, e.g., Xtext~\cite{efftinge2006xtext-MSES,bettini2016Xtext-Book} for languages with textual syntax defined in terms of a grammar, from which the metamodel, parser etc. are derived and a compiler can be defined.
We use Xtext for implementing a prototype for the language that we proposed in this thesis and it is also used for language that we reuse, such as the \reactionslanguage introduced in one of the subsequent sections.

JaMoPP for treating Java code a model, as already introduced in \autoref{chap:foundations:modeling:mdsd}.
Capabilities for parsing and printing Java code to be represented as an Ecore model~\cite{heidenreich2010jamopp-SLE, heidenreich2009jamopp-report}.


\section{Multi-view Modeling}
\label{chap:foundations:multiview}

Multi-view modeling covers the general topic of describing a system by means of multiple views or, in general, models~\cite{reineke2017ProblemMultiView-SoSym}.
A key challenge in multi-view modeling is consistency, as we have motivated in \autoref{chap:introduction}~\cite{reineke2017ProblemMultiView-SoSym}.
Preserving consistency between multiple views is referred to as \emph{model repair}~\cite{macedo2017ModelRepairClassification-TSE}, \emph{consistency restoration}~\cite{stevens2010sosym, kramer2017a} or \emph{model synchronization}~\cite{diskin2016Taxonomy-JSS}, with slightly different meanings.
We, in general, refer to this as \emph{consistency preservation}.

Views have been defined in an ISO standard: \emph{architecture view} defined as expressing the system architecture regarding specific concerns \cite[p.~2]{iso42010}.
synthetic vs. projective~\cite[p.~22]{iso42010}
While synthetic composes system description of views, such that each of them represents some information not contained in the others, projective views derive the information completely from an underlying source and are thus only projections.
In projective approaches, the underlying source can, again, be seen as a model, such that views in projective approaches are projections of that model~\cite[Fig.~5]{klare2020Vitruv-JSS}.
This underlying model is called a \gls{SUM}~\cite[p.~210]{atkinson2010a}, which, like any model, conform to a metamodel, the \gls{SUMM}~\owncite[Def.~2]{klare2020Vitruv-JSS}.

In a projective approach, the problem of preserving consistency is transferred to ensuring consistency within the \gls{SUM}, from which the views are projected.
Consistency of this \gls{SUM} can be achieved in different ways~\owncite{meier2019modelsward,meier2020ccis}, especially depending on whether a \gls{SUM} is \emph{essential} or \emph{pragmatic}~\cite{atkinson2015realizationMultiView-EDOC}.
An essential \gls{SUM} is free of any redundancies or implicit dependencies, such that every instance of its \gls{SUMM} is inherently consistent, whereas a pragmatic \gls{SUM} can contain allow arbitrary redundancies and dependencies, which then have to be kept consistent by explicit mechanisms for consistency preservation, such a transformations.
While the former approach is followed by the \gls{OSM} approach, the latter is used in the \vitruv approach, which we depict in more detail in the following.


% \subsection{Consistency Preservation}
% \label{chap:foundations:multiview:consistency}

% Consistency vs. its preservation

% Terminology: model repair~\cite{macedo2017ModelRepairClassification-TSE}, consistency restoration~\cite{stevens2010sosym, kramer2017a}, model synchronization~\cite{diskin2016Taxonomy-JSS}

% Synchronization vs. incremental vs. concurrent


\subsection{Orthographic Software Modeling}
\label{chap:foundations:multiview:osm}

\gls{OSM}
Projective multi-view approach, based on essential SUMs~\cite{atkinson2010a}.
Focus actually on views, how to create and manage them, structured along dimensions and dynamically created on-demand from the SUM.
Consistency achieved through the SUM, which is inherently consistent.


\subsection{The \vitruv Framework}
\label{chap:foundations:multiview:vitruv}
Copies the idea of a SUM and projective views from \gls{OSM}.
Instead of an essential SUM, is uses a pragmatic SUM, which can contain redundancies and dependencies that are kept consistent.
The SUM internally consists of models, which are kept consistent by model transformations, denoted as a \vsum~\cite{klare2020Vitruv-JSS}.
It is motivated by the insight that constructing an essential, redundancy-free SUM is hard to achieve and that for compatibility with existing tools it may be easier to combine their metamodels with a synthetic approach, such that the view used by each tool is a projection of a single models within the V-SUM, whereas further projective views can be derived from the information of the models in the V-SUM, but ensuring their consistency with transformations.

Within a V-SUM, multiple models need to be kept consistent, which is one application area for the contributions of this thesis.
%\vitruv puts an abstraction layers of views onto the contributions of this thesis and defines a process of using and applying it. 
%\todo{Reflect this later in the Commonalities chapter by referring to the idea and saying how composition of Commonalities can even improve the approach.}
\vitruv serves both as a motivation for the contributions of this thesis, but its implementation in the \vitruv framework~\cite{vitruvFrameworkGithub} and especially its languages for consistency preservation serves as a basis for our prototypical implementation and validation purposes.
Additionally, we will see that the abstraction provided by a layer of projective views onto the models that are kept consistent in a V-SUM provides benefits of our approach for improving quality properties rather than using it standalone.
%Additionally, at some points (Commonalities), the usage of developed concepts provides even more benefits when not only used standalone but in combination with further ideas of \vitruv.

For \vitruv, we have provided a simple but sufficient formalism defining consistency~\cite{klare2020Vitruv-JSS}, on which the formalism in this thesis bases.
However, the formalism in this thesis will be more detailed and fine-grained.



\section{Model Transformations}
\label{chap:foundations:transformations}

Heart and soul of \gls{MDSD}~\cite{sendall2003modelTransformation-Software}.

According to \textcite{kleppe2003mdaExplained-Book}, transformation defines how to generate target model from a source model by a transformation definition.
Transformation definition consists of transformation rules, which in turn define how one or more constructs of the source language or metamodel are transformed into constructs of the target language or metamodel.

\begin{figure}
    \centering
    \input{figures/prologue/foundations/transformation_schema.tex}
    \caption[Transformation artifacts and their relations]{Artifacts of a transformation and transformation language, as well as their relations. Adapted from \cite[Fig.~9-5]{kleppe2003mdaExplained-Book}.}
    \label{fig:foundations:transformation}
\end{figure}

While \textcite{kleppe2003mdaExplained-Book} is specific to \gls{MDA} thus deriving more specific artifacts from abstract artifacts, this can be generalized to transformations between any languages.
Graphics as an abstraction and schematic representation of the process \cite[Fig.~9-5]{kleppe2003mdaExplained-Book}.
TODO: Adapt graphics such that transformation definition consists of transformation rules.
Transformation definitions and their rules need to fulfill some format expected by the transformation engine.
Often supported by a \emph{transformation definition language}~\cite[Sec. 9.2]{kleppe2003mdaExplained-Book}, or short \emph{transformation language} that generates appropriate artifacts.

Transformations provide multiple degrees of freedom for how information from one or more models can be transferred into one or more other models.
\textcite{czarnecki2006a} provides feature models for transformations regarding many aspects.
Transformations used for many different purposes, from batch generation of class stubs from UML class models to the update of multiple models after concurrent changes to them for restoring consistency.

Important for us and the goal of consistency are in particular two aspects:
Directionality \cite[Fig.~19]{czarnecki2006a}: Unidirectional vs. multidirectional (specifically bidirectional)
Incrementality \cite[Fig.~19]{czarnecki2006a}: Source- and target-incrementality (latter is ordinary incrementality, former is kind of change-driven/state-based)
Discuss state-based/delta-based!

Intermediate structure: additional models often temporary for execution, especially traceability models


\subsection{Bidirectional Transformations}
\label{chap:foundations:transformations:bidirectional}
\todo{Introduce Transformations}

Bidirectional transformations define consistency between two models and how to restore it in both directions~\cite{stevens2010sosym}.
They consist of a relation defining when two models are considered consistent and two consistency restorers, one for each direction.
A consistency restorer is a function taking two potentially inconsistent models and returning an updated instance of one of the models (depending on the direction), such that the resulting models are consistent again.
We define these kinds of transformations more precisely later based on the formalism that we introduce.

Important properties of such transformations are correctness and hippocraticness, both defined by \textcite{stevens2010sosym}.
Correctness means that the result models are actually consistent, i.e., they are in the relation of the transformation.
Hippocraticness means that whenever the input models are consistent, the consistency restorer does not alter them.
We recapture these properties and define also them precisely later, based on the formalism that we introduce.

% Compare multidirectional transformations with networks of transformations.
% Refer for other consistency approaches to related work.

% Correctness, hippocraticness!


\subsection{Transformation Languages}
\label{chap:foundations:transformations:languages}

Discuss what transformation languages are. Refer to initial graphics.
Transformation language can be seen as \glspl{DSL} (see \autoref{chap:foundations:modeling:metamodels}).

We will especially distinguish between rather \emph{imperative} and \emph{declarative} transformation languages.
Imperative languages allow to define how consistency is restored whenever changes are performed, whereas a declarative language allows to define when models are considered consistent and the language derives how to restore this after changes.
This distinction is most relevant for us, because it maps to different concepts in our formalization, which we present in \autoref{chap:correctness}.
Although languages can actually contain imperative and declarative constructs, we make this rather broad distinction, as the basic distinction of whether the developer specifies how to preserve consistency or whether the language has to derive it from a declarative specification applies no matter whether the complete language or only single constructs can be considered declarative.
In the classification of \textcite{czarnecki2006a}, this is covered by different paradigms of specifying transformations in languages, especially distinguishing procedural and logic paradigms~\cite[Fig.~20]{czarnecki2006a}, depending on whether they describe how to achieve or restore consistency, or whether they only define the constraints, which usually come along with a specific way of specifying values~\cite[Fig.~20]{czarnecki2006a}, in particular imperative assignment and constraints.

\textcite{czarnecki2006a} also distinguish different transformation approaches, such as operational, relational or graph-based approaches.
Although we usually not consider the actual language and thus the approach for specifying transformations, the languages we explicitly consider or even propose in this thesis follow either an operational approach, which imperatively specifies how to preserve consistency, or a relational approach, which declaratively specifies constraints between two metamodels.

Examples for transformation languages for the \gls{MOF} are the languages of the \gls{QVT} standard~\cite{qvt}, namely \gls{QVTO}, an imperative, operational and unidirectional language, and \gls{QVTR}, a declarative, relational and bidirectional language.
\gls{QVTR} is relevant for this thesis, as we propose a practical realization of one of our approaches for \gls{QVTR}.
\gls{QVTR} uses the \gls{OCL}~\cite{ocl} for specifying the constraints that have to hold between instances of two metamodels.
In general, \gls{QVTR} is even multidirectional and allows to define relations between multiple metamodels, we however only consider the bidirectional case.

For the \gls{QVT} languages, implementations for the \gls{EMF} exist. Further common \gls{EMF}-based languages are \gls{VIATRA}~\cite{bergmann2015viatra}, an imperative and unidirectional transformation language, and \gls{ATL}, which is hybrid language containing both imperative and declarative constructs.
Another well-researched transformation approach are \glspl{TGG}, originally developed by \cite{schuerr1995a} as a graph transformation approach and later applied to \gls{EMF}~\cite{leblebici2014IncrementalTGGSurvey-GTVMT} with tools like eMoflon~\cite{anjorin2014c}.


\todo{Need to discuss QVT-R more detailed?}

% imperative vs. declarative

% Also on language structure:
% Paradigm: functional, logic
% Value Specification: Constraint, Imperative Assignment


\subsection{The \reactionslanguage}
\label{chap:foundations:transformations:reactions}

Maybe move something from prototypical implementation in \autoref{chap:correctness_evaluation:categorization} here.

\vitruv framework defines transformation engines, executes rules according to some change propagation format.
\reactionslanguage generated rules according to that format.



\section{Case Studies}

\subsection{Domains: PCM, UML and Java}
\label{chap:foundations:case_studies:domains}

Introduce domains

Explain what PCM is used for, what essential elements are. Say that it is developed with EMF. Also introduce SEFFs, but say that we do not consider them (we also  mention that in the following relations section).
Depict a diagram representing each element. Cite book and tech report

Refer to UML standard and its UML2 realization as an Ecore model. Say that we focus on UML class models (and partly small extracts of component models), but in general only structural diagram types and no behavioral ones (refer standard).

Say why Java is a model, refer to JaMoPP.


\subsection{Consistency Relations}
\label{chap:foundations:case_studies:relations}

We explain our notions of consistency and, in particular, of consistency relations in detail in \autoref{chap:networks} and \autoref{chap:correctness}.
Broadly speaking, consistency relations define when one model is considered consistent to another.
We depict the consistency relations for the case study domains in such a general way that this broad notion of sufficient for comprehending them.
In the way we introduce the relations, they are supposed to mean that if some elements are present in model, according other elements need to be present in another model, such that for every \gls{UML} class a Java class with the same name has to exist.

\mnote{Two sets of underlying consistency relations}
The consistency relations between \gls{PCM}, \gls{UML} and Java consists of two parts.
First, the relations between \gls{PCM} and object-oriented design in both \gls{UML} and Java were defined and explained in detail by \citeauthor{langhammer2017a}~\cite{langhammer2015a, langhammer2017a}.
He, in particular, proposed different options for relations between \gls{PCM} and Java, which can be generalized to object-oriented design.
We selected the mapping of architectural components to classes and packages, as that is the one that was studied most intensively and whose implementation is most mature.
This conforms to the mapping that we have already sketched in \autoref{chap:introduction}.
Second, the relations between \gls{UML} and Java reflect the usually implicitly known mapping between the two languages, as both describe the object-oriented structure of a software system in a similar way.

\begin{table}
	\centering 
    \small
    \renewcommand{\arraystretch}{1.4}
    \rowcolors{2}{\secondlinecolor}{\firstlinecolor}
	\begin{tabular}{p{3.2cm} p{6.6cm}}
		\toprule
        \textbf{\gls{PCM} Element}  & \textbf{Object-oriented Design Element} \\
        \midrule
		Repository              & Three packages: main, contracts, data types\\
		BasicComponent 		    & Package within the main package and a public component realization class within the package \\
		OperationInterface		& Interface in the contracts package \\
		Signature \& parameters & Method \& parameters \\
		CompositeDatatype       & Class with getter and setter (or appropriate read-only property) for inner types\\
		CollectionDatatypes     & Class that inherits from a collection type (e.g., \texttt{ArrayList} in Java) \\
		RequiredRole		    & Field typed with required interface in the component realization class and constructor parameter for the field in the component realization class\\
		ProvidedRole		    & Component realization class of providing component implements the provided interface\\
		\bottomrule
	\end{tabular}
	\caption[Consistency relations between \acrshort{PCM} and \acrshort{UML}/Java]{Consistency relations between elements of the \gls{PCM} repository metamodel and object-oriented design elements (\gls{UML}/Java). Adapted from \cite[Table 4.1]{langhammer2017a}.}
	\label{tab:foundations:pcm_oo_rules}
\end{table}

\mnote{Relations between \gls{PCM} and object-oriented design}
\autoref{tab:foundations:pcm_oo_rules} sketches the relevant consistency relations between \gls{PCM} models and object-oriented design, which can be reflected in both \gls{UML} and Java.
A \gls{PCM} repository model consists of data types, interfaces and components, which are all contained in one repository.
The repository is represented as a package structure of three packages in object-oriented design.
Each component is represented as a package containing a so called \emph{component realization class}.
Interfaces with their signatures and parameters are mapped to corresponding object-oriented elements as they are.
Composite data types are represented as a class containing the composed types, and collection data types are represented as subclasses of a collection type.
Finally, provided and required roles define that a component provides or requires an interface.
Provided roles are realized by an implementation of the provided interfaces in the component realization class.
A required role, on the contrary, is represented as a field in the component realization class, which must be set via a constructor parameter.
All these relations include further constraints for their features, especially their names, such as the field representing a required role has to have the same name as the role.

\mnote{Behavioral consistency of \gls{PCM} and Java}
\gls{PCM} models can also contain \emph{service effect specifications}, which are an abstract specification of the behavior of a service provided by a component.
Consistency between these behavior specifications in \gls{PCM} and their implementation in Java code was researched in detail by \textcite{langhammer2017a}.
We do, however, not consider such behavioral specifications in our case studies, for which we explain the reasons in \autoref{chap:networks:notions:types}.

\begin{table}
	\centering 
    \small
    \renewcommand{\arraystretch}{1.4}
    \rowcolors{2}{\secondlinecolor}{\firstlinecolor}
	\begin{tabular}{p{3cm} p{6.8cm}}
		\toprule
        \textbf{\gls{UML} Element}  & \textbf{Java Code Element} \\
        \midrule
        Package                         & Package\\
		Class                           & Class\\
		Enum		                    & Enum \\
		Interface		   	            & Interface \\
        Method                          & Method \\
        Parameter $[$0-1 .. 1$]$        & Parameter of same type \\
        Parameter $[$0-* .. 2-*$]$      & Parameter of collection type with type parameter \\
        Field $[$0-1 .. 1$]$            & Field of same type\\
        Field $[$0-* .. 2-*$]$          & Field of collection type with type parameter\\
        Association $[$0-1 .. 1$]$      & Field of same type\\
        Association $[$0-* .. 2-*$]$    & Field of collection type with type parameter\\
		\bottomrule
	\end{tabular}
	\caption[Consistency relation between \acrshort{UML} and Java]{Consistency relations between \gls{UML} class models and Java code.}
	\label{tab:foundations:uml_java_rules}
\end{table}

\mnote{Relations between \gls{UML} and Java}
\autoref{tab:foundations:uml_java_rules} shows the relevant consistency relations between \gls{UML} models and Java code.
They reflect the intuitive notion of the relation between \gls{UML} and Java of mostly one-to-one mappings, since we do only consider Java elements that are present in the abstraction provided by the \gls{UML}, i.e., we do especially not consider method bodies.
The only special cases are fields having a type of another class in Java, which can also be expressed as associations in \gls{UML}, as well as parameters, fields and associations, which can have multiplicities in \gls{UML} that have to be expressed as collection types with an appropriate type parameter in Java if the upper bound is higher than $1$.


\section{Mathematical Notations}
\label{chap:foundations:notations}

\begin{table}
    \centering
    \small
    \renewcommand{\arraystretch}{1.4}%
    \rowcolors{1}{\firstlinecolor}{\secondlinecolor}
    \begin{tabular}{L{10em} L{17em}}
        \toprule
        %\rowcolor{\headinglinecolor}
        \textbf{Notation} & \textbf{Description} \\
        \midrule
        %\multicolumn{2}{c}{Notations}\\
        $\set{S} = \set{s} = \setted{a, b, \ldots}$ 
            & A set $\set{S}$ or $\set{s}$ of elements\\
        $\tuple{T} = \tuple{t} = \tupled{a, b, \ldots}$ 
            & A tuple $\tuple{T}$ or $\tuple{t}$ of elements\\
        $\sequence{S} = \sequence{s} = \sequenced{a, b, \ldots}$ 
            & A sequence $\sequence{S}$ or $\sequence{s}$ of elements\\
        $\sequenceindex{S}{i}$ 
            & Element at index $i$ of sequence $\sequence{S}$\\
        $\function{Func}$ 
            & A function\\
        \bottomrule
    \end{tabular}
    \caption[Notations for sets, tuples, sequences and functions]{Notations for sets, tuples, sequences and functions.}
    \label{tab:foundations:notation}
\end{table}

\mnote{Notations overview}
For most of our definition, we use standard mathematical notations.
Whenever we deviate from that within the thesis, we explicitly denote it and define the used constructed.
We use specific formatting especially for sets, tuples, sequences and functions to ease their distinction.
We introduce this notation in \autoref{tab:foundations:notation}.
Additionally, we define some additional shortcut operators for tuples, which we frequently require throughout the thesis.

\mnote{Sets, tuples and sequences}
We usually denote variables representing sets of any kinds of elements in blackboard bold font $\set{S}{}$ and the definition of a set of elements by putting them in curly brackets, e.g., $\setted{a, b, \dots}$.
Likewise, we denote variables representing tuples of any kinds of elements in gothic font $\tuple{T}{}$ and write elements forming a tuple in angle brackets, e.g., $\tupled{a, b, \dots}$.
Finally, we denote variables representing sequences of any kinds of elements by subsequent square brackets $\sequence{S}$ and the definition of a sequence of elements by putting them into square brackets, e.g., $\sequenced{a, b, \dots}$.
To access an element at index $i$ of a sequence $\sequence{S}$, we write $\sequenceindex{S}{i}$.
We denote the addition of an element $e$ to a sequence $\sequence{S} = \sequenced{s_1, \dots, s_n}$ as:
\begin{align*}
    \sequence{S} + e \equalsperdefinition \sequenced{s_1, \dots, s_n, e}
\end{align*}
Sequences are mathematically equal to tuples, but we write them differently to make explicit that they represent an order of potentially equal elements, rather than combining different elements of potentially different types in tuples. This is why we explicitly define an access operator for contained elements of sequences.
We derive from the described formatting of sets and tuples in specific situations whenever the focus of the semantics of the variable is not that it is a set or a tuple.
For example, if we consider a relation, which is a set of tuples, we do not denote it in our set syntax, as its semantics is to be a relation and not a set.
If we consider a set of relations, however, we denote it in the described set syntax.
In every case, we ensure that the meaning of the variables stay clear from the context.

\mnote{Tuple operators}
We often use tuples to ensure that the elements can be indexed, although they cannot contain duplications and thus behave as sets if not interested in the order of elements.
Since we need to treat the tuples similar to sets in several situations, especially to describe that a tuple contains an element or that is has a specific relation to another tuple, we define several operators which treat them as sets.
For a tuple $\tuple{t} = \tupled{t_1, \dots, t_n}$, we say that:
\begin{align*}
    &
    e \in \tuple{t}{} \equivalentperdefinition \exists i \in \setted{1, \dots, n} : e = t_i
\end{align*}
For two tuples $\tuple{v}$ and $\tuple{w}$, we define:
\begin{align*}
    &
    \tuple{v} \subseteq \tuple{w} \equivalentperdefinition \forall e \in \tuple{v} : e \in \tuple{w} \\
    &
    \tuple{v} \cap \tuple{w} := \setted{e \mid e \in \tuple{v} \land e \in \tuple{w}}
\end{align*}
Note that the intersection of tuples is not a tuple but a set, because we are only interested in getting the elements contained in both tuples but do not need to match their order.

\mnote{Relation concatenation}
In several situations, we define binary relations, which are sets of pairs, i.e., tuples of two elements.
We define the concatenation of two relations to express their transitive relation.
For two binary relations $R_1 = \setted{\tupled{a_{l}, a_{r}}, %\tupled{a_{2,l}, a_{2,r}}, 
\dots}$ and $R_2 = \setted{\tupled{b_{l}, b_{r}}, %\tupled{b_{2,l}, b_{2,r}}, 
\dots}$, we define their concatenation $R_1 \concat R_2$ as:
\begin{align*}
    &
    R_1 \concat R_2 = \setted{\tupled{a,b} \mid \exists z : \tupled{a,z} \in R_1 \land \tupled{z,b} \in R_2}
\end{align*}
This conforms to the composition of relations often denoted as $R_1 ; R_2$.

\mnote{Functions and Composition}
We usually denote function names in small caps, e.g., $\function{Func}$.
For functions, we use the standard notation for their composition. For two functions $\function{F}_{1}$ and $\function{F}_{2}$, we denote their composition for an input $x$ as:
\begin{align*}
    &
    \function{F}_{1} \concatfunction \function{F}_{2}(x) \equalsperdefinition \function{F}_{1}(\function{F}_{2}(x))
\end{align*}




% \begin{copiedFrom}{ICMT}

%%% Define what a transformation networks is
% \section{Assumptions and Terminology from ICMT}
% \label{chap:properties:terminology}

% We shortly clarify our assumptions and introduce a terminology for consistency %and its preservation % based on definitions of models, consistency and consistency preservation 
% that we %later 
% use to explain our classification.
% %Short introduction of transformations (not deeply necessary on ICMT) -- leave out, put to assumptions
% %\subsection{Assumptions}
% %\label{sec:foundations:assumptions}
% %We consider incremental \acp{BX} for preserving consistency between models.
% %Furthermore, we 
% We assume that consistency of more than two types of models is specified using networks of \acp{BX} rather than multidirectional approaches for two reasons:
% First, it is easier to think about binary than about $n$-ary relations~\cite{stevens2017a}.
% Second, a domain expert usually only knows about consistency relations within a subset of all model types used to develop a system, so modularizing transformations is inevitable.
% It was also the result of a Dagstuhl seminar that \enquote{it seems likely that networks of bidirectional transformations suffice for specifying multidirectional transformations}~\cite[p. 7]{cleve2019dagstuhl}.
% Finally, we investigate of a subset of problems that can actually occur, as in a concrete scenario $n$-ary relations may exist that cannot be expressed by sets of binary relations.
% Although we limit our considerations to the assumed scenarios, most of our findings could also be extended to a modularization into smaller $n$-ary relations rather than binary relations.

%Furthermore, we focus on consistency preservation rather than only consistency checking.
%Therefore, we follow a \emph{normative} approach, which means that we always assume that a specification of consistency defines when models are consistent rather than having another, maybe information notion of consistency that has to be met and potentially validated.
%
% \begin{itemize}
%     \item Incremental
%     \item Bidirectional
%     \item Delta-based(!)
%     \item Normative
%     \item Binary modularization, with domain experts
% \end{itemize}
%
% \todoHeiko{Make assumptions explicit! (From Intro) Incremental, distributed development (divide and conquer), ...}
% \begin{itemize}
%     \item Repair, not only checking!
%     \item Incremental transformations for consistency preservation
%     \item Independent development of binary transformations by domain experts -> Necessity to independently develop and combine transformations afterwards
%     \item Normative: We define what is consistent (rather than defining consistency and checking it against a "real" relation)
% \end{itemize}
%
% \paragraph{Terminology}
%
% Failure, (Fault), Mistake, Cause - define?
%
%
%\subsection{Terminology}
%
%\subsection{Models}
% \label{sec:foundations:models}
%\todoHeiko{Nicht Metamodelle, sondern Model Sets sagen? Diese Mengen sind ja eigentlich keine Metamodelle, sondern werden von einem Metamodell induziert. Oder auch model type?}
%
%We provide short definitions for models and the specification of consistency, on which we build our classification to clearly separate the issues that we investigate.
%Provide a short formalization of what is necessary to later define the different issues, e.g., what do these issues mean in terms of a formal definition. \todoHeiko{do this here in ICMT paper or later in SoSym?}
%\subsubsection{Models and Metamodels}
%Our definition of models follows the one used by \textcite{stevens2017a}. 

% \begin{definition}[Model]
% A model $M = \{e_1, e_2, \ldots\}$ is a finite set of not further defined elements, such as objects, attribute and reference values.
% \end{definition}

% The exact representation of the model contents is not relevant for our work, which is why we use this lightweight definition. 
% It allows us to transfer the insights to arbitrary models, such as models that are conform to the \ac{EMOF}~\cite{mof}.

% \begin{definition}[Model Type]
% A model type $\mathcal{M} = \{M_1, M_2, \dots\}$ is the (usually but not necessarily infinite) set of all models $M_1, M_2, \dots$ that are instances of $\mathcal{M}$.
% \end{definition}

% %So for a model type $\mathcal{M}$, a model $M$ is considered an instance of $\mathcal{M}$ if and only if $M \in \mathcal{M}$.
% In the following, let a model $M_i$ be always an instance of model type $\mathcal{M}_i$.
% This definition constitutes an \emph{extensional description} of models and does not explicitly consider actual instantiation relations between classes and objects, attributes and their values etc., other than containment in the respective model type. 
% We also use the term \emph{metamodel} when referring to an abstract syntax of classes, attributes and associations, as defined in the OCL standard~\cite[A.1]{ocl}. 
% A metamodel constitutes an \emph{intensional description} of models, from which the model type could be derived by enumerating all valid instances, i.e., all models with arbitrary instantiations of classes, their attributes and associations.
%In fact, common definitions of metamodels require abstract specifications of elements and their relations, which can be instantiated. Our definition rather covers a description of models sets, which is appropriate for our case.

%\subsection{Consistency}
%\label{sec:foundations:consistency}

%In addition to models, we define the basic terms \emph{consistency specification}, % expressing the consistency constraints that have to hold, 
%and \emph{consistency preservation specification}: % , expressing the rules to preserve consistency after changes.

% \begin{definition}[Consistency Specification]
% \label{def:consistency_specification}
% A \emph{consistency specification} $\mathit{CS}$ for model types $\mathcal{M}_1, \ldots, \mathcal{M}_n$ is a relation $\mathit{CS} \subset \mathcal{M}_1 \times \ldots \times \mathcal{M}_n$ between models that are consistent. 
% % the tuples of instances of model types $\mathcal{M}_1 \times \ldots \times \mathcal{M}_n$ that are consistent.
% We denote a binary consistency specification for model types $\mathcal{M}_i$ and $\mathcal{M}_j$ as $\mathit{CS}_{i,j}$.
% \end{definition}

% %\todoHeiko{In der Relation zu sein heißt konsistent zu sein. D.h. wenn ich keine Einschränkungen bzgl. Konsistenz mache (alle Modelle sind konsistent zueinadner), enthält die Relation alle möglichen Paare von Modellen}

% %This way of defining consistency between models by enumerating consistent instances is comparable to \cite{stevens2017a}.
% Enumerating consistent instances to define consistency is comparable to \cite{stevens2017a}.
% %Enumerating consistent models is not practically applicable in contrast to constructive approaches that define how to construct consistent models, but it eases expressing properties of consistency. % mathematical statements about consistency.
% If there are no restrictions on when models are consistent, %all models are always consistent by definition, and 
% $\mathit{CS}$ % the consistency specification 
% contains all tuples of models.
% We denote restrictions for models to be in $\mathit{CS}$ as \emph{consistency constraints}.
% It would, in theory, also be possible to define $\mathit{CS}$ on an infinite number of model types. However, for ease of understanding and because of missing practical examples, we decided to fix the number of model types in a consistency specification.

% We primarily consider binary consistency specifications, which are the binary relations that define consistency pairs of models, %, which only specify consistent instances of two model types.
% and also binary specifications for consistency preservation, which are functions that restore consistency between two models after one of them was modified. 
% % We also consider binary specifications for consistency preservation, which concern the modification of one model and the update of it and a model of another type. 
% In the following, we introduce such consistency preservation specifications.
% %To simplify the composition of such functions between more than two model types, 
% Each consistency preservation specification concerns modifications in instances of two model types.
% However, instead of defining such a function on two model types, we define it on an arbitrary number of model types, but restrict modifications to instances of two of them.
% In consequence, a set of binary consistency preservation specifications for an arbitrary number of model types can be defined, whose signatures of input and output are all equal.
% This leads to a rather verbose definition of consistency preservation specifications, but eases the composition of such functions between more than two model types.
% If the function only considered the two involved model types, the composition definition would have to properly consider matching function signatures, whereas our definition allows the composition of all functions with each other.
% %Therefore, we define them on an arbitrary number of model types, but restrict modifications to two of them.
% A consistency preservation specification expects and returns a tuple of pairs, each representing a change by containing an original and a modified model.
% The original models in a tuple are always consistent, but a specification may update the modified models. % may be updated by the specification.

% \begin{definition}[Consistency Preservation Specification]
% \label{def:consistency_preservation_specification}
% % A consistency preservation specification $CPS_{CS}$ is a function for a consistency specification $CS$ that expects a tuple of original models, and one model having a modified state regarding one of the original ones, and maps it to a new set of models:
% % \begin{align*}
% %     CPS_{CS} : (\mathcal{M}_1), \ldots, \mathcal{M}_n, \mathcal{M}_i) \mapsto (\mathcal{M}_1, \times \ldots \times \mathcal{M}_n), i \in \{1, \ldots, n\}
% % \end{align*}
% % For a consistency specification $CS_{i, j}$, a \emph{consistency preservation specification} $CPS_{CS_{i.j}}$ is a function between a tuple of model pairs, each containing one original and one modified model of the same model type, and maps it to a new tuple of model pairs.
% % \begin{align*}
% %     CPS_{CS} : ((\mathcal{M}_1, \mathcal{M}_1), \ldots, (\mathcal{M}_n, \mathcal{M}_n) \mapsto ((\mathcal{M}_1, \mathcal{M}_1), \ldots, (\mathcal{M}_n, \mathcal{M}_n)
% % \end{align*}
% % so that for $M_1, \ldots, M_n$ with $(M_i, M_j) \in CS_{i,j}$ and modified instances $M'_i, M'_j$:
% % \begin{align*}
% %     & \forall M'_k \in \mathcal{M}_k, k \in \{1, \dots, n\}\backslash\{i\}:\\
% %     & \hspace{1em} ((M_1, M''_1), \ldots, (M_n, M''_n)) = CPS_{CS_{i,j}}((M_1, M'_1), \ldots, (M_n, M'_n)) \\
% %     & \hspace{2em} \Rightarrow CS_{i,j}(M''_i, M''_j) \land \forall k \in \{1, \dots, n\}\backslash\{i, j\} : M'_k = M''_k
% %     %
% % \end{align*}
% For a binary consistency specification $\mathit{CS}_{i, j}$, a \emph{consistency preservation specification} $\mathit{CPS}_{\mathit{CS}_{i,j}}$ is a partial function defined if $(M_i, M_j) \in \mathit{CS}_{i,j}$
% that maps a tuple of model pairs, each containing an original model $M_k \in \mathcal{M}_k$ and a modified model $M'_k \in \mathcal{M}_k$, to a new tuple of model pairs:
% \begin{align*}
%     \mathit{CPS}_{\mathit{CS}_{i,j}}: \hspace{0.3em} & \big( (\mathcal{M}_1, \mathcal{M}_1), \ldots, (\mathcal{M}_n, \mathcal{M}_n) \big) \rightarrow \big( (\mathcal{M}_1, \mathcal{M}_1), \ldots, (\mathcal{M}_n, \mathcal{M}_n) \big), \\[0.5em]
%     & \hspace{-3.1em} \big( (M_1, M'_1), \ldots, (M_i, M'_i), \ldots, (M_j, M'_j), \ldots, (M_n, M'_n) \big) \\
%     & \hspace{-3.1em} \mapsto \begin{cases}
%         \big( (M_1, M'_1), \ldots, (M_i, M''_i), \ldots, (M_j, M''_j), \ldots, (M_n, M'_n) \big) & (M_i, M_j) \in \mathit{CS}_{i,j} \\
%         \mathit{undefined} & \mathit{otherwise}
%     \end{cases}
% \end{align*}
% so that
% \begin{align*}
%     (M''_i, M''_j) \in \mathit{CS}_{i,j}
% \end{align*}
% %holds
% %\begin{align*}
%     %$(M''_1, \ldots, M''_n) \in CS$
% %\end{align*}
% % Furthermore, it holds that for models $M_1, \ldots, M_n$ with $(M_1, \ldots, M_n) \in CS$ and a modified instance $M'_i$ of model $M_i$ that 
% % \begin{align*}
% %     CPS_{CS}(M_1, \ldots, M_n, M'_i) \in CS
% % \end{align*}
% \end{definition}
% %\todoHeiko{Normativ klar machen: Wir definieren, was konsistent ist. Wenn wir CPS angeben, die alle auf leere Modelle abbilden, ist das valide}

% \noindent\textit{Remark:} %We assume a normative approach for defining consistency, so it is up to the developer to provide reasonable specifications. 
% A specification that always maps to empty models would be valid regarding our definition.
% It is up to the developer to provide reasonable specifications. 

%\noindent\textit{Remark:} %We assume a normative approach for defining consistency, so it is up to the developer to provide reasonable specifications. 
%A specification that always maps to empty models would be valid regarding our definition.
%It is up to the developer to provide reasonable specifications. 
%We assume a normative approach for defining consistency, so consistent is what a developer specifies as such. In consequence, a consistency preservation specification that always maps to a tuple of empty models would be valid in our definition.

%Usually, incremental model transformations are used to preserve consistency between models. 

% We consider binary consistency preservation specifications, which concern the modification of one model type and the update of that and one other type. 
% To able to concatenate those specifications, we restrict the number of models appropriately.

%This can be expressed by a consistency preservation specification that is specified on two model types, but to be able to easily concatenate binary consistency preservation specifications on different pairs of model types, we use the following definition that simply restricts the number of modified models appropriately.

% \begin{definition}[Binary Consistency Preservation Specification]
% \label{def:binary_consistency_preservation_specification}
% A binary consistency preservation specification $CPS_{CS{i,j}}$ for a binary consistency specification $CS_{i,j}$ is a function according to \autoref{def:consistency_preservation_specification}, which only changes $\mathcal{M}_i$ and $\mathcal{M}_j$, so that 
% %This means that for models $M_1, \ldots, M_n$ with $(M_1, \ldots, M_n) \in CS$ and modified instances $M'_1, \ldots, M'_n$
% %\begin{align*}
%     %((M_1, M''_1), \dots, (M_n, M''_n)) := CPS_{CS, \mathcal{M}_{i,j}}(M_1, \dots, M_n, M'_i)
% %\end{align*}
% %holds
% %\begin{align*}
%     $CS_{i,j}(M''_i, M''_j) \land \forall k \in \{1, \dots, n\}\backslash\{i, j\} : M'_k = M''_k$
% %\end{align*}
% \end{definition}

% We are interested in consistency preservation specifications that can be executed in arbitrary order, so that they finally terminate in a consistent state regarding all consistency specifications, comparable to a fixed-point iteration.
% Therefore, it is essential for all specifications to be hippocratic~\cite{stevens2010sosym}, so that no changes are performed when models are already consistent.
% Let $\mathcal{CPS}$ be a set of preservation specifications %\mathit{CPS}_1, \dots, \mathit{CPS}_k$ 
% for consistency specifications $\mathcal{CS}$. % = \{CS_1, \dots, CS_l\}$, 
% We denote the set of consistent model tuples regarding $\mathcal{CS}$ as $\mathfrak{M}_{\mathcal{CS}} = \{(M_1, \dots, M_n) \mid %\forall i, j, 0 \leq i,j \leq n : 
% \forall \mathit{CS}_{i,j} \in \mathcal{CS} : (M_i, M_j) \in \mathit{CS}_{i, j}\}$.
% We want to achieve that:
% \begin{align*}
%     & \forall (M_1, \dots, M_n) \in \mathfrak{M}_{\mathcal{CS}} : %\{(M_1, \dots, M_n) \mid \forall CS_{i,j} \in \mathcal{CS} \Rightarrow (M_i, M_j) \in CS_{i, j}\} : \\ %0 \leq i,j \leq n : \exists CS_{i,j} \in \mathcal{CS} \Rightarrow (M_i, M_j) \in CS_{i, j}\} : \\
%     % & \hspace{1em} 
%     \forall M'_1 \in \mathcal{M}_1, \dots, M'_n \in \mathcal{M}_n : \exists \mathit{CPS}_1, \dots, \mathit{CPS}_k \in \mathcal{CPS} : \\
%     %& \forall M_1, \dots, M_n \mid \big( \forall CS_{i,j} \in \mathcal{CS} : (M_i, M_j) \in CS_{i, j} \big) : \\ % (i,j) \mid 1 \leq i, j \leq n
%     %& \exists p \in \mathbb{N}: (CPS_1 \circ \dots \circ CPS_k)^p \big( (M_1, M'_1), \dots, (M_n, M'_n) \big) = \big( (M_1, M''_1), \dots, (M_n, M''_n) \big) \\
%     & \hspace{1em} \mathit{CPS}_1 \circ \dots \circ \mathit{CPS}_k \big( (M_1, M'_1), \dots, (M_n, M'_n) \big) = \big( (M_1, M''_1), \dots, (M_n, M''_n) \big) \\
%     & \hspace{2em} \land \forall \mathit{CS}_{i,j} \in \mathcal{CS} : (M''_i, M''_j) \in \mathit{CS}_{i, j} %\forall (i,j) \mid 1 \leq i, j \leq n : CS_{i, j}(M''_i, M''_j)
% \end{align*}

% This means that there is always a sequence of consistency preservation specification applications, potentially with multiple applications of the same specification, that ensures that the modified models in all tuples are consistent after applying it.

%\todoHeiko{Zunächst mal die Konkatenierung erklären. Wir nehmen an, dass in einer korrekten Spezifikation eine Konkatenation existiert, die für eine beliebige Änderung wieder ein konsistentes Modell ausspuckt. Dafür ist die Ausführungsreihenfolge der Spezifikationen egal. Da man in der Praxis nicht nur wissen muss, dass die Modelle nach einer ausreichend langen Ausführung der Spezifikationen konsistent sind, sondern auch terminieren muss, wird die hippocraticness Eigenschaft \cite{stevens2007a} vorausgesetzt, nach der Transformationen nichts tun, wenn die Modelle bereits konsistent sind. Cf. Fixpunktiteration} 

% Declarative transformation languages are usually well suited to define consistency specifications according to \autoref{def:consistency_specification}, 
% from which a consistency preservation specification is %, in the best case automatically, 
% derived. 
% Imperative transformation languages can be used to define consistency preservation specifications according to \autoref{def:consistency_preservation_specification}. 

% \end{copiedFrom} % ICMT

