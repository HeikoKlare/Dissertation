\chapter{Foundations and Notation
    \pgsize{10 p.}
}
\label{chap:foundations}

\mnote{Foundations overview}
In this chapter, we introduce fundamental concepts and notations that we use throughout this thesis.
We introduce modeling in terms of a notion of models and methods in which they are used, and depict important formalisms and frameworks for modeling. % namely the \gls{MOF} standard and its realization in \gls{EMF}.
We introduce the idea of multi-view modeling and in particular the \vitruv approach, which we employ for evaluations in this thesis, as well as the approach it was inspired by.
Finally, we introduce model transformations, in particular bidirectional transformations and languages to describe them. % and one specific language we use for the realization of our contributions.
After introducing the case studies used for our evaluations and, partly, for explanations of our contributions, we depict the mathematical notations that we use in this thesis.


\section{Modeling}
\label{chap:foundations:modeling}

\mnote{Models and their usage}
This thesis researches the employment of transformations to keep multiple models that are used to describe a single software systems consistent.
Therefore, we first introduce a notion of models and how to use them.


\subsection{Models and Model Theory}
\label{chap:foundations:modeling:models}

\cite{stachowiak1973modelltheorie-Book}
What are models? -> Stachowiak

mapping \cite[p.~131]{stachowiak1973modelltheorie-Book}
abstraction \cite[p.~132]{stachowiak1973modelltheorie-Book}
pragmatics \cite[p.~131]{stachowiak1973modelltheorie-Book}

\enquote{A model is an abstraction of something for the purpose of understanding it before building it.}~\cite[p.~15]{rumbaugh2005objectoriented-Book}

Can be just static representation of structure to understand how modular parts fit together or also predictions of properties of the system to build, like Palladio.

should answer questions in place of the actual system.
E.g., predict performance rather than measure it in productive system
Depict the architecture without reconstructing it from code


\subsection{Metamodels and Languages}
\label{chap:foundations:modeling:metamodels}

Metamodel describes how a valid model looks like. There is an instance-of relationship between models and their metamodel.
This conforms to the type and instance level relationship knowing from object-oriented programming, in which objects instantiate classes.
The programming language grammar, such as the Java language specification~\cite{gosling2018jls-specification}, can be considered a metamodel for programs of that language.

In the most simple case, a metamodel can be seen as a set of models, and a model is an instance of that metamodel when it is contained in that set. This is sometimes also referred to as \emph{model sets}~\cite{stevens2020BidirectionalTransformationLarge-SoSym}.
Usually, metamodels will be described with a formalism, which we discuss in more detail in \autoref{chap:foundations:formalisms}, which define of which elements a metamodel consists and how these elements instantiate in the models, along with constraints that define when a model is considered a valid instance.

Models are often understood, for example, as a UML class diagram, or at least depicted as such.
Models are however not only elements and relations between them, but these elements must also have a meaning, i.e., a semantics~\cite{harel2004semantics-Computer}, in the specific context they are used for, as aimed by the abstraction and pragmatics characteristics of Stachowiak's classification.

Analogous to programming languages, we usually consider modeling languages, which are the tools to specify models.
They also define the semantics of elements, often in terms of defining how they are transformed into another representation, such as code which has an execution semantics.
According to \textcite[p. 26]{voelter2013DslEngineering}, modeling languages consists of a specification of abstract and concrete syntax, as well as static and dynamic semantics.
static: set of constraints, type system rules language has to conform in addition to structure regarding abstract syntax
execution: meaning of the program/model when it is executed, for DSL realized by execution engine
Abstract syntax: data structure holding the semantically relevant information of the model (not layout information), typically a tree or graph
Concrete syntax: notations with which user can express models, e.g. textural, graphical, tabular

Instead of modeling languages, \textcite{voelter2013DslEngineering} use the term \emph{\gls{DSL}}.
Introduce the term "DSL" used in introduction. Refer to XML, as its used in introduction.
\Glspl{DSL} in comparison to \glspl{GPL} are supposed to increase productivity and conciseness for specifying models in a specific domain~\cite[p.~30]{voelter2013DslEngineering}.
A language is, however, not either domain-specific or general-purpose, but domain-specificity of a language is a gradual notion~\cite[p.~30]{voelter2013DslEngineering}.
\Glspl{DSL} are usually assumed to have restricted expressiveness~\cite[Chap.~2]{fowler2010dsls-Book}.

Say that "domain" can mean really different things.
DSL for software developers:
- Generic domain: e.g. software design (UML), performance properties (PCM)
- Application domain: e.g. automotive (ASEM/ASCET, Amalthea)
DSL for software tool developers:
- Language for specifying transformations, editors etc.
- For us especially transformation languages as we introduce later

In our work, two kinds of DSLs are relevant: the ones used by software developers, whose artifacts have to be kept consistent, and the transformation languages used by developers of transformation networks.
\citeauthor{voelter2013DslEngineering} distinguishes these kinds of DSLs as \emph{technical} and \emph{application domain} DLSs, although emphasizing that there is no clear border between them~\cite[p.~26]{voelter2013DslEngineering}.
Since we do not consider how far a language is domain-specific, we only use the general term \emph{modeling language}.

Metamodels are often only referred to as the abstract syntax of models~\cite[p.~27]{voelter2013DslEngineering}, whose semantics is defined by the modeling language it is used in.
In this thesis, we use a notion of models and metamodels that we will define more precisely in \autoref{chap:networks:models}, which does also not reflect the semantics of the models explicitly.
Some semantics of models is, however, represented implicitly when using transformations to define consistency, because defining that elements are to be transformed into each other actually gives them a semantics.


\subsection{Model-Driven Software Development}
\label{chap:foundations:modeling:mdsd}
Describe what MDSD is supposed to be

Coined in early 2000s.
Seen as natural continuation of improving abstraction, like before achieved by more powerful compilers and higher abstraction in programming languages.
Now further abstraction by MDSD (or MDD) by automating repetitive tasks such support for persistence or interoperability~\cite{atkinson2003mdd-Software}.

notion of \citeauthor{bezivin2005sosym} that \enquote{everything is a model}~\cite{bezivin2005sosym}
so even code can be considered a model and is considered a model in mdsd.
For example, metamodel for Java, which we use in this thesis~\cite{heidenreich2010jamopp-SLE}.

The \gls{MDA}~\cite{mda} proposed a \gls{MDSD} process using models at different levels of abstraction, namely computation-independent models, platform-independent models and platform-specific models.
It was supposed to enable one of the central goal of portability and platform-independence, by deriving the more specific models from the abstract ones as far as possible.

We do not assume such a restricted process, but consider \gls{MDSD} simply as the usage of multiple models to describe a system under construction, which do not only serve documentation purposes but which all or of which most contain at least some information that is not represented in the other models, while still sharing common information that, as a central part of the motivation of this thesis, need to be kept consistent.


\section{Modeling Formalisms and Frameworks}
\label{chap:foundations:formalisms}

\subsection{Meta-Object Facility}
\label{chap:foundations:formalisms:mof}
Discuss \gls{MOF}, especially \gls{EMOF} and how it is used to model things;
Discuss levels of UML;
Say why MOF is the relevant formalism for us which we base our considerations on.

Many relevant tools use MOF-compliant models, such as AUTOSAR or SysML.

Modeling Levels M1--M3

Elements of metamodels: types of objects, types of relations and attributes
Metaclass (also class, type of an object)
Reference (also association in UML, multiplicities, directionality)
Attribute (properties of an element, in general both metaclass as well as reference!, have data type with value range)

\begin{figure}
    \centering
    \input{figures/prologue/foundations/emof.tex}
    \caption[Simplified EMOF metamodelling language]{Simplified class diagram showing central \metaclasses of the EMOF metamodelling language~\cite[p. 27]{mof} (dotted lines denote indirect inheritance). Adapted from \cite[Fig. 2.2]{kramer2017a}.}
    \label{fig:foundations:emof}
\end{figure}


Other formalisms such as multi-level or deep modeling, which precisely separates ontological and linguistic modelling and, in the extreme case, allows in arbitrary number of levels. Idea already presented in early 2000s~\cite{atkinson2003mdd-Software}.
Goal is also to reduce accidental complexity introduced by artifical boundary to two modeling levels~\cite{atkinson2008reducingAccidentalComplexity-SoSym}.
This is complementary to the accidental complexity introduced by replicating information across different models, which we aim to manage with consistency preservation mechanism, as it concerns the accidental complexity within the single models due to restricted modeling capabilities.
Still, we focus on the modeling levels defined by UML as they are still state-of-practice in programming (single type and instance level) as well as in modeling at least considering mature tools like EMF (explained in following), whereas multi-level modeling has gained attention in the last years~\cite{atkinso2014multilevel-MLM} and tools are not as mature or at least not that widely adopted and sophisticated.



\subsection{EMF and Ecore}
\label{chap:foundations:formalisms:ecore}
Discuss \gls{EMF}, Ecore and the relation EMOF

Say that we define an own modelling formalism without precise specifications of the elements models consist of. We therefore rely on EMOF as the most general relevant standard for a modeling formalism.

Add graphics of relevant part of EMOF metamodel here, from Max' Diss

\begin{figure}
    \centering
    \input{figures/prologue/foundations/ecore.tex}
    \caption[Simplified Ecore metamodelling language]{Simplified class diagram showing central \metaclasses of the Ecore metamodelling language~\cite[p. 97]{steinberg2009emf}. Adapted from \cite[Fig. 2.3]{kramer2017a}.}
    \label{fig:foundations:ecore}
\end{figure}


%\subsection{Differences}
\label{chap:foundations:formalisms:differences}

Discuss differences between Ecore and EMOF, especially those relevant for the changes later and how the differences in general manifest in our formal framework

FROM MAX:
Different information and case distinctions are necessary to describe all possible model changes for modelling languages that follow the Essential Meta Object Facility (EMOF) standard or the Ecore variant. 
Both meta-modelling languages and the differences between them are described in \autoref{chap:foundations:modeling:models}.
Only two differences have a major effect on our change modelling language and the specifications language that use them:
\begin{longenumerate}%[1.]
\item In EMOF, properties can be typed using \metaclasses or using other data types, but in Ecore these are distinguished as references and attributes.
\item Ecore requires that all elements except for a root element are contained in exactly one container and EMOF only requires that all elements have at most one container~\cite[pp.\ 31-32]{mof}.
\end{longenumerate}
If we only consider these two differences, then Ecore can be seen as a refinement of EMOF, which only adds a more fine-grained distinction of properties and further containment restrictions.
Because of this refinement relation, we will first describe which information is necessary to represent model changes of EMOF-based models and then add further information and distinctions for Ecore-based models.
Finally, we briefly explain how we made all this information available in practice using a change modelling language.


%\subsection{Simplification}
\label{chap:foundations:formalisms:simplification}

Discuss how far we simplify the modeling concepts (or maybe do that later in the notation / formalization discussion at the end of foundations or in networks chapter)


TOOLING:
Many tools for EMF, such as editor frameworks, transformation languages, language workbenches etc.
Transformation languages discussed in following.
Language workbenches, e.g., Xtext~\cite{efftinge2006xtext-MSES,bettini2016Xtext-Book} for languages with textual syntax defined in terms of a grammar, from which the metamodel, parser etc. are derived and a compiler can be defined.
We use Xtext for implementing a prototype for the language that we proposed in this thesis and it is also used for language that we reuse, such as the \reactionslanguage introduced in one of the subsequent sections.

JaMoPP for treating Java code a model, as already introduced in \autoref{chap:foundations:modeling:mdsd}.
Capabilities for parsing and printing Java code to be represented as an Ecore model~\cite{heidenreich2010jamopp-SLE, heidenreich2009jamopp-report}.


\section{Multi-view Modeling}
\label{chap:foundations:multiview}

Multi-view modeling covers the general topic of describing a system by means of multiple views or, in general, models~\cite{reineke2017ProblemMultiView-SoSym}.
A key challenge in multi-view modeling is consistency, as we have motivated in \autoref{chap:introduction}~\cite{reineke2017ProblemMultiView-SoSym}.
Preserving consistency between multiple views is referred to as \emph{model repair}~\cite{macedo2017ModelRepairClassification-TSE}, \emph{consistency restoration}~\cite{stevens2010sosym, kramer2017a} or \emph{model synchronization}~\cite{diskin2016Taxonomy-JSS}, with slightly different meanings.
We, in general, refer to this as \emph{consistency preservation}.

Views have been defined in an ISO standard: \emph{architecture view} defined as expressing the system architecture regarding specific concerns \cite[p.~2]{iso42010}.
synthetic vs. projective~\cite[p.~22]{iso42010}
While synthetic composes system description of views, such that each of them represents some information not contained in the others, projective views derive the information completely from an underlying source and are thus only projections.
In projective approaches, the underlying source can, again, be seen as a model, such that views in projective approaches are projections of that model~\cite[Fig.~5]{klare2020Vitruv-JSS}.
This underlying model is called a \gls{SUM}~\cite[p.~210]{atkinson2010a}, which, like any model, conform to a metamodel, the \gls{SUMM}~\owncite[Def.~2]{klare2020Vitruv-JSS}.

In a projective approach, the problem of preserving consistency is transferred to ensuring consistency within the \gls{SUM}, from which the views are projected.
Consistency of this \gls{SUM} can be achieved in different ways~\owncite{meier2019modelsward,meier2020ccis}, especially depending on whether a \gls{SUM} is \emph{essential} or \emph{pragmatic}~\cite{atkinson2015realizationMultiView-EDOC}.
An essential \gls{SUM} is free of any redundancies or implicit dependencies, such that every instance of its \gls{SUMM} is inherently consistent, whereas a pragmatic \gls{SUM} can contain allow arbitrary redundancies and dependencies, which then have to be kept consistent by explicit mechanisms for consistency preservation, such a transformations.
While the former approach is followed by the \gls{OSM} approach, the latter is used in the \vitruv approach, which we depict in more detail in the following.


% \subsection{Consistency Preservation}
% \label{chap:foundations:multiview:consistency}

% Consistency vs. its preservation

% Terminology: model repair~\cite{macedo2017ModelRepairClassification-TSE}, consistency restoration~\cite{stevens2010sosym, kramer2017a}, model synchronization~\cite{diskin2016Taxonomy-JSS}

% Synchronization vs. incremental vs. concurrent


\subsection{Orthographic Software Modeling}
\label{chap:foundations:multiview:osm}

\gls{OSM}
Projective multi-view approach, based on essential SUMs~\cite{atkinson2010a}.
Focus actually on views, how to create and manage them, structured along dimensions and dynamically created on-demand from the SUM.
Consistency achieved through the SUM, which is inherently consistent.


\subsection{The \vitruv Framework}
\label{chap:foundations:multiview:vitruv}
Copies the idea of a SUM and projective views from \gls{OSM}.
Instead of an essential SUM, is uses a pragmatic SUM, which can contain redundancies and dependencies that are kept consistent.
The SUM internally consists of models, which are kept consistent by model transformations, denoted as a \vsum~\cite{klare2020Vitruv-JSS}.
It is motivated by the insight that constructing an essential, redundancy-free SUM is hard to achieve and that for compatibility with existing tools it may be easier to combine their metamodels with a synthetic approach, such that the view used by each tool is a projection of a single models within the V-SUM, whereas further projective views can be derived from the information of the models in the V-SUM, but ensuring their consistency with transformations.

Within a V-SUM, multiple models need to be kept consistent, which is one application area for the contributions of this thesis.
%\vitruv puts an abstraction layers of views onto the contributions of this thesis and defines a process of using and applying it. 
%\todo{Reflect this later in the Commonalities chapter by referring to the idea and saying how composition of Commonalities can even improve the approach.}
\vitruv serves both as a motivation for the contributions of this thesis, but its implementation in the \vitruv framework~\cite{vitruvFrameworkGithub} and especially its languages for consistency preservation serves as a basis for our prototypical implementation and validation purposes.
Additionally, we will see that the abstraction provided by a layer of projective views onto the models that are kept consistent in a V-SUM provides benefits of our approach for improving quality properties rather than using it standalone.
%Additionally, at some points (Commonalities), the usage of developed concepts provides even more benefits when not only used standalone but in combination with further ideas of \vitruv.

For \vitruv, we have provided a simple but sufficient formalism defining consistency~\cite{klare2020Vitruv-JSS}, on which the formalism in this thesis bases.
However, the formalism in this thesis will be more detailed and fine-grained.



\section{Model Transformations}
\label{chap:foundations:transformations}

Heart and soul of \gls{MDSD}~\cite{sendall2003modelTransformation-Software}.

According to \textcite{kleppe2003mdaExplained-Book}, transformation defines how to generate target model from a source model by a transformation definition.
Transformation definition consists of transformation rules, which in turn define how one or more constructs of the source language or metamodel are transformed into constructs of the target language or metamodel.

\begin{figure}
    \centering
    \input{figures/prologue/foundations/transformation_schema.tex}
    \caption[Transformation artifacts and their relations]{Artifacts of a transformation and transformation language, as well as their relations. Adapted from \cite[Fig.~9-5]{kleppe2003mdaExplained-Book}.}
    \label{fig:foundations:transformation}
\end{figure}

While \textcite{kleppe2003mdaExplained-Book} is specific to \gls{MDA} thus deriving more specific artifacts from abstract artifacts, this can be generalized to transformations between any languages.
Graphics as an abstraction and schematic representation of the process \cite[Fig.~9-5]{kleppe2003mdaExplained-Book}.
TODO: Adapt graphics such that transformation definition consists of transformation rules.
Transformation definitions and their rules need to fulfill some format expected by the transformation engine.
Often supported by a \emph{transformation definition language}~\cite[Sec. 9.2]{kleppe2003mdaExplained-Book}, or short \emph{transformation language} that generates appropriate artifacts.


Synchronization vs. incremental vs. concurrent -- cite something?

%\subsection{Properties}
\textcite{czarnecki2006a}: Feature models for transformations regarding many aspects

Important for us:
Directionality: Unidirectional vs. multidirectional (specifically bidirectional)
Incrementality: Source- and target-incrementality (latter is ordinary incrementality, former is kind of change-driven)

Also on language structure:
Paradigm: functional, logic
Value Specification: Constraint, Imperative Assignment

Much about rule scheduling: selection, iteration etc., but focused on rules of a single language

Intermediate structure: additional models often temporary for execution, especially traceability models


\subsection{Bidirectional Transformations}
\label{chap:foundations:transformations:bidirectional}
\todo{Introduce Transformations}

Compare multidirectional transformations with networks of transformations.
Refer for other consistency approaches to related work.

Correctness, hippocraticness!


\subsection{Transformation Languages}
\label{chap:foundations:transformations:languages}

\gls{QVT}, \gls{QVTR} with \gls{OCL}, \gls{VIATRA} etc.

\todo{Introduce especially \qvtr in detail to understand compatibility}
\todo{Introduce TGGs shortly}
\todo{Only refer to \gls{VIATRA}, but do not explain it in detail}

imperative vs. deklarative

transformation language can be seen as \glspl{DSL} (see \autoref{chap:foundations:modeling:metamodels}).


\subsection{The \reactionslanguage}
\label{chap:foundations:transformations:reactions}

Maybe move something from prototypical implementation in \autoref{chap:correctness_evaluation:categorization} here.

\vitruv framework defines transformation engines, executes rules according to some change propagation format.
\reactionslanguage generated rules according to that format.


\section{Case Studies}

\subsection{Domains: PCM, UML and Java}
\label{chap:foundations:case_studies:domains}

Introduce domains

Explain what PCM is used for, what essential elements are. Say that it is developed with EMF. Also introduce SEFFs, but say that we do not consider them (we also  mention that in the following relations section).
Depict a diagram representing each element. Cite book and tech report

Refer to UML standard and its UML2 realization as an Ecore model. Say that we focus on UML class models (and partly small extracts of component models), but in general only structural diagram types and no behavioral ones (refer standard).

Say why Java is a model, refer to JaMoPP.


\subsection{Consistency Relations}
\label{chap:foundations:case_studies:relations}

We explain our notions of consistency and, in particular, of consistency relations in detail in \autoref{chap:networks} and \autoref{chap:correctness}.
Broadly speaking, consistency relations define when one model is considered consistent to another.
We depict the consistency relations for the case study domains in such a general way that this broad notion of sufficient for comprehending them.
In the way we introduce the relations, they are supposed to mean that if some elements are present in model, according other elements need to be present in another model, such that for every \gls{UML} class a Java class with the same name has to exist.

\mnote{Two sets of underlying consistency relations}
The consistency relations between \gls{PCM}, \gls{UML} and Java consists of two parts.
First, the relations between \gls{PCM} and object-oriented design in both \gls{UML} and Java were defined and explained in detail by \citeauthor{langhammer2017a}~\cite{langhammer2015a, langhammer2017a}.
He, in particular, proposed different options for relations between \gls{PCM} and Java, which can be generalized to object-oriented design.
We selected the mapping of architectural components to classes and packages, as that is the one that was studied most intensively and whose implementation is most mature.
This conforms to the mapping that we have already sketched in \autoref{chap:introduction}.
Second, the relations between \gls{UML} and Java reflect the usually implicitly known mapping between the two languages, as both describe the object-oriented structure of a software system in a similar way.

\begin{table}
	\centering 
    \small
    \renewcommand{\arraystretch}{1.4}
    \rowcolors{2}{\secondlinecolor}{\firstlinecolor}
	\begin{tabular}{p{3.2cm} p{6.6cm}}
		\toprule
        \textbf{\gls{PCM} Element}  & \textbf{Object-oriented Design Element} \\
        \midrule
		Repository              & Three packages: main, contracts, data types\\
		BasicComponent 		    & Package within the main package and a public component realization class within the package \\
		OperationInterface		& Interface in the contracts package \\
		Signature \& parameters & Method \& parameters \\
		CompositeDatatype       & Class with getter and setter (or appropriate read-only property) for inner types\\
		CollectionDatatypes     & Class that inherits from a collection type (e.g., \texttt{ArrayList} in Java) \\
		RequiredRole		    & Field typed with required interface in the component realization class and constructor parameter for the field in the component realization class\\
		ProvidedRole		    & Component realization class of providing component implements the provided interface\\
		\bottomrule
	\end{tabular}
	\caption[Consistency relations between \acrshort{PCM} and \acrshort{UML}/Java]{Consistency relations between elements of the \gls{PCM} repository metamodel and object-oriented design elements (\gls{UML}/Java). Adapted from \cite[Table 4.1]{langhammer2017a}.}
	\label{tab:foundations:pcm_oo_rules}
\end{table}

\mnote{Relations between \gls{PCM} and object-oriented design}
\autoref{tab:foundations:pcm_oo_rules} sketches the relevant consistency relations between \gls{PCM} models and object-oriented design, which can be reflected in both \gls{UML} and Java.
A \gls{PCM} repository model consists of data types, interfaces and components, which are all contained in one repository.
The repository is represented as a package structure of three packages in object-oriented design.
Each component is represented as a package containing a so called \emph{component realization class}.
Interfaces with their signatures and parameters are mapped to corresponding object-oriented elements as they are.
Composite data types are represented as a class containing the composed types, and collection data types are represented as subclasses of a collection type.
Finally, provided and required roles define that a component provides or requires an interface.
Provided roles are realized by an implementation of the provided interfaces in the component realization class.
A required role, on the contrary, is represented as a field in the component realization class, which must be set via a constructor parameter.
All these relations include further constraints for their features, especially their names, such as the field representing a required role has to have the same name as the role.

\mnote{Behavioral consistency of \gls{PCM} and Java}
\gls{PCM} models can also contain \emph{service effect specifications}, which are an abstract specification of the behavior of a service provided by a component.
Consistency between these behavior specifications in \gls{PCM} and their implementation in Java code was researched in detail by \textcite{langhammer2017a}.
We do, however, not consider such behavioral specifications in our case studies, for which we explain the reasons in \autoref{chap:networks:notions:types}.

\begin{table}
	\centering 
    \small
    \renewcommand{\arraystretch}{1.4}
    \rowcolors{2}{\secondlinecolor}{\firstlinecolor}
	\begin{tabular}{p{3cm} p{6.8cm}}
		\toprule
        \textbf{\gls{UML} Element}  & \textbf{Java Code Element} \\
        \midrule
        Package                         & Package\\
		Class                           & Class\\
		Enum		                    & Enum \\
		Interface		   	            & Interface \\
        Method                          & Method \\
        Parameter $[$0-1 .. 1$]$        & Parameter of same type \\
        Parameter $[$0-* .. 2-*$]$      & Parameter of collection type with type parameter \\
        Field $[$0-1 .. 1$]$            & Field of same type\\
        Field $[$0-* .. 2-*$]$          & Field of collection type with type parameter\\
        Association $[$0-1 .. 1$]$      & Field of same type\\
        Association $[$0-* .. 2-*$]$    & Field of collection type with type parameter\\
		\bottomrule
	\end{tabular}
	\caption[Consistency relation between \acrshort{UML} and Java]{Consistency relations between \gls{UML} class models and Java code.}
	\label{tab:foundations:uml_java_rules}
\end{table}

\mnote{Relations between \gls{UML} and Java}
\autoref{tab:foundations:uml_java_rules} shows the relevant consistency relations between \gls{UML} models and Java code.
They reflect the intuitive notion of the relation between \gls{UML} and Java of mostly one-to-one mappings, since we do only consider Java elements that are present in the abstraction provided by the \gls{UML}, i.e., we do especially not consider method bodies.
The only special cases are fields having a type of another class in Java, which can also be expressed as associations in \gls{UML}, as well as parameters, fields and associations, which can have multiplicities in \gls{UML} that have to be expressed as collection types with an appropriate type parameter in Java if the upper bound is higher than $1$.


\section{Mathematical Notations}
\label{chap:foundations:notations}

\begin{table}
    \centering
    \small
    \renewcommand{\arraystretch}{1.4}%
    \rowcolors{1}{\firstlinecolor}{\secondlinecolor}
    \begin{tabular}{L{10em} L{17em}}
        \toprule
        %\rowcolor{\headinglinecolor}
        \textbf{Notation} & \textbf{Description} \\
        \midrule
        %\multicolumn{2}{c}{Notations}\\
        $\set{S} = \set{s} = \setted{a, b, \ldots}$ 
            & A set $\set{S}$ or $\set{s}$ of elements\\
        $\tuple{T} = \tuple{t} = \tupled{a, b, \ldots}$ 
            & A tuple $\tuple{T}$ or $\tuple{t}$ of elements\\
        $\sequence{S} = \sequence{s} = \sequenced{a, b, \ldots}$ 
            & A sequence $\sequence{S}$ or $\sequence{s}$ of elements\\
        $\sequenceindex{S}{i}$ 
            & Element at index $i$ of sequence $\sequence{S}$\\
        $\function{Func}$ 
            & A function\\
        \bottomrule
    \end{tabular}
    \caption[Notations for sets, tuples, sequences and functions]{Notations for sets, tuples, sequences and functions.}
    \label{tab:foundations:notation}
\end{table}

\mnote{Notations overview}
For most of our definition, we use standard mathematical notations.
Whenever we deviate from that within the thesis, we explicitly denote it and define the used constructed.
We use specific formatting especially for sets, tuples, sequences and functions to ease their distinction.
We introduce this notation in \autoref{tab:foundations:notation}.
Additionally, we define some additional shortcut operators for tuples, which we frequently require throughout the thesis.

\mnote{Sets, tuples and sequences}
We usually denote variables representing sets of any kinds of elements in blackboard bold font $\set{S}{}$ and the definition of a set of elements by putting them in curly brackets, e.g., $\setted{a, b, \dots}$.
Likewise, we denote variables representing tuples of any kinds of elements in gothic font $\tuple{T}{}$ and write elements forming a tuple in angle brackets, e.g., $\tupled{a, b, \dots}$.
Finally, we denote variables representing sequences of any kinds of elements by subsequent square brackets $\sequence{S}$ and the definition of a sequence of elements by putting them into square brackets, e.g., $\sequenced{a, b, \dots}$.
To access an element at index $i$ of a sequence $\sequence{S}$, we write $\sequenceindex{S}{i}$.
We denote the addition of an element $e$ to a sequence $\sequence{S} = \sequenced{s_1, \dots, s_n}$ as:
\begin{align*}
    \sequence{S} + e \equalsperdefinition \sequenced{s_1, \dots, s_n, e}
\end{align*}
Sequences are mathematically equal to tuples, but we write them differently to make explicit that they represent an order of potentially equal elements, rather than combining different elements of potentially different types in tuples. This is why we explicitly define an access operator for contained elements of sequences.
We derive from the described formatting of sets and tuples in specific situations whenever the focus of the semantics of the variable is not that it is a set or a tuple.
For example, if we consider a relation, which is a set of tuples, we do not denote it in our set syntax, as its semantics is to be a relation and not a set.
If we consider a set of relations, however, we denote it in the described set syntax.
In every case, we ensure that the meaning of the variables stay clear from the context.

\mnote{Tuple operators}
We often use tuples to ensure that the elements can be indexed, although they cannot contain duplications and thus behave as sets if not interested in the order of elements.
Since we need to treat the tuples similar to sets in several situations, especially to describe that a tuple contains an element or that is has a specific relation to another tuple, we define several operators which treat them as sets.
For a tuple $\tuple{t} = \tupled{t_1, \dots, t_n}$, we say that:
\begin{align*}
    &
    e \in \tuple{t}{} \equivalentperdefinition \exists i \in \setted{1, \dots, n} : e = t_i
\end{align*}
For two tuples $\tuple{v}$ and $\tuple{w}$, we define:
\begin{align*}
    &
    \tuple{v} \subseteq \tuple{w} \equivalentperdefinition \forall e \in \tuple{v} : e \in \tuple{w} \\
    &
    \tuple{v} \cap \tuple{w} := \setted{e \mid e \in \tuple{v} \land e \in \tuple{w}}
\end{align*}
Note that the intersection of tuples is not a tuple but a set, because we are only interested in getting the elements contained in both tuples but do not need to match their order.

\mnote{Relation concatenation}
In several situations, we define binary relations, which are sets of pairs, i.e., tuples of two elements.
We define the concatenation of two relations to express their transitive relation.
For two binary relations $R_1 = \setted{\tupled{a_{l}, a_{r}}, %\tupled{a_{2,l}, a_{2,r}}, 
\dots}$ and $R_2 = \setted{\tupled{b_{l}, b_{r}}, %\tupled{b_{2,l}, b_{2,r}}, 
\dots}$, we define their concatenation $R_1 \concat R_2$ as:
\begin{align*}
    &
    R_1 \concat R_2 = \setted{\tupled{a,b} \mid \exists z : \tupled{a,z} \in R_1 \land \tupled{z,b} \in R_2}
\end{align*}
This conforms to the composition of relations often denoted as $R_1 ; R_2$.

\mnote{Functions and Composition}
We usually denote function names in small caps, e.g., $\function{Func}$.
For functions, we use the standard notation for their composition. For two functions $\function{F}_{1}$ and $\function{F}_{2}$, we denote their composition for an input $x$ as:
\begin{align*}
    &
    \function{F}_{1} \concatfunction \function{F}_{2}(x) \equalsperdefinition \function{F}_{1}(\function{F}_{2}(x))
\end{align*}




% \begin{copiedFrom}{ICMT}

%%% Define what a transformation networks is
% \section{Assumptions and Terminology from ICMT}
% \label{chap:properties:terminology}

% We shortly clarify our assumptions and introduce a terminology for consistency %and its preservation % based on definitions of models, consistency and consistency preservation 
% that we %later 
% use to explain our classification.
% %Short introduction of transformations (not deeply necessary on ICMT) -- leave out, put to assumptions
% %\subsection{Assumptions}
% %\label{sec:foundations:assumptions}
% %We consider incremental \acp{BX} for preserving consistency between models.
% %Furthermore, we 
% We assume that consistency of more than two types of models is specified using networks of \acp{BX} rather than multidirectional approaches for two reasons:
% First, it is easier to think about binary than about $n$-ary relations~\cite{stevens2017a}.
% Second, a domain expert usually only knows about consistency relations within a subset of all model types used to develop a system, so modularizing transformations is inevitable.
% It was also the result of a Dagstuhl seminar that \enquote{it seems likely that networks of bidirectional transformations suffice for specifying multidirectional transformations}~\cite[p. 7]{cleve2019dagstuhl}.
% Finally, we investigate of a subset of problems that can actually occur, as in a concrete scenario $n$-ary relations may exist that cannot be expressed by sets of binary relations.
% Although we limit our considerations to the assumed scenarios, most of our findings could also be extended to a modularization into smaller $n$-ary relations rather than binary relations.

%Furthermore, we focus on consistency preservation rather than only consistency checking.
%Therefore, we follow a \emph{normative} approach, which means that we always assume that a specification of consistency defines when models are consistent rather than having another, maybe information notion of consistency that has to be met and potentially validated.
%
% \begin{itemize}
%     \item Incremental
%     \item Bidirectional
%     \item Delta-based(!)
%     \item Normative
%     \item Binary modularization, with domain experts
% \end{itemize}
%
% \todoHeiko{Make assumptions explicit! (From Intro) Incremental, distributed development (divide and conquer), ...}
% \begin{itemize}
%     \item Repair, not only checking!
%     \item Incremental transformations for consistency preservation
%     \item Independent development of binary transformations by domain experts -> Necessity to independently develop and combine transformations afterwards
%     \item Normative: We define what is consistent (rather than defining consistency and checking it against a "real" relation)
% \end{itemize}
%
% \paragraph{Terminology}
%
% Failure, (Fault), Mistake, Cause - define?
%
%
%\subsection{Terminology}
%
%\subsection{Models}
% \label{sec:foundations:models}
%\todoHeiko{Nicht Metamodelle, sondern Model Sets sagen? Diese Mengen sind ja eigentlich keine Metamodelle, sondern werden von einem Metamodell induziert. Oder auch model type?}
%
%We provide short definitions for models and the specification of consistency, on which we build our classification to clearly separate the issues that we investigate.
%Provide a short formalization of what is necessary to later define the different issues, e.g., what do these issues mean in terms of a formal definition. \todoHeiko{do this here in ICMT paper or later in SoSym?}
%\subsubsection{Models and Metamodels}
%Our definition of models follows the one used by \textcite{stevens2017a}. 

% \begin{definition}[Model]
% A model $M = \{e_1, e_2, \ldots\}$ is a finite set of not further defined elements, such as objects, attribute and reference values.
% \end{definition}

% The exact representation of the model contents is not relevant for our work, which is why we use this lightweight definition. 
% It allows us to transfer the insights to arbitrary models, such as models that are conform to the \ac{EMOF}~\cite{mof}.

% \begin{definition}[Model Type]
% A model type $\mathcal{M} = \{M_1, M_2, \dots\}$ is the (usually but not necessarily infinite) set of all models $M_1, M_2, \dots$ that are instances of $\mathcal{M}$.
% \end{definition}

% %So for a model type $\mathcal{M}$, a model $M$ is considered an instance of $\mathcal{M}$ if and only if $M \in \mathcal{M}$.
% In the following, let a model $M_i$ be always an instance of model type $\mathcal{M}_i$.
% This definition constitutes an \emph{extensional description} of models and does not explicitly consider actual instantiation relations between classes and objects, attributes and their values etc., other than containment in the respective model type. 
% We also use the term \emph{metamodel} when referring to an abstract syntax of classes, attributes and associations, as defined in the OCL standard~\cite[A.1]{ocl}. 
% A metamodel constitutes an \emph{intensional description} of models, from which the model type could be derived by enumerating all valid instances, i.e., all models with arbitrary instantiations of classes, their attributes and associations.
%In fact, common definitions of metamodels require abstract specifications of elements and their relations, which can be instantiated. Our definition rather covers a description of models sets, which is appropriate for our case.

%\subsection{Consistency}
%\label{sec:foundations:consistency}

%In addition to models, we define the basic terms \emph{consistency specification}, % expressing the consistency constraints that have to hold, 
%and \emph{consistency preservation specification}: % , expressing the rules to preserve consistency after changes.

% \begin{definition}[Consistency Specification]
% \label{def:consistency_specification}
% A \emph{consistency specification} $\mathit{CS}$ for model types $\mathcal{M}_1, \ldots, \mathcal{M}_n$ is a relation $\mathit{CS} \subset \mathcal{M}_1 \times \ldots \times \mathcal{M}_n$ between models that are consistent. 
% % the tuples of instances of model types $\mathcal{M}_1 \times \ldots \times \mathcal{M}_n$ that are consistent.
% We denote a binary consistency specification for model types $\mathcal{M}_i$ and $\mathcal{M}_j$ as $\mathit{CS}_{i,j}$.
% \end{definition}

% %\todoHeiko{In der Relation zu sein heißt konsistent zu sein. D.h. wenn ich keine Einschränkungen bzgl. Konsistenz mache (alle Modelle sind konsistent zueinadner), enthält die Relation alle möglichen Paare von Modellen}

% %This way of defining consistency between models by enumerating consistent instances is comparable to \cite{stevens2017a}.
% Enumerating consistent instances to define consistency is comparable to \cite{stevens2017a}.
% %Enumerating consistent models is not practically applicable in contrast to constructive approaches that define how to construct consistent models, but it eases expressing properties of consistency. % mathematical statements about consistency.
% If there are no restrictions on when models are consistent, %all models are always consistent by definition, and 
% $\mathit{CS}$ % the consistency specification 
% contains all tuples of models.
% We denote restrictions for models to be in $\mathit{CS}$ as \emph{consistency constraints}.
% It would, in theory, also be possible to define $\mathit{CS}$ on an infinite number of model types. However, for ease of understanding and because of missing practical examples, we decided to fix the number of model types in a consistency specification.

% We primarily consider binary consistency specifications, which are the binary relations that define consistency pairs of models, %, which only specify consistent instances of two model types.
% and also binary specifications for consistency preservation, which are functions that restore consistency between two models after one of them was modified. 
% % We also consider binary specifications for consistency preservation, which concern the modification of one model and the update of it and a model of another type. 
% In the following, we introduce such consistency preservation specifications.
% %To simplify the composition of such functions between more than two model types, 
% Each consistency preservation specification concerns modifications in instances of two model types.
% However, instead of defining such a function on two model types, we define it on an arbitrary number of model types, but restrict modifications to instances of two of them.
% In consequence, a set of binary consistency preservation specifications for an arbitrary number of model types can be defined, whose signatures of input and output are all equal.
% This leads to a rather verbose definition of consistency preservation specifications, but eases the composition of such functions between more than two model types.
% If the function only considered the two involved model types, the composition definition would have to properly consider matching function signatures, whereas our definition allows the composition of all functions with each other.
% %Therefore, we define them on an arbitrary number of model types, but restrict modifications to two of them.
% A consistency preservation specification expects and returns a tuple of pairs, each representing a change by containing an original and a modified model.
% The original models in a tuple are always consistent, but a specification may update the modified models. % may be updated by the specification.

% \begin{definition}[Consistency Preservation Specification]
% \label{def:consistency_preservation_specification}
% % A consistency preservation specification $CPS_{CS}$ is a function for a consistency specification $CS$ that expects a tuple of original models, and one model having a modified state regarding one of the original ones, and maps it to a new set of models:
% % \begin{align*}
% %     CPS_{CS} : (\mathcal{M}_1), \ldots, \mathcal{M}_n, \mathcal{M}_i) \mapsto (\mathcal{M}_1, \times \ldots \times \mathcal{M}_n), i \in \{1, \ldots, n\}
% % \end{align*}
% % For a consistency specification $CS_{i, j}$, a \emph{consistency preservation specification} $CPS_{CS_{i.j}}$ is a function between a tuple of model pairs, each containing one original and one modified model of the same model type, and maps it to a new tuple of model pairs.
% % \begin{align*}
% %     CPS_{CS} : ((\mathcal{M}_1, \mathcal{M}_1), \ldots, (\mathcal{M}_n, \mathcal{M}_n) \mapsto ((\mathcal{M}_1, \mathcal{M}_1), \ldots, (\mathcal{M}_n, \mathcal{M}_n)
% % \end{align*}
% % so that for $M_1, \ldots, M_n$ with $(M_i, M_j) \in CS_{i,j}$ and modified instances $M'_i, M'_j$:
% % \begin{align*}
% %     & \forall M'_k \in \mathcal{M}_k, k \in \{1, \dots, n\}\backslash\{i\}:\\
% %     & \hspace{1em} ((M_1, M''_1), \ldots, (M_n, M''_n)) = CPS_{CS_{i,j}}((M_1, M'_1), \ldots, (M_n, M'_n)) \\
% %     & \hspace{2em} \Rightarrow CS_{i,j}(M''_i, M''_j) \land \forall k \in \{1, \dots, n\}\backslash\{i, j\} : M'_k = M''_k
% %     %
% % \end{align*}
% For a binary consistency specification $\mathit{CS}_{i, j}$, a \emph{consistency preservation specification} $\mathit{CPS}_{\mathit{CS}_{i,j}}$ is a partial function defined if $(M_i, M_j) \in \mathit{CS}_{i,j}$
% that maps a tuple of model pairs, each containing an original model $M_k \in \mathcal{M}_k$ and a modified model $M'_k \in \mathcal{M}_k$, to a new tuple of model pairs:
% \begin{align*}
%     \mathit{CPS}_{\mathit{CS}_{i,j}}: \hspace{0.3em} & \big( (\mathcal{M}_1, \mathcal{M}_1), \ldots, (\mathcal{M}_n, \mathcal{M}_n) \big) \rightarrow \big( (\mathcal{M}_1, \mathcal{M}_1), \ldots, (\mathcal{M}_n, \mathcal{M}_n) \big), \\[0.5em]
%     & \hspace{-3.1em} \big( (M_1, M'_1), \ldots, (M_i, M'_i), \ldots, (M_j, M'_j), \ldots, (M_n, M'_n) \big) \\
%     & \hspace{-3.1em} \mapsto \begin{cases}
%         \big( (M_1, M'_1), \ldots, (M_i, M''_i), \ldots, (M_j, M''_j), \ldots, (M_n, M'_n) \big) & (M_i, M_j) \in \mathit{CS}_{i,j} \\
%         \mathit{undefined} & \mathit{otherwise}
%     \end{cases}
% \end{align*}
% so that
% \begin{align*}
%     (M''_i, M''_j) \in \mathit{CS}_{i,j}
% \end{align*}
% %holds
% %\begin{align*}
%     %$(M''_1, \ldots, M''_n) \in CS$
% %\end{align*}
% % Furthermore, it holds that for models $M_1, \ldots, M_n$ with $(M_1, \ldots, M_n) \in CS$ and a modified instance $M'_i$ of model $M_i$ that 
% % \begin{align*}
% %     CPS_{CS}(M_1, \ldots, M_n, M'_i) \in CS
% % \end{align*}
% \end{definition}
% %\todoHeiko{Normativ klar machen: Wir definieren, was konsistent ist. Wenn wir CPS angeben, die alle auf leere Modelle abbilden, ist das valide}

% \noindent\textit{Remark:} %We assume a normative approach for defining consistency, so it is up to the developer to provide reasonable specifications. 
% A specification that always maps to empty models would be valid regarding our definition.
% It is up to the developer to provide reasonable specifications. 

%\noindent\textit{Remark:} %We assume a normative approach for defining consistency, so it is up to the developer to provide reasonable specifications. 
%A specification that always maps to empty models would be valid regarding our definition.
%It is up to the developer to provide reasonable specifications. 
%We assume a normative approach for defining consistency, so consistent is what a developer specifies as such. In consequence, a consistency preservation specification that always maps to a tuple of empty models would be valid in our definition.

%Usually, incremental model transformations are used to preserve consistency between models. 

% We consider binary consistency preservation specifications, which concern the modification of one model type and the update of that and one other type. 
% To able to concatenate those specifications, we restrict the number of models appropriately.

%This can be expressed by a consistency preservation specification that is specified on two model types, but to be able to easily concatenate binary consistency preservation specifications on different pairs of model types, we use the following definition that simply restricts the number of modified models appropriately.

% \begin{definition}[Binary Consistency Preservation Specification]
% \label{def:binary_consistency_preservation_specification}
% A binary consistency preservation specification $CPS_{CS{i,j}}$ for a binary consistency specification $CS_{i,j}$ is a function according to \autoref{def:consistency_preservation_specification}, which only changes $\mathcal{M}_i$ and $\mathcal{M}_j$, so that 
% %This means that for models $M_1, \ldots, M_n$ with $(M_1, \ldots, M_n) \in CS$ and modified instances $M'_1, \ldots, M'_n$
% %\begin{align*}
%     %((M_1, M''_1), \dots, (M_n, M''_n)) := CPS_{CS, \mathcal{M}_{i,j}}(M_1, \dots, M_n, M'_i)
% %\end{align*}
% %holds
% %\begin{align*}
%     $CS_{i,j}(M''_i, M''_j) \land \forall k \in \{1, \dots, n\}\backslash\{i, j\} : M'_k = M''_k$
% %\end{align*}
% \end{definition}

% We are interested in consistency preservation specifications that can be executed in arbitrary order, so that they finally terminate in a consistent state regarding all consistency specifications, comparable to a fixed-point iteration.
% Therefore, it is essential for all specifications to be hippocratic~\cite{stevens2010sosym}, so that no changes are performed when models are already consistent.
% Let $\mathcal{CPS}$ be a set of preservation specifications %\mathit{CPS}_1, \dots, \mathit{CPS}_k$ 
% for consistency specifications $\mathcal{CS}$. % = \{CS_1, \dots, CS_l\}$, 
% We denote the set of consistent model tuples regarding $\mathcal{CS}$ as $\mathfrak{M}_{\mathcal{CS}} = \{(M_1, \dots, M_n) \mid %\forall i, j, 0 \leq i,j \leq n : 
% \forall \mathit{CS}_{i,j} \in \mathcal{CS} : (M_i, M_j) \in \mathit{CS}_{i, j}\}$.
% We want to achieve that:
% \begin{align*}
%     & \forall (M_1, \dots, M_n) \in \mathfrak{M}_{\mathcal{CS}} : %\{(M_1, \dots, M_n) \mid \forall CS_{i,j} \in \mathcal{CS} \Rightarrow (M_i, M_j) \in CS_{i, j}\} : \\ %0 \leq i,j \leq n : \exists CS_{i,j} \in \mathcal{CS} \Rightarrow (M_i, M_j) \in CS_{i, j}\} : \\
%     % & \hspace{1em} 
%     \forall M'_1 \in \mathcal{M}_1, \dots, M'_n \in \mathcal{M}_n : \exists \mathit{CPS}_1, \dots, \mathit{CPS}_k \in \mathcal{CPS} : \\
%     %& \forall M_1, \dots, M_n \mid \big( \forall CS_{i,j} \in \mathcal{CS} : (M_i, M_j) \in CS_{i, j} \big) : \\ % (i,j) \mid 1 \leq i, j \leq n
%     %& \exists p \in \mathbb{N}: (CPS_1 \circ \dots \circ CPS_k)^p \big( (M_1, M'_1), \dots, (M_n, M'_n) \big) = \big( (M_1, M''_1), \dots, (M_n, M''_n) \big) \\
%     & \hspace{1em} \mathit{CPS}_1 \circ \dots \circ \mathit{CPS}_k \big( (M_1, M'_1), \dots, (M_n, M'_n) \big) = \big( (M_1, M''_1), \dots, (M_n, M''_n) \big) \\
%     & \hspace{2em} \land \forall \mathit{CS}_{i,j} \in \mathcal{CS} : (M''_i, M''_j) \in \mathit{CS}_{i, j} %\forall (i,j) \mid 1 \leq i, j \leq n : CS_{i, j}(M''_i, M''_j)
% \end{align*}

% This means that there is always a sequence of consistency preservation specification applications, potentially with multiple applications of the same specification, that ensures that the modified models in all tuples are consistent after applying it.

%\todoHeiko{Zunächst mal die Konkatenierung erklären. Wir nehmen an, dass in einer korrekten Spezifikation eine Konkatenation existiert, die für eine beliebige Änderung wieder ein konsistentes Modell ausspuckt. Dafür ist die Ausführungsreihenfolge der Spezifikationen egal. Da man in der Praxis nicht nur wissen muss, dass die Modelle nach einer ausreichend langen Ausführung der Spezifikationen konsistent sind, sondern auch terminieren muss, wird die hippocraticness Eigenschaft \cite{stevens2007a} vorausgesetzt, nach der Transformationen nichts tun, wenn die Modelle bereits konsistent sind. Cf. Fixpunktiteration} 

% Declarative transformation languages are usually well suited to define consistency specifications according to \autoref{def:consistency_specification}, 
% from which a consistency preservation specification is %, in the best case automatically, 
% derived. 
% Imperative transformation languages can be used to define consistency preservation specifications according to \autoref{def:consistency_preservation_specification}. 

% \end{copiedFrom} % ICMT

