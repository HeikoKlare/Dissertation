\chapter{Foundations and Notation
    \pgsize{10 p.}
}
\label{chap:foundations}

\mnote{Foundations overview}
In this chapter, we introduce fundamental concepts and notations that we use throughout this thesis.
We consider modeling in terms of a notion of models and methods in which they are used, and depict important formalisms and frameworks for modeling. % namely the \gls{MOF} standard and its realization in \gls{EMF}.
We introduce the idea of multi-view modeling and in particular the \vitruv approach, which we employ for evaluations in this thesis.
Finally, we discuss model transformations and languages to describe them. % and one specific language we use for the realization of our contributions.
After introducing the case studies used for our evaluations and, partly, for explanations of our contributions, we depict the mathematical notations that we use in this thesis.


%%%
%% MODELING
%%%
\section{Modeling}
\label{chap:foundations:modeling}

\mnote{Models and their usage}
This thesis researches the employment of transformations to keep multiple models, which are used to describe a single software systems, consistent.
Therefore, we first introduce a notion of models and how to use them.


\subsection{Models and Model Theory}
\label{chap:foundations:modeling:models}

\mnote{General model notion}
Models are a ubiquitous concept, which is used throughout many technical and non-technical domains.
The term \emph{model} is used differently in various contexts from informal depictions to mathematical formalizations~\cite{stachowiak1973modelltheorie-Book}.
In his work on general model theory, \citeauthor{stachowiak1973modelltheorie-Book} characterizes models by three criteria: representation, abstraction and pragmatics~\cite[p.~131--133]{stachowiak1973modelltheorie-Book}.

\begin{properdescription}
\item[Representation:] \mnote{Representation of an original}
The \emph{representation} characteristic requires a model to be a mapping or representation of some \emph{original}.
An original must not necessarily be a natural, existing entity, but can also be any kind of concept, which can, again, be a model~\cite[p.~131]{stachowiak1973modelltheorie-Book}.
We always consider models that are representations of a software-intensive system under construction.
This characteristic requires a model to contain no information that is not related to the system, such that, if the system and the model could be represented by a set of explicit properties, we would be able to define a mapping, or, more precisely, a homomorphism between them.

\item[Abstraction:] \mnote{Subset of properties of an original}
The \emph{abstraction} characteristic requires a model to, in general, only represent a subset of the properties of its original.
Properties are limited to those that seem relevant the creator of the model~\cite[p.~132]{stachowiak1973modelltheorie-Book}.
This abstraction should be driven by the pragmatics of the model, defined as the third characteristic.
For example, an architecture model of a software system may only represent properties relevant for some information need at the architectural level, which could, for example, abstract from behavior or implementation details.

\item[Pragmatics:] \mnote{Defined for specific purpose}
The \emph{pragmatic} characteristic requires a model to be designed for a specific purpose, such that it can only be related to its original for specific users, for specific points in time, and for specific operations~\cite[pp.~132]{stachowiak1973modelltheorie-Book}.
Models of software systems can, for example, have the purpose of depicting or editing the system structure or its behavior, or of performing some analyses or simulations for specific properties of the system.
The pragmatics influences the abstraction, as a specific purpose implies a certain information need to be provided by a proper abstraction.
\end{properdescription}

\mnote{Notion in software engineering}
While this is a rather general notion of a model, it also fits to the one relevant for software engineering, as depicted in the examples.
One appropriate definition for models in the domain of software design has been given by \citeauthor{rumbaugh2005objectoriented-Book}:
\enquote{A model is an abstraction of something for the purpose of understanding it before building it}~\cite[p.~15]{rumbaugh2005objectoriented-Book}.
This fits well to the notion of making predictions about the systems upfront, such as the already mentioned Palladio Simulator making performance predictions about a software systems based on an architectural model of it.
Models may, however, not only be used to understand the system, but also to build it, especially when considering code as a model as well.


\subsection{Metamodels and Languages}
\label{chap:foundations:modeling:metamodels}

\mnote{Metamodels and instance-of relations}
To automatically or semi-automatically process models, such as compiling source code, these models need to follow some specification, which can be considered a model that defines how a valid model for a specific purpose looks like.
Such a model of a model is often denoted as a \emph{metamodel}.
Models and their metamodels induce an \emph{instance-of} relationship, such that a metamodel can be considered the type of a model, and a model is considered an instance of a metamodel.
This conforms to the notion of type and instance level known from programming.
The grammar of a programming language, such as the Java language specification~\cite{gosling2018jls-specification}, can be considered a metamodel for programs of that language.

\mnote{Metamodels as sets of models}
In a simple notion, a metamodel can be considered as a set of models, such that a model is an instance of that metamodel if it is contained in that set. This is sometimes also referred to as \emph{model sets}~\cite{stevens2020BidirectionalTransformationLarge-SoSym}.
Usually, metamodels will be described with some formalism, which we discuss in more detail in \autoref{chap:foundations:formalisms}.
Such a formalism defines the elements of which a metamodel consists and how these elements are instantiated in the models, along with some constraints that a model has to fulfill to be considered a valid instance.

\mnote{Modeling languages}
Models, especially in software engineering, are often understood as structures of objects and relations between them, which can be depicted in \gls{UML} class diagrams.
Although this notion fits well to how we consider models and how we later define them more precisely, the elements of models must also have a meaning, i.e., a semantics~\cite{harel2004semantics-Computer}, in the specific context they are used for.
This semantics is given by the pragmatics characteristic of \citeauthor{stachowiak1973modelltheorie-Book}'s classification.
For models in software engineering, this semantics is usually defined by \emph{modeling languages} and tools defined for that modeling language, in which these models are defined and used.
These languages and tools, for example, transform models into another representation, i.e., into another model, for which the semantics is known
For code, execution semantics can be given by its compilation to machine code for some, potentially virtual, machine whose execution semantics is known.
This is known as \emph{transformational semantics}~\cite{pepper1987transformationalSemantics-SSPC}.

\mnote{Parts of modeling languages}
A modeling language consists of a specification of abstract and concrete syntax, as well as its static and execution semantics~\cite[p.~26]{voelter2013DslEngineering}.
\begin{properdescription}
    \item[Abstract Syntax:] Defines a data structure containing the relevant information about a system or program, usually in terms of a tree of graph.
    \item[Concrete Syntax:] The notation in which a user can express models, such as a textual or graphical representation.
    \item[Static Semantics:] A set of constraints that a model has to fulfill in addition to conforming to the syntax, for example, a type system.
    \item[Execution semantics:] The semantics of a program or model when it is executed, which can also be given by a transformation to another model. 
\end{properdescription}

\mnote{Domain-specific languages}
\textcite{voelter2013DslEngineering} use the term \emph{\gls{DSL}} instead of modeling language, which we have already referred to in \autoref{chap:introduction} at the example of \gls{XML}.
\Glspl{DSL} are supposed to increase productivity and conciseness for specifying models in a specific domain~\cite[p.~30]{voelter2013DslEngineering} in comparison to using a \emph{\gls{GPL}}.
A language is, however, not either domain-specific or general-purpose, but domain specificity of a language is a gradual notion~\cite[p.~30]{voelter2013DslEngineering}.
\Glspl{DSL} being designed for a specific domain are usually assumed to have restricted expressiveness~\cite[Chap.~2]{fowler2010dsls-Book}.
The term \emph{domain} can have different meanings.
\citeauthor{voelter2013DslEngineering} distinguish between \emph{technical} and \emph{application domain} \glspl{DSL}, although emphasizing that there is no clear border between them~\cite[p.~26]{voelter2013DslEngineering}.
In the context of this work, we can distinguish \glspl{DSL} used by software developers and \glspl{DSL} used by developers of software development tools.
\glspl{DSL} for software developers can again be separated into rather generic \glspl{DSL}, such as \gls{UML} for general software design and \gls{PCM} for general performance prediction, and rather application specific \glspl{DSL}, such as MATLAB/Simulink~\cite{simulink} or AUTOSAR~\cite{scheid2015autosar} in automotive software development.
\glspl{DSL} for software development tool developers cover languages to specify transformations and editors to be used for developing software and keeping software models consistent.
In this work, especially transformation languages used by developers of transformation networks to support software development are relevant, whereas languages of software developers are used to define the models that transformations have to keep consistent.
Since we are not concerned with domain specificity of a language, we only use the general term \emph{modeling language}.

\mnote{Metamodels as abstract syntax}
Metamodels are often considered as the abstract syntax of models~\cite[p.~27]{voelter2013DslEngineering}, whose semantics is defined by the modeling language it is used in.
In this thesis, we use a notion of models and metamodels that we define more precisely in \autoref{chap:networks:models}, which does also not reflect the semantics of the models explicitly.
Some semantics of models is, however, represented implicitly by the transformations preserving consistency.


\subsection{Model-Driven Software Development}
\label{chap:foundations:modeling:mdsd}

\mnote{Abstraction in software development}
\glsreset{MDSD}
\gls{MDSD}~\cite{stahl2006a} is a general term for the idea of increasing abstraction in software development by using models instead of or in addition to program code~\cite{atkinson2003mdd-Software}.
It also appears as \emph{model-driven software engineering} or simply \emph{model-driven development}~\cite{atkinson2003mdd-Software}.
It has been seen as the natural continuation of increasing abstraction, like achieved with more powerful compilers and higher abstraction in programming languages before, by automating repetitive tasks such as support for persistence or interoperability~\cite{atkinson2003mdd-Software}.
This especially includes that models are not only considered additional documentation artifacts, but central entities of the development process, from which even code can be derived.

\mnote{Development processes}
The \gls{MDA}~\cite{mda} proposed a standard for an \gls{MDSD} process, in which abstract, platform-independent and thus highly reusable and portable models of a system are used to generate code for different platforms.
It explicitly distinguishes between computation-independent, platform-independent and platform-specific models.
\citeauthor{voelter2013mdsd-Book} propose a more sophisticated process for \gls{MDSD}, in which repetitive and generic code is separated from individual code, such that repetitive code can be automatically generated and extended by individual code~\cite[Fig.~2.1]{voelter2013mdsd-Book}.

\mnote{Everything is a model}
We consider \gls{MDSD} as an even more generic process using any models to describe a system under construction, which do not only serve documentation purposes but which all contain some information that is not represented in the other models, while still sharing common information that, as a central part of the motivation of this thesis, need to be kept consistent.
Thus, we do especially not split the code into repetitive and individual code, as we also treat code as a model, which can be changed like the other models.
In this thesis, for example, we employ a metamodel for Java code~\cite{heidenreich2010jamopp-SLE}.
This follows the notion of \citeauthor{bezivin2005sosym} that \enquote{everything is a model}~\cite{bezivin2005sosym}.



%%%
%% MODELING FORMALISMS / FRAMEWORKS
%%%
\section{Modeling Formalisms and Frameworks}
\label{chap:foundations:formalisms}

\mnote{Formalisms for metamodels}
Models are instances of metamodels, as discussed in \autoref{chap:foundations:modeling:metamodels}, which usually rely on some formalism that defines which elements metamodels can contain and how they are instantiated in models.
Such a \emph{modeling formalism} can, again, be defined as a model of the metamodel, which is then called a \emph{\metametamodel}.
We call each of the instantiation levels of models and their metamodels as \emph{\metalevels}.
While, in general, there can be an arbitrary number of \metalevels, for practical reasons there has to be a topmost model in this hierarchy that is \emph{self-describing}.

\mnote{Concrete formalisms and a framework to use them}
We depict two modeling formalisms, the \emph{\acrlong{MOF}} and \emph{Ecore}, which are commonly used in software engineering and which we use in this thesis.
Using a common modeling formalism for all models and metamodels enables the application of common tooling to them, which, in our case, especially concerns transformations.
A \emph{modeling framework} provides the infrastructure for such common tooling of a modeling formalism.
Ecore belongs to the \emph{\acrlong{EMF}}, which defines an infrastructure for tooling on models and metamodels defined with Ecore, based on a code representation of models with a well-defined \gls{API}.


\subsection{Meta-Object Facility}
\label{chap:foundations:formalisms:mof}

\mnote{\acrshort{MOF}, \acrshort{EMOF} and \metalevels}
The \gls{MOF}~\cite{mof} is a standardized modeling formalism, i.e., it defines a self-describing \metametamodel that is also called \gls{MOF}.
It contains the \gls{EMOF}, which is a subset of the \gls{MOF} derived from class models in the \gls{UML}~\cite{uml}.
The \gls{MOF} standard does not prescribe a specific number of \metalevels~\cite[Sec.~7.3]{mof}.
We do, however, usually assume four \metalevels, as defined by the \gls{UML} standard~\cite{uml} and as used for Ecore as a realization of the \gls{EMOF}.
These \metalevels, denoted M3--M0, comprise the \metametamodel at M3, metamodels at M2, models at M1 and, finally, instances of models at M0.

\begin{figure}
    \centering
    \input{figures/prologue/foundations/emof.tex}
    \caption[Relevant subset of \acrshort{EMOF} modeling formalism]{Simplified class diagram with central \metaclasses of the \gls{EMOF} modeling formalism~\cite[p.~27]{mof}. Dotted lines denote indirect inheritance. Adapted from \cite[Fig. 2.2]{kramer2017a}.}
    \label{fig:foundations:emof}
\end{figure}

\mnote{Elements in the \acrshort{EMOF} \metametamodel}
The modeling formalism used in this work will be even more generic than the one proposed by the \gls{EMOF}, but can be considered a generalization of it.
For a less abstract understanding, the reader may, thus, have the \gls{EMOF} in mind and apply the discussions to it.
In addition, we denote examples and perform our evaluations with \gls{EMOF}-compliant models and metamodels.
To support this, we depict an important subset of the \gls{EMOF} \metametamodel as a \gls{UML} class diagram in \autoref{fig:foundations:emof}.
Comparable to class models in the \gls{UML}, the \gls{EMOF} defines classes consisting of properties, which have multiplicities and a type.
The type of a property can, again, be a class, but also an enumeration or a primitive type.
Each property has multiplicities that define an upper and lower bound for the number of elements to refer to.
In addition, a property defines whether it is composite, denoting that the elements referenced in an instance are to be considered contained in an instance of the class containing that property.
This simple structure of classes and relations between them leads to models and metamodels of the \gls{EMOF} that are mathematically equivalent to attributed, typed graphs with inheritance~\cite[Sec.~2.1.3.1]{kramer2017a}, such that they are widely applicable.
Even common engineering tools such as AUTOSAR~\cite{scheid2015autosar} and SysML~\cite{sysml} use \gls{MOF}-compliant models.

\mnote{Classes and \metaclasses}
We usually denote the types of model elements as \emph{\metaclasses} rather than classes, especially to avoid confusion with classes of \gls{UML} class models.
\gls{UML} class models, defined at M1, contain classes, which are instances of a \modelelement{Class} \metaclass in the \gls{UML} metamodel at M2, which, in turn, is an instances of the \modelelement{Class} \metaclass of the \gls{EMOF}.

% Elements of metamodels: types of objects, types of relations and attributes
% Metaclass (also class, type of an object)
% Reference (also association in UML, multiplicities, directionality)
% Attribute (properties of an element, in general both meta-class as well as reference!, have data type with value range)

\mnote{Multi-level modeling}
Since the restriction to type and instance level of models and metamodels at M1 and M2 increases accidental complexity in models~\cite{atkinson2008reducingAccidentalComplexity-SoSym}, other formalisms such as \emph{multi-level modeling} support an arbitrary number of \metalevels and precisely separate ontological and linguistic modeling~\cite{atkinson2003mdd-Software}.
This accidental complexity is complementary to the one introduced by replicating information across different models, which we aim to manage with consistency preservation mechanisms, as it concerns the accidental complexity within the single models due to restricted modeling capabilities.
Although multi-level modeling gained more attention in the last years~\cite{atkinson2014multilevel-MLM}, common modeling frameworks such as the \acrlong{EMF} are still restricted to linguistic instantiation relations between metamodels, models and their instances, which is why we stick to such formalisms in this thesis.


\subsection{Ecore and EMF}
\label{chap:foundations:formalisms:ecore}

\mnote{Eclipse Modeling Frameowkr}
The \gls{EMF}~\cite{steinberg2009emf} is a modeling framework for Eclipse, which is a plugin-based, extensible \gls{IDE}.
It uses the \metametamodel \emph{Ecore} and provides an infrastructure for defining tools on models based on Ecore.
This bases on a code generator for metamodels~\cite[pp.~237]{steinberg2009emf}, which does not only relieve the developer from manually specifying a metamodel as a data structure in code manually, but also ensures that the code provides a well-defined \gls{API}, on which tools can rely, as it is provided by any metamodel developed with \gls{EMF}.
This enables the definition of, for example, editor frameworks that only require configuration files for providing a sophisticated graphical editor for a model, or transformation languages that enable the definition of transformations between arbitrary Ecore metamodels.
Regarding \metalevels, \gls{EMF} provides the Ecore \metametamodel for which it allows the definition of metamodels and which can then be instantiated in models.

\begin{figure}
    \centering
    \input{figures/prologue/foundations/ecore.tex}
    \caption[Relevant subset of the Ecore modeling formalism]{Simplified class diagram with central \metaclasses of the Ecore modeling formalism~\cite[p.~107]{steinberg2009emf}. Adapted from \cite[Fig. 2.3]{kramer2017a}.}
    \label{fig:foundations:ecore}
\end{figure}

\mnote{Ecore \metametamodel}
Ecore can be considered a reference implementation of the \gls{EMOF} standard.
Thus, Ecore and \gls{EMOF} share most concepts, but, apart from minor structural and naming changes, Ecore provides some refinements compared to \gls{EMOF}.
We depict the relevant subset of the Ecore \metametamodel as a \gls{UML} class diagram in \autoref{fig:foundations:ecore}.
The most notably difference is that Ecore separates \gls{EMOF} properties, called \emph{features}, into attributes and references, of which attributes refer to enumerations and primitive types, whereas references refer to other classes.
In contrast to properties being composite in \gls{EMOF}, references in Ecore have an explicit \modelelement{containment} attribute.

\mnote{Relation to formalism in this thesis}
In this thesis, whenever referring to an existing modeling formalism rather than the more general one we propose, we use the terminology of Ecore.
The distinction of attributes and references in Ecore eases understanding as it conforms to the notion of class properties and associations in \gls{UML}.

\mnote{Tools and Xtext}
For \gls{EMF}, many tools such as editor frameworks, transformation languages and language workbenches have been developed.
We explicitly discuss transformation languages in \autoref{chap:foundations:transformations}.
Language workbenches allow the specification of modeling languages.
One such workbench is Xtext~\cite{efftinge2006xtext-MSES,bettini2016Xtext-Book} for defining languages with a textual concrete syntax.
It allows to define the language grammar from which it derives the metamodel in terms of an abstract syntax, as well as parsers and editors.
A compiler or generator can be defined to transform models in that language into another representation, such as executable code, giving them their semantics.
Such a language workbench can be used for languages to define domain models, but also for languages used as tooling in \gls{MDSD} processes.
We use Xtext for the implementation of the prototype of a transformation language that we propose in this thesis, and it has also been used to develop the \reactionslanguage, which is a transformation language that we introduced in \autoref{chap:foundations:transformations:reactions} and that we reuse for the evaluation in this thesis.

\mnote{Java code as a model}
As already introduced in \autoref{chap:foundations:modeling:mdsd}, code can also be considered a model.
For the representation of Java code as an Ecore model, JaMoPP has been proposed~\cite{heidenreich2010jamopp-SLE, heidenreich2009jamopp-report}.
It defines an Ecore metamodel for the Java language and also provides parsing and printing capabilities for treating Java source code files as Ecore models.



%%%
%% MULTI-VIEW MODEDLING
%%%
\section{Multi-view Modeling}
\label{chap:foundations:multiview}

\mnote{Consistency preservation in multi-view modeling}
Multi-view modeling covers the general topic of describing a system by means of multiple views or, in general, multiple models~\cite{reineke2019ProblemMultiView-SoSym}.
A key challenge in multi-view modeling is consistency~\cite{reineke2019ProblemMultiView-SoSym}, as we have motivated in \autoref{chap:introduction}.
Preserving consistency between multiple views is referred to as \emph{model repair}~\cite{macedo2017ModelRepairClassification-TSE}, \emph{consistency restoration}~\cite{stevens2010sosym, kramer2017a} or \emph{model synchronization}~\cite{diskin2016Taxonomy-JSS}, with slightly different meanings.
We, in general, refer to this as \emph{consistency preservation}.

\mnote{Synthetic and projective views}
The term \emph{architecture view} has been defined in the context of system architecture as an expression of the architecture regarding specific concerns in an ISO standard~\cite[p.~2]{iso42010}.
We generalize this to \emph{views} as representations of system extracts or properties regarding specific concerns.
Approaches for constructing views can be separated into \emph{synthetic} and \emph{projective} ones~\cite[p.~22]{iso42010}.
A synthetic approach composes a system description of views, such that each of them represents some information not contained in the others.
Projective approaches derive the information in a view completely from an underlying repository, thus views are only projections from that repository.
In projective approaches, the underlying repository can, again, be seen as a model, such that views in projective approaches are projections of that model~\cite[Fig.~5]{klare2020Vitruv-JSS}.
This underlying model is also called a \gls{SUM}~\cite[p.~210]{atkinson2010a}, which conforms to a metamodel, the \gls{SUMM}~\owncite[Def.~2]{klare2020Vitruv-JSS}.

\mnote{Single underlying models}
In a projective approach, the problem of preserving consistency between the views, as it is necessary in a synthetic approach, is transferred to ensuring consistency within the \gls{SUM}, from which the views are projected.
Consistency of this \gls{SUM} can be achieved in different ways~\owncite{meier2019modelsward,meier2020ccis}, especially depending on whether a \gls{SUM} is \emph{essential} or \emph{pragmatic}~\cite{atkinson2015realizationMultiView-EDOC}.
An essential \gls{SUM} is free of any redundancies or implicit dependencies, such that every instance of its \gls{SUMM} is inherently consistent, whereas a pragmatic \gls{SUM} can allow arbitrary redundancies and dependencies, which then have to be kept consistent by explicit mechanisms for consistency preservation, such as transformations.
While the former approach is followed by the \acrlong{OSM} approach, the latter is used in the \vitruv approach, which we depict in more detail in the following.

% \subsection{Consistency Preservation}
% \label{chap:foundations:multiview:consistency}

% Consistency vs. its preservation

% Terminology: model repair~\cite{macedo2017ModelRepairClassification-TSE}, consistency restoration~\cite{stevens2010sosym, kramer2017a}, model synchronization~\cite{diskin2016Taxonomy-JSS}

% Synchronization vs. incremental vs. concurrent


\subsection{Orthographic Software Modeling}
\label{chap:foundations:multiview:osm}

\mnote{View definition in \acrshort{OSM}}
\gls{OSM} is an approach to multi-view modeling based on the idea of an essential \gls{SUM} and proposed by \textcite{atkinson2010a}.
It assumes a \gls{SUM}, which is, in the best case, free of any redundancy and dependencies and thus inherently consistent.
The approach focuses on the creation and management of projective views from this \gls{SUM}~\cite[p.~211]{atkinson2010a}.
It proposes to structure these views along their properties spanning different dimensions, inducing a cube in which each cell potentially represents a views, at least if the associated combination of property values makes sense~\cite[p.~212]{atkinson2010a}.
Dimensions can be static, such as the abstraction level or the notation, or dynamic, such as the elements to display.
For example, one might select a graphical view at the architecture level for a specific component, or a textual view at the implementation level for a specific class.
These views are created dynamically and on-demand from the \gls{SUM}~\cite[p.~211]{atkinson2010a}, and views are assumed to be the only possibility to modify information in the \gls{SUM}.
Views, like models, base on a metamodel that defines how valid views have to look like, which is called a \emph{\viewtype}~\cite[p.~133]{goldschmidt2011diss}.

\mnote{Consistency in OSM}
Consistency in this approach is achieved by proper construction of a \gls{SUMM}, which ensures that instances are always consistent.
It requires transformations between the views and the \gls{SUM} to first generate a view and later propagate changes in the view back to the \gls{SUM}.
The approach does, however, not inherently solve the problem of concurrent modifications to different views to be merged.


\subsection{The \vitruv Approach}
\label{chap:foundations:multiview:vitruv}

\mnote{Construction of \vsums in \vitruv}
The \vitruv approach~\cite{klare2020Vitruv-JSS} bases on the \gls{OSM} idea of having a \gls{SUM} from which projective views are derived though which the information in the \gls{SUM} can be modified.
Instead of essential \glspl{SUM}, is uses pragmatic \glspl{SUM}, which can contain redundancies and dependencies that are kept consistent.
The \gls{SUM} internally consists of models, which are kept consistent by model transformations, called \emph{consistency preservation rules}, and is denoted as a \vsum~\cite[Def.~9]{klare2020Vitruv-JSS}.
The metamodel of a \vsum is denoted as a \vsumm~\cite[Def.~10]{klare2020Vitruv-JSS}.
It is motivated by the insight that constructing an essential, redundancy-free \gls{SUM} is hard to achieve~\cite{meier2020ccis}.
In addition, to achieve compatibility with existing tools and their modeling languages it may be easier to combine their metamodels with a synthetic approach, because then the view used by each tool is only a projection given by an isomorphism to one of the models within the \vsum~\cite{klare2020Vitruv-JSS}.
Still, in contrast to a purely synthetic approach, it allows to define further projective views derived from the information of the models in the \vsum.

\begin{figure}
    \centering
    \input{figures/prologue/foundations/vsum_cbse_example.tex}
    \caption[Exemplary \acrshort{VSUMM}]{Exemplarily \vsumm consisting of three metamodels for component-based development and exemplarily views derived from them. Adapted from~\cite[Fig.~4.4]{langhammer2017a}.}
    \label{fig:foundations:vsum_cbse_example}
\end{figure}

\mnote{Exemplary \vsum for component-based design}
\autoref{fig:foundations:vsum_cbse_example} depicts an exemplary \vsumm for component-based development, using Java for the source code representation, \gls{UML} for depicting object-oriented design, and \gls{PCM} for representing the architecture of the system and potentially performing quality predications.
These three metamodels form the \vsumm, whose instances can be accessed via views that can be instantiated from four exemplary \viewtypes.
$\mathvariable{VT}_1$ and $\mathvariable{VT}_3$ depict existing \viewtypes, already used as visualizations of \gls{UML} and \gls{PCM} models, whereas $\mathvariable{VT}_2$ and $\mathvariable{VT}_4$ represent \viewtypes projected from multiple models within a \vsum and potentially further information defined by the consistency preservation rules.
We will also introduce consistency between these metamodels as a case study used for explanations and evaluations of this thesis in \autoref{chap:foundations:case_studies}.

\mnote{\vitruv as motivation, application area and implementation base}
Within a \vsum, multiple models need to be kept consistent, which is one application area for the contributions of this thesis.
\vitruv serves both as a motivation for the contributions of this thesis, but its implementation in the \vitruv framework~\cite{vitruvFrameworkGithub} and especially its languages for consistency preservation also serve as a basis for our prototypical implementation and validation purposes.
For \vitruv, we have provided a simple but sufficient formalism defining consistency~\cite{klare2020Vitruv-JSS}.
The formalism in this thesis bases on it, but will be more detailed and fine-grained.
Additionally, we will see that the abstraction provided by a layer of projective views onto the models that are kept consistent in a \vsum provides additional benefits in our approach for improving quality properties explained in \autoref{chap:improvement} rather than using it standalone.


\section{Model Transformations}
\label{chap:foundations:transformations}

\mnote{Model transformation central to \gls{MDSD}}
In addition to models and formalisms to define them, model transformations are another central element of \gls{MDSD} processes.
They are sometimes considered the \enquote{heart and soul}~\cite{sendall2003modelTransformation-Software} of \gls{MDSD}.
Model transformations, which we also simply denote as \emph{transformations} throughout this thesis, generate one model or even code from another model.

\begin{figure}
    \centering
    \input{figures/prologue/foundations/transformation_schema.tex}
    \caption[Transformation artifacts and their relations]{Artifacts of a transformation and transformation language, as well as their relations. Adapted from \cite[Fig.~9-5]{kleppe2003mdaExplained-Book}.}
    \label{fig:foundations:transformation}
\end{figure}

\mnote{Relevant terms for model transformations}
According to \textcite{kleppe2003mdaExplained-Book}, a transformation defines how to generate a \emph{target model} from a \emph{source model} by a \emph{transformation definition}.
A transformation definition consists of \emph{transformation rules}, which in turn define how one or more constructs of the source language or metamodel are transformed into constructs of the target language or metamodel.
For example, a transformation definition may define how to transform a \gls{PCM} model into a \gls{UML} model, which consists of transformation rules, of which one could define how a component is transformed into a class.
Transformation definitions and their rules need to fulfill some format expected by the transformation engine, which is responsible for applying the transformation rules.
A transformation engine is often supported by a \emph{transformation definition language}~\cite[Sec. 9.2]{kleppe2003mdaExplained-Book}, or short \emph{transformation language}, in which transformation rules can be defined and from which appropriate artifacts for the transformation engine are generated.
These terms and their relations are depicted in \autoref{fig:foundations:transformation}, restricted to the usually considered situation of defining transformations between two metamodels, although they can, in general, transform between an arbitrary number of metamodels.
While the notions of \textcite{kleppe2003mdaExplained-Book} are specific to the \gls{MDA}, thus deriving more specific from abstract artifacts, we have generalized them to transformations between any languages.


\subsection{Properties and Bidirectional Transformations}
\label{chap:foundations:transformations:properties}

\mnote{Directionality and incrementality of transformations}
Transformations do not only support the simple case of taking one model and generating another, known as a \emph{batch transformation}, but there are several degrees of freedom how information from one or more models can be transferred into one or more other models by a transformation.
This also includes the incremental update of multiple models after concurrent changes for restoring consistency.
\textcite{czarnecki2006a} provides a classification of transformations regarding a variety of features.
For our use case, in particular \emph{directionality} and \emph{incrementality}~\cite[p.~14]{czarnecki2006a} are important.
\begin{properdescription}
    \item[Directionality:] Regarding directionality~\cite[Fig.~19]{czarnecki2006a}, transformations can be separated into unidirectional and multidirectional ones, of which the latter includes the well-researched bidirectional transformations.
    It describes whether a transformation can be applied in only one or multiple directions.
    For consistency preservation purposes, transformations usually need to be executed in multiple directions, depending on which of the models was changes and requires others to be updated.
    \item[Incrementality:] Incrementality \cite[Fig.~19]{czarnecki2006a} concerns \emph{source incrementality} and \emph{target incrementality}.
    We use the term incrementality specifically for target incrementality, which describes the ability of a transformation to update an existing target model after changes to the source model. This is essential for consistency preservation, because otherwise changes and additions made to the target models would become overwritten. For example, if Java code is generated from a \gls{UML} class model, then a change to the \gls{UML} model should incrementally update the Java code instead of generating it anew to avoid that additions to the code, such as method implementations, get lost.
    Target incrementality is also referred to as \emph{change propagation}.
    Source incrementality is about re-executing only transformation rules for changed parts of the source model.
    Instead of using this term, we later introduce the notion of \emph{delta-based} transformations, which operate on the actual source model changes.
\end{properdescription}

\mnote{Traceability models}
Another feature of transformations that is relevant for some of our contributions are \emph{intermediate structures}~\cite[p.~10]{czarnecki2006a}.
These structures concern additional models, which are often temporarily used for transformation execution, and especially include traceability models.
Traceability models represent which elements of the source and target model are related to each other by a transformation rule and, to enable incremental execution, are usually persisted in contrast to other structures~\cite[p.~10]{czarnecki2006a}.
These models define which model elements have some kind of dependency and thus serve as information about or even a witness for consistency, which can even be used to define transformations~\cite{diskin2017traceabilityMappings-fse}.

%\subsection{Bidirectional Transformations}
%\label{chap:foundations:transformations:bidirectional}

\mnote{Relations and consistency restorers}
Among all options from unidirectional to multidirectional transformations, \emph{bidirectional} transformations are the ones that are of most interest for consistency preservation and thus well-researched.
These transformations relate only two metamodels, which makes them less complex than other multidirectional transformations, but defines how to restore consistency in both directions between these metamodels~\cite{stevens2010sosym}, which is important for consistency preservation if instances of both models may be modified.
These transformations consist of a \emph{relation} defining when two models are considered consistent and two \emph{consistency restorers}, one for each direction.
A consistency restorer is a function that accepts two potentially inconsistent models and returns an updated instance of one of the models, depending on the direction.
There are also derivations that expect two consistent models and explicit changes to one or both of them, as we discuss more precisely when introducing our formalism.

\mnote{Correctness and hippocraticness}
Important properties of such transformations are \emph{correctness} and \emph{hippocraticness} as defined by \textcite{stevens2010sosym}.
A bidirectional transformation is correct if the resulting models are consistent, i.e., if the updated instance of one model and the input instance of the other model are in the relation of the transformation.
Hippocraticness of a transformation means that whenever the input models are consistent, the consistency restorer does not alter them.
Thus, consistent models can be considered fixed-points of a hippocratic transformation.
We recapture the notion of bidirectional transformations and the depicted properties later to define them more precisely for the formalism that we introduce in \autoref{chap:correctness}.

% Compare multidirectional transformations with networks of transformations.
% Refer for other consistency approaches to related work.

% Correctness, hippocraticness!


\subsection{Transformation Languages}
\label{chap:foundations:transformations:languages}

\mnote{Transformation engines and languages}
Although transformations can be implemented manually by directly modifying the models~\cite[p.~16]{czarnecki2006a}, they usually rely on some engine that accepts rules implemented for a specific \gls{API} and automate tasks such as scheduling or orchestrating the execution of transformation rules.
Such an engine can be defined on its own, but is often provided together with a transformation language, which uses a specific syntax for defining transformation rules and from which implementations of these rules for the specific \gls{API} of the engine are generated.
Transformation languages can be considered \glspl{DSL} (see \autoref{chap:foundations:modeling:metamodels}).
We have depicted these artifacts already in \autoref{fig:foundations:transformation}.

\mnote{Imperative and declarative languages}
Among various degrees of freedom to define a transformation language, just like a transformation itself, we especially distinguish between rather \emph{imperative} and \emph{declarative} transformation languages.
We say \enquote{rather} because being declarative is actually a gradual and not a total notion.
Imperative languages allow to define how consistency is restored whenever changes are performed, whereas a declarative language allows to define when models are considered consistent and the language derives how to restore this after changes.
This distinction is most relevant for us, because it maps to different concepts in our formalization, which we present in \autoref{chap:correctness}.
Although languages can actually contain imperative and declarative constructs, we make this rather broad distinction, as the basic distinction of whether the developer specifies how to preserve consistency or whether the language has to derive it from a declarative specification applies no matter whether the complete language or only single constructs of it can be considered declarative.
In the classification of \textcite{czarnecki2006a}, this is covered by different paradigms of transformation languages, especially distinguishing procedural and logic paradigms~\cite[Fig.~20]{czarnecki2006a}, depending on whether they describe how to achieve or restore consistency, or whether they only define the constraints, which usually come along with a specific way of specifying values~\cite[Fig.~20]{czarnecki2006a}, in particular imperative assignment and constraints.

\mnote{Opreational, relational and graph-based languages}
\textcite{czarnecki2006a} also distinguish different transformation approaches, such as operational, relational or graph-based approaches.
Although we usually only consider transformations and not the actual languages to define them, the languages we explicitly consider or even propose in this thesis follow either an operational approach, which imperatively specifies how to preserve consistency, or a relational approach, which declaratively specifies constraints between two metamodels.

\mnote{Languages of the \gls{QVT} standard}
Examples for transformation languages for the \gls{MOF} (see \autoref{chap:foundations:formalisms:mof}) are the languages of the \gls{QVT} standard~\cite{qvt}, namely \gls{QVTO}, an imperative, operational and unidirectional language, and \gls{QVTR}, a declarative, relational and bidirectional language.
\gls{QVTR} is relevant for this thesis, as we propose a practical realization of one of our approaches for that language.
It uses the \gls{OCL}~\cite{ocl} for specifying the constraints that have to hold between instances of two metamodels.
In general, \gls{QVTR} is even multidirectional and allows to define relations between multiple metamodels, but we only consider the bidirectional case.

\mnote{Language for the \gls{EMF}}
For the \gls{QVT} languages, implementations for the \gls{EMF} (see \autoref{chap:foundations:formalisms:ecore}) exist. Further common \gls{EMF}-based languages are \gls{VIATRA}~\cite{bergmann2015viatra-ICMT}, an imperative and unidirectional transformation language, and the \gls{ATL}~\cite{jouault2006a,martinez2017incrementalATL-SCP}, which is a hybrid language containing imperative and declarative constructs.
Another well-researched approach are \glspl{TGG}, originally developed as a graph transformation approach~\cite{schuerr1995a}, and later applied to \gls{EMF}~\cite{leblebici2014IncrementalTGGSurvey-GTVMT} with tools like eMoflon~\cite{anjorin2014diss}.

\todo{Need to discuss QVT-R more detailed?}

% imperative vs. declarative

% Also on language structure:
% Paradigm: functional, logic
% Value Specification: Constraint, Imperative Assignment


\subsection{The \reactions Language}
\label{chap:foundations:transformations:reactions}

\mnote{\Reactionslanguage and transformation engine}
The \vitruv framework (see \autoref{chap:foundations:multiview:vitruv}) provides several languages for defining consistency preservation~\cite{kramer2017a}. 
This especially comprises the \emph{\mappings language}~\cite{werle2016a}, which is a bidirectional, declarative language comparable to \qvtr, and the \emph{\reactionslanguage}~\cite{klare2016b} for defining imperative, unidirectional transformations.
While the \mappings language is used as a conceptual basis for the language that we propose in \autoref{chap:language}, the \reactionslanguage is of specific importance for this thesis, because we use it for prototypical implementations and evaluations.
The \vitruv framework defines a transformation engine, which processes changes performed to a model and calls given transformation rules that implement an \gls{API}, which accepts the processed changes and updates models that are accessed via a traceability model, which is called \emph{correspondence model}.
This correspondence model represents between which elements consistency has to be preserved.
The \reactionslanguage generates implementations of transformation rules according to this \gls{API} provided by the framework.
The \mappings language, in turn, generated specifications in the \reactionslanguage.

\lstinputlisting[%
float,%
language=reactions,
caption={[Reaction for creating classes for components]\reaction creating a \gls{UML} class for a \gls{PCM} component. Adapted from~\cite[Lst.~2]{klare2020Vitruv-JSS}.},
label={lst:foundations:reaction_example},
]{listings/prologue/foundations/reaction_example.tex}

\mnote{Example for \reactions}
A transformation rule defined in the \reactionslanguage is called a \emph{\reaction}.
To give an impression of how such rules look like, an example that transforms a \gls{PCM} component into a class with appropriate naming in \gls{UML} among its creation is depicted in \autoref{lst:foundations:reaction_example}.
A \reaction specifies after which type of change it should be executed, which, in this case, is the insertion of a component into a repository.
It may then call one or more reusable \emph{routines}, which are supposed to restore consistency.
Such a routine consists of a \emph{match} block, which checks whether it is responsible for restoring consistency and retrieves all relevant elements from the models and the correspondence model, and an \emph{action} block, which restores consistency.
In the example, the routine retrieves an appropriate package in the \gls{UML} model to place the class in.
It then creates a class, assigns it an appropriate name and adds a correspondence between the elements.
For the complete explanation of that example, we refer to previous work~\cite{klare2020Vitruv-JSS}.



%%%
%% CASE STUDIES
%%%
\section{Case Studies}
\label{chap:foundations:case_studies}

\mnote{Metamodels from component-based software engineering}
We use case studies from component-based software engineering for several examples in this thesis that are more realistic than the ones based on a running example introduced in \autoref{chap:networks:example} and for the evaluation of several of our contributions.
They cover a scenario already depicted in \autoref{chap:introduction}, which is based on three metamodels.
\gls{PCM}~\cite{reussner2016a} is used for defining the component-based architecture of a software system, \gls{UML}~\cite{uml} is used for depicting the fine-grained object-oriented design in terms of class models and Java~\cite{gosling2018jls-specification} depicts the implementation in code.
%\mnote{\gls{EMF} representation of metamodels}
The \gls{UML} is defined in a standard based on the \gls{MOF} and Java is specified with a grammar-based language specification.
Nevertheless, for all three languages an Ecore-based metamodel for \gls{EMF} (see \autoref{chap:foundations:formalisms:ecore}) exists.

\mnote{Elements of \gls{PCM}}
We assume basic concepts of class models of the \gls{UML} and Java, or in general object-oriented programming languages, to be known to the reader.
The elements of \gls{PCM} that we use in this thesis only require a broad understanding of those component-based architecture descriptions.
Basic elements are \emph{components}, \emph{interfaces} and \emph{data types}, which are all contained in a \emph{repository}.
Data types specific structures for data, including \emph{primitive types}, such as integers or strings, \emph{composite types}, which compose a type of multiple other types, and \emph{collection types}, which can contain multiple elements of a defined other data type.
Regarding interfaces we only consider \emph{operation interfaces}, which contain operation signatures consisting of return types and parameters, similar to methods in programming languages.
\gls{PCM} also provides further types of interfaces, which we do not consider in this thesis.
Finally, components define the reusable, architectural elements of a software systems.
They have \emph{provided} and \emph{required roles}, which define on which interfaces a component depends and which interfaces it provides to other components.
Since \gls{PCM} models do not only specify the architecture of a software system but enable predictions of its performance via simulation, they allow to define an abstract behavior specification of services provided by components, called \emph{service effect specifications}.
We do not explain them in more detail, as we do not consider these behavior specifications in this thesis.

%\subsection{Domains: PCM, UML and Java}
% \label{chap:foundations:case_studies:domains}

% Introduce domains

% Explain what PCM is used for, what essential elements are. Say that it is developed with EMF. Also introduce SEFFs, but say that we do not consider them (we also  mention that in the following relations section).
% Depict a diagram representing each element. Cite book and tech report

% Refer to UML standard and its UML2 realization as an Ecore model. Say that we focus on UML class models (and partly small extracts of component models), but in general only structural diagram types and no behavioral ones (refer standard).

% Say why Java is a model, refer to JaMoPP.


%\subsection{Consistency Relations}
%\label{chap:foundations:case_studies:relations}

\mnote{Intuitive notion of consistency}
In the case studies used in thesis, we consider a specific notion of consistency between \gls{PCM}, \gls{UML} and Java models.
We explain our notions of consistency and, in particular, of consistency relations in detail in \autoref{chap:networks} and \autoref{chap:correctness}.
Broadly speaking, consistency relations define under which conditions one model is considered consistent to another.
We depict the consistency relations for the metamodels of the case studies in such a general way that this broad notion is sufficient for comprehending them.
In the way we introduce the relations, they are supposed to mean that if some elements are present in a model, according other elements need to be present in another model, such as that for every \gls{UML} class a Java class with the same name has to exist.

\mnote{Two sets of underlying consistency relations}
The consistency relations between \gls{PCM}, \gls{UML} and Java consist of two parts.
First, the relations between \gls{PCM} and object-oriented design in both \gls{UML} and Java were defined and explained in detail by \citeauthor{langhammer2017a}~\cite{langhammer2015a, langhammer2017a}.
He, in particular, proposed different options for relations between \gls{PCM} and Java, which can be generalized to object-oriented design.
We have selected the mapping of architectural components to classes and packages, as that is the one that was studied most intensively and whose implementation is most mature.
This conforms to the mapping that we have already sketched in \autoref{chap:introduction}.
Second, the relations between \gls{UML} and Java reflect the usually implicitly known mapping between the two languages, as both describe the object-oriented structure of a software system in a similar way.

\begin{table}
	\centering 
    \small
    \renewcommand{\arraystretch}{1.4}
    \rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{p{3.2cm} p{6.6cm}}
		\toprule
        \textbf{\gls{PCM} Element}  & \textbf{Object-oriented Design Element} \\
        \midrule
		Repository              & Three packages: main, contracts, data types\\
		BasicComponent 		    & Package within the main package and a public component realization class within the package \\
		OperationInterface		& Interface in the contracts package \\
		Signature \& parameters & Method \& parameters \\
		CompositeDatatype       & Class with getter and setter for inner types\\
		CollectionDatatypes     & Class that inherits from a collection type (e.g., \texttt{ArrayList} in Java) \\
		RequiredRole		    & Field typed with required interface in the component realization class and constructor parameter for the field in the component realization class\\
		ProvidedRole		    & Component realization class of providing component implements the provided interface\\
		\bottomrule
	\end{tabular}
	\caption[Consistency relations between \acrshort{PCM} and \acrshort{UML}/Java]{Consistency relations between elements of the \gls{PCM} repository metamodel and object-oriented design elements (\gls{UML}/Java). Adapted from \cite[Table 4.1]{langhammer2017a}.}
	\label{tab:foundations:pcm_oo_rules}
\end{table}

\mnote{Relations between \gls{PCM} and object-oriented design}
\autoref{tab:foundations:pcm_oo_rules} sketches the relevant consistency relations between \gls{PCM} models and object-oriented design, which can be reflected in both \gls{UML} and Java.
A \gls{PCM} repository model consists of data types, interfaces and components, which are all contained in one repository.
The repository is represented as a package structure of three packages in object-oriented design.
Each component is represented as a package containing a so called \emph{component realization class}.
Interfaces with their signatures and parameters are mapped to corresponding object-oriented elements as they are.
Composite data types are represented as a class containing the composed types, and collection data types are represented as subclasses of a collection type.
%Finally, provided and required roles define that a component provides or requires an interface.
Provided roles are realized by an implementation of the provided interfaces in the component realization class.
A required role, on the contrary, is represented as a field in the component realization class, which must be set via a constructor parameter.
All these relations include further constraints for their features, especially regarding their names. %, such as the field representing a required role has to have the same name as the role.

\mnote{Behavioral consistency of \gls{PCM} and Java}
We have mentioned that \gls{PCM} models can also contain \emph{service effect specifications} as an abstract behavior specification of components, whose consistency to the implementaiton in Java was researched in detail by \textcite{langhammer2017a}.
We do, however, not consider such behavioral specifications in our case studies, for which we explain the reasons in \autoref{chap:networks:notions:types}.

\begin{table}
	\centering 
    \small
    \renewcommand{\arraystretch}{1.4}
    \rowcolors{1}{\firstlinecolor}{\secondlinecolor}
	\begin{tabular}{p{3cm} p{6.8cm}}
		\toprule
        \textbf{\gls{UML} Element}  & \textbf{Java Code Element} \\
        \midrule
        Package                         & Package\\
		Class / Enum                    & Class / Enum \\
		Interface		   	            & Interface \\
        Method                          & Method \\
        Parameter $[$0-1 .. 1$]$        & Parameter of same type \\
        Parameter $[$0-* .. 2-*$]$      & Parameter of collection type with type parameter \\
        Field $[$0-1 .. 1$]$            & Field of same type\\
        Field $[$0-* .. 2-*$]$          & Field of collection type with type parameter\\
        Association $[$0-1 .. 1$]$      & Field of same type\\
        Association $[$0-* .. 2-*$]$    & Field of collection type with type parameter\\
		\bottomrule
	\end{tabular}
	\caption[Consistency relation between \acrshort{UML} and Java]{Consistency relations between \gls{UML} class models and Java code.}
	\label{tab:foundations:uml_java_rules}
\end{table}

\mnote{Relations between \gls{UML} and Java}
\autoref{tab:foundations:uml_java_rules} shows the relevant consistency relations between \gls{UML} models and Java code.
They reflect the intuitive notion of the relation between \gls{UML} and Java of mostly one-to-one mappings, since we only consider Java elements that are present in the abstraction provided by the \gls{UML}, i.e., we do especially not consider method bodies.
The only special cases are fields having a type of another class in Java, which can also be expressed as associations in \gls{UML}, as well as parameters, fields and associations, which can have multiplicities in \gls{UML} that have to be expressed as collection types with an appropriate type parameter in Java if the upper bound is higher than $1$.


\section{Mathematical Notations}
\label{chap:foundations:notations}

\begin{table}
    \centering
    \small
    \renewcommand{\arraystretch}{1.4}%
    \rowcolors{1}{\firstlinecolor}{\secondlinecolor}
    \begin{tabular}{L{10em} L{17em}}
        \toprule
        %\rowcolor{\headinglinecolor}
        \textbf{Notation} & \textbf{Description} \\
        \midrule
        %\multicolumn{2}{c}{Notations}\\
        $\set{S} = \set{s} = \setted{a, b, \ldots}$ 
            & A set $\set{S}$ or $\set{s}$ of elements\\
        $\tuple{T} = \tuple{t} = \tupled{a, b, \ldots}$ 
            & A tuple $\tuple{T}$ or $\tuple{t}$ of elements\\
        $\sequence{S} = \sequence{s} = \sequenced{a, b, \ldots}$ 
            & A sequence $\sequence{S}$ or $\sequence{s}$ of elements\\
        $\sequenceindex{S}{i}$ 
            & Element at index $i$ of sequence $\sequence{S}$\\
        $\function{Func}$ 
            & A function\\
        \bottomrule
    \end{tabular}
    \caption[Notations for sets, tuples, sequences and functions]{Notations for sets, tuples, sequences and functions.}
    \label{tab:foundations:notation}
\end{table}

\mnote{Notations overview}
For most of our definitions, we use standard mathematical notations.
Whenever we deviate from that within the thesis, we explicitly denote it and define the used constructed.
We use specific formatting especially for sets, tuples, sequences and functions to ease their distinction.
We introduce this notation in \autoref{tab:foundations:notation}.
Additionally, we define some shortcut operators for tuples, which we frequently require throughout the thesis.

\mnote{Sets, tuples and sequences}
We usually denote variables representing sets of any kinds of elements in blackboard bold font $\set{S}{}$ and the definition of a set of elements by putting them in curly brackets, e.g., $\setted{a, b, \dots}$.
Likewise, we denote variables representing tuples of elements in gothic font $\tuple{T}{}$ and write elements forming a tuple in angle brackets, e.g., $\tupled{a, b, \dots}$.
Finally, we denote variables representing sequences of elements by subsequent square brackets $\sequence{S}$ and the definition of a sequence of elements by putting them into square brackets, e.g., $\sequenced{a, b, \dots}$.
To access an element at index $i$ of a sequence $\sequence{S}$, we write $\sequenceindex{S}{i}$.
We denote the addition of an element $e$ to a sequence $\sequence{S} = \sequenced{s_1, \dots, s_n}$ as:
\begin{align*}
    \sequence{S} + e \equalsperdefinition \sequenced{s_1, \dots, s_n, e}
\end{align*}
Sequences are mathematically equal to tuples, but we make them explicit as representation of an order of potentially equal elements, rather than combining elements of potentially different types in tuples. This is why we define an access operator for contained elements of sequences.
We deviate from the described formatting of sets and tuples in specific situations whenever the focus of the semantics of the variable is not that it is a set or a tuple.
For example, if we consider a relation that is a set of tuples, we do not denote it in our set syntax, as its semantics is to be a relation and not a set.
If we consider a set of relations, however, we denote it in the set syntax.
We ensure that the meaning of the variables stays clear from the context.

\mnote{Tuple operators}
We often use tuples to ensure that the elements can be indexed, although they cannot contain duplications and thus behave as sets if not interested in the order of elements.
Since we need to treat the tuples similar to sets in several situations, especially to describe that a tuple contains an element or that is has a specific relation to another tuple, we define several operators which treat them as sets.
For tuples $\tuple{t}$ and $\tuple{v}$ with $\tuple{t}{} = \tupled{t_1, \dots, t_n}$, we define:
\begin{align*}
    &
    e \in \tuple{t}{} \equivalentperdefinition \exists i \in \setted{1, \dots, n} : e = t_i \\
%\end{align*}
%For two tuples $\tuple{v}$ and $\tuple{w}$, we define:
%\begin{align*}
    &
    \tuple{t} \subseteq \tuple{v} \equivalentperdefinition \forall e \in \tuple{t} : e \in \tuple{v} \\
    &
    \tuple{t} \cap \tuple{v} \equalsperdefinition \setted{e \mid e \in \tuple{t} \land e \in \tuple{v}}
\end{align*}
Note that the intersection of tuples is not a tuple but a set, because we are not interested in matching their orders. %only interested in getting the elements contained in both tuples but do not need to match their order.

\mnote{Relation concatenation}
In several situations, we define binary relations, which are sets of pairs, i.e., tuples of two elements.
We define the concatenation of two relations to express their transitive relation.
For two binary relations $R_1 = \setted{\tupled{a_{l}, a_{r}}, %\tupled{a_{2,l}, a_{2,r}}, 
\dots}$ and $R_2 = \setted{\tupled{b_{l}, b_{r}}, %\tupled{b_{2,l}, b_{2,r}}, 
\dots}$, we define their concatenation $R_1 \concat R_2$ as:
\begin{align*}
    &
    R_1 \concat R_2 \equalsperdefinition \setted{\tupled{a,b} \mid \exists z : \tupled{a,z} \in R_1 \land \tupled{z,b} \in R_2}
\end{align*}
This conforms to the composition of relations often denoted as $R_1 ; R_2$.

\mnote{Functions and Composition}
We usually denote function names in small caps, e.g., $\function{Func}$.
For functions, we use the standard notation for their composition. For two functions $\function{F}_{1}$ and $\function{F}_{2}$, we denote their composition for an input $x$ as:
\begin{align*}
    &
    \function{F}_{1} \concatfunction \function{F}_{2}(x) \equalsperdefinition \function{F}_{1}(\function{F}_{2}(x))
\end{align*}




% \begin{copiedFrom}{ICMT}

%%% Define what a transformation networks is
% \section{Assumptions and Terminology from ICMT}
% \label{chap:properties:terminology}

% We shortly clarify our assumptions and introduce a terminology for consistency %and its preservation % based on definitions of models, consistency and consistency preservation 
% that we %later 
% use to explain our classification.
% %Short introduction of transformations (not deeply necessary on ICMT) -- leave out, put to assumptions
% %\subsection{Assumptions}
% %\label{sec:foundations:assumptions}
% %We consider incremental \acp{BX} for preserving consistency between models.
% %Furthermore, we 
% We assume that consistency of more than two types of models is specified using networks of \acp{BX} rather than multidirectional approaches for two reasons:
% First, it is easier to think about binary than about $n$-ary relations~\cite{stevens2017a}.
% Second, a domain expert usually only knows about consistency relations within a subset of all model types used to develop a system, so modularizing transformations is inevitable.
% It was also the result of a Dagstuhl seminar that \enquote{it seems likely that networks of bidirectional transformations suffice for specifying multidirectional transformations}~\cite[p.~7]{cleve2019dagstuhl}.
% Finally, we investigate of a subset of problems that can actually occur, as in a concrete scenario $n$-ary relations may exist that cannot be expressed by sets of binary relations.
% Although we limit our considerations to the assumed scenarios, most of our findings could also be extended to a modularization into smaller $n$-ary relations rather than binary relations.

%Furthermore, we focus on consistency preservation rather than only consistency checking.
%Therefore, we follow a \emph{normative} approach, which means that we always assume that a specification of consistency defines when models are consistent rather than having another, maybe information notion of consistency that has to be met and potentially validated.
%
% \begin{itemize}
%     \item Incremental
%     \item Bidirectional
%     \item Delta-based(!)
%     \item Normative
%     \item Binary modularization, with domain experts
% \end{itemize}
%
% \todoHeiko{Make assumptions explicit! (From Intro) Incremental, distributed development (divide and conquer), ...}
% \begin{itemize}
%     \item Repair, not only checking!
%     \item Incremental transformations for consistency preservation
%     \item Independent development of binary transformations by domain experts -> Necessity to independently develop and combine transformations afterwards
%     \item Normative: We define what is consistent (rather than defining consistency and checking it against a "real" relation)
% \end{itemize}
%
% \paragraph{Terminology}
%
% Failure, (Fault), Mistake, Cause - define?
%
%
%\subsection{Terminology}
%
%\subsection{Models}
% \label{sec:foundations:models}
%\todoHeiko{Nicht Metamodelle, sondern Model Sets sagen? Diese Mengen sind ja eigentlich keine Metamodelle, sondern werden von einem Metamodell induziert. Oder auch model type?}
%
%We provide short definitions for models and the specification of consistency, on which we build our classification to clearly separate the issues that we investigate.
%Provide a short formalization of what is necessary to later define the different issues, e.g., what do these issues mean in terms of a formal definition. \todoHeiko{do this here in ICMT paper or later in SoSym?}
%\subsubsection{Models and Metamodels}
%Our definition of models follows the one used by \textcite{stevens2017a}. 

% \begin{definition}[Model]
% A model $M = \{e_1, e_2, \ldots\}$ is a finite set of not further defined elements, such as objects, attribute and reference values.
% \end{definition}

% The exact representation of the model contents is not relevant for our work, which is why we use this lightweight definition. 
% It allows us to transfer the insights to arbitrary models, such as models that are conform to the \ac{EMOF}~\cite{mof}.

% \begin{definition}[Model Type]
% A model type $\mathcal{M} = \{M_1, M_2, \dots\}$ is the (usually but not necessarily infinite) set of all models $M_1, M_2, \dots$ that are instances of $\mathcal{M}$.
% \end{definition}

% %So for a model type $\mathcal{M}$, a model $M$ is considered an instance of $\mathcal{M}$ if and only if $M \in \mathcal{M}$.
% In the following, let a model $M_i$ be always an instance of model type $\mathcal{M}_i$.
% This definition constitutes an \emph{extensional description} of models and does not explicitly consider actual instantiation relations between classes and objects, attributes and their values etc., other than containment in the respective model type. 
% We also use the term \emph{metamodel} when referring to an abstract syntax of classes, attributes and associations, as defined in the OCL standard~\cite[A.1]{ocl}. 
% A metamodel constitutes an \emph{intensional description} of models, from which the model type could be derived by enumerating all valid instances, i.e., all models with arbitrary instantiations of classes, their attributes and associations.
%In fact, common definitions of metamodels require abstract specifications of elements and their relations, which can be instantiated. Our definition rather covers a description of models sets, which is appropriate for our case.

%\subsection{Consistency}
%\label{sec:foundations:consistency}

%In addition to models, we define the basic terms \emph{consistency specification}, % expressing the consistency constraints that have to hold, 
%and \emph{consistency preservation specification}: % , expressing the rules to preserve consistency after changes.

% \begin{definition}[Consistency Specification]
% \label{def:consistency_specification}
% A \emph{consistency specification} $\mathit{CS}$ for model types $\mathcal{M}_1, \ldots, \mathcal{M}_n$ is a relation $\mathit{CS} \subset \mathcal{M}_1 \times \ldots \times \mathcal{M}_n$ between models that are consistent. 
% % the tuples of instances of model types $\mathcal{M}_1 \times \ldots \times \mathcal{M}_n$ that are consistent.
% We denote a binary consistency specification for model types $\mathcal{M}_i$ and $\mathcal{M}_j$ as $\mathit{CS}_{i,j}$.
% \end{definition}

% %\todoHeiko{In der Relation zu sein heißt konsistent zu sein. D.h. wenn ich keine Einschränkungen bzgl. Konsistenz mache (alle Modelle sind konsistent zueinadner), enthält die Relation alle möglichen Paare von Modellen}

% %This way of defining consistency between models by enumerating consistent instances is comparable to~\cite{stevens2017a}.
% Enumerating consistent instances to define consistency is comparable to~\cite{stevens2017a}.
% %Enumerating consistent models is not practically applicable in contrast to constructive approaches that define how to construct consistent models, but it eases expressing properties of consistency. % mathematical statements about consistency.
% If there are no restrictions on when models are consistent, %all models are always consistent by definition, and 
% $\mathit{CS}$ % the consistency specification 
% contains all tuples of models.
% We denote restrictions for models to be in $\mathit{CS}$ as \emph{consistency constraints}.
% It would, in theory, also be possible to define $\mathit{CS}$ on an infinite number of model types. However, for ease of understanding and because of missing practical examples, we decided to fix the number of model types in a consistency specification.

% We primarily consider binary consistency specifications, which are the binary relations that define consistency pairs of models, %, which only specify consistent instances of two model types.
% and also binary specifications for consistency preservation, which are functions that restore consistency between two models after one of them was modified. 
% % We also consider binary specifications for consistency preservation, which concern the modification of one model and the update of it and a model of another type. 
% In the following, we introduce such consistency preservation specifications.
% %To simplify the composition of such functions between more than two model types, 
% Each consistency preservation specification concerns modifications in instances of two model types.
% However, instead of defining such a function on two model types, we define it on an arbitrary number of model types, but restrict modifications to instances of two of them.
% In consequence, a set of binary consistency preservation specifications for an arbitrary number of model types can be defined, whose signatures of input and output are all equal.
% This leads to a rather verbose definition of consistency preservation specifications, but eases the composition of such functions between more than two model types.
% If the function only considered the two involved model types, the composition definition would have to properly consider matching function signatures, whereas our definition allows the composition of all functions with each other.
% %Therefore, we define them on an arbitrary number of model types, but restrict modifications to two of them.
% A consistency preservation specification expects and returns a tuple of pairs, each representing a change by containing an original and a modified model.
% The original models in a tuple are always consistent, but a specification may update the modified models. % may be updated by the specification.

% \begin{definition}[Consistency Preservation Specification]
% \label{def:consistency_preservation_specification}
% % A consistency preservation specification $CPS_{CS}$ is a function for a consistency specification $CS$ that expects a tuple of original models, and one model having a modified state regarding one of the original ones, and maps it to a new set of models:
% % \begin{align*}
% %     CPS_{CS} : (\mathcal{M}_1), \ldots, \mathcal{M}_n, \mathcal{M}_i) \mapsto (\mathcal{M}_1, \times \ldots \times \mathcal{M}_n), i \in \{1, \ldots, n\}
% % \end{align*}
% % For a consistency specification $CS_{i, j}$, a \emph{consistency preservation specification} $CPS_{CS_{i.j}}$ is a function between a tuple of model pairs, each containing one original and one modified model of the same model type, and maps it to a new tuple of model pairs.
% % \begin{align*}
% %     CPS_{CS} : ((\mathcal{M}_1, \mathcal{M}_1), \ldots, (\mathcal{M}_n, \mathcal{M}_n) \mapsto ((\mathcal{M}_1, \mathcal{M}_1), \ldots, (\mathcal{M}_n, \mathcal{M}_n)
% % \end{align*}
% % so that for $M_1, \ldots, M_n$ with $(M_i, M_j) \in CS_{i,j}$ and modified instances $M'_i, M'_j$:
% % \begin{align*}
% %     & \forall M'_k \in \mathcal{M}_k, k \in \{1, \dots, n\}\backslash\{i\}:\\
% %     & \hspace{1em} ((M_1, M''_1), \ldots, (M_n, M''_n)) = CPS_{CS_{i,j}}((M_1, M'_1), \ldots, (M_n, M'_n)) \\
% %     & \hspace{2em} \Rightarrow CS_{i,j}(M''_i, M''_j) \land \forall k \in \{1, \dots, n\}\backslash\{i, j\} : M'_k = M''_k
% %     %
% % \end{align*}
% For a binary consistency specification $\mathit{CS}_{i, j}$, a \emph{consistency preservation specification} $\mathit{CPS}_{\mathit{CS}_{i,j}}$ is a partial function defined if $(M_i, M_j) \in \mathit{CS}_{i,j}$
% that maps a tuple of model pairs, each containing an original model $M_k \in \mathcal{M}_k$ and a modified model $M'_k \in \mathcal{M}_k$, to a new tuple of model pairs:
% \begin{align*}
%     \mathit{CPS}_{\mathit{CS}_{i,j}}: \hspace{0.3em} & \big( (\mathcal{M}_1, \mathcal{M}_1), \ldots, (\mathcal{M}_n, \mathcal{M}_n) \big) \rightarrow \big( (\mathcal{M}_1, \mathcal{M}_1), \ldots, (\mathcal{M}_n, \mathcal{M}_n) \big), \\[0.5em]
%     & \hspace{-3.1em} \big( (M_1, M'_1), \ldots, (M_i, M'_i), \ldots, (M_j, M'_j), \ldots, (M_n, M'_n) \big) \\
%     & \hspace{-3.1em} \mapsto \begin{cases}
%         \big( (M_1, M'_1), \ldots, (M_i, M''_i), \ldots, (M_j, M''_j), \ldots, (M_n, M'_n) \big) & (M_i, M_j) \in \mathit{CS}_{i,j} \\
%         \mathit{undefined} & \mathit{otherwise}
%     \end{cases}
% \end{align*}
% so that
% \begin{align*}
%     (M''_i, M''_j) \in \mathit{CS}_{i,j}
% \end{align*}
% %holds
% %\begin{align*}
%     %$(M''_1, \ldots, M''_n) \in CS$
% %\end{align*}
% % Furthermore, it holds that for models $M_1, \ldots, M_n$ with $(M_1, \ldots, M_n) \in CS$ and a modified instance $M'_i$ of model $M_i$ that 
% % \begin{align*}
% %     CPS_{CS}(M_1, \ldots, M_n, M'_i) \in CS
% % \end{align*}
% \end{definition}
% %\todoHeiko{Normativ klar machen: Wir definieren, was konsistent ist. Wenn wir CPS angeben, die alle auf leere Modelle abbilden, ist das valide}

% \noindent\textit{Remark:} %We assume a normative approach for defining consistency, so it is up to the developer to provide reasonable specifications. 
% A specification that always maps to empty models would be valid regarding our definition.
% It is up to the developer to provide reasonable specifications. 

%\noindent\textit{Remark:} %We assume a normative approach for defining consistency, so it is up to the developer to provide reasonable specifications. 
%A specification that always maps to empty models would be valid regarding our definition.
%It is up to the developer to provide reasonable specifications. 
%We assume a normative approach for defining consistency, so consistent is what a developer specifies as such. In consequence, a consistency preservation specification that always maps to a tuple of empty models would be valid in our definition.

%Usually, incremental model transformations are used to preserve consistency between models. 

% We consider binary consistency preservation specifications, which concern the modification of one model type and the update of that and one other type. 
% To able to concatenate those specifications, we restrict the number of models appropriately.

%This can be expressed by a consistency preservation specification that is specified on two model types, but to be able to easily concatenate binary consistency preservation specifications on different pairs of model types, we use the following definition that simply restricts the number of modified models appropriately.

% \begin{definition}[Binary Consistency Preservation Specification]
% \label{def:binary_consistency_preservation_specification}
% A binary consistency preservation specification $CPS_{CS{i,j}}$ for a binary consistency specification $CS_{i,j}$ is a function according to \autoref{def:consistency_preservation_specification}, which only changes $\mathcal{M}_i$ and $\mathcal{M}_j$, so that 
% %This means that for models $M_1, \ldots, M_n$ with $(M_1, \ldots, M_n) \in CS$ and modified instances $M'_1, \ldots, M'_n$
% %\begin{align*}
%     %((M_1, M''_1), \dots, (M_n, M''_n)) := CPS_{CS, \mathcal{M}_{i,j}}(M_1, \dots, M_n, M'_i)
% %\end{align*}
% %holds
% %\begin{align*}
%     $CS_{i,j}(M''_i, M''_j) \land \forall k \in \{1, \dots, n\}\backslash\{i, j\} : M'_k = M''_k$
% %\end{align*}
% \end{definition}

% We are interested in consistency preservation specifications that can be executed in arbitrary order, so that they finally terminate in a consistent state regarding all consistency specifications, comparable to a fixed-point iteration.
% Therefore, it is essential for all specifications to be hippocratic~\cite{stevens2010sosym}, so that no changes are performed when models are already consistent.
% Let $\mathcal{CPS}$ be a set of preservation specifications %\mathit{CPS}_1, \dots, \mathit{CPS}_k$ 
% for consistency specifications $\mathcal{CS}$. % = \{CS_1, \dots, CS_l\}$, 
% We denote the set of consistent model tuples regarding $\mathcal{CS}$ as $\mathfrak{M}_{\mathcal{CS}} = \{(M_1, \dots, M_n) \mid %\forall i, j, 0 \leq i,j \leq n : 
% \forall \mathit{CS}_{i,j} \in \mathcal{CS} : (M_i, M_j) \in \mathit{CS}_{i, j}\}$.
% We want to achieve that:
% \begin{align*}
%     & \forall (M_1, \dots, M_n) \in \mathfrak{M}_{\mathcal{CS}} : %\{(M_1, \dots, M_n) \mid \forall CS_{i,j} \in \mathcal{CS} \Rightarrow (M_i, M_j) \in CS_{i, j}\} : \\ %0 \leq i,j \leq n : \exists CS_{i,j} \in \mathcal{CS} \Rightarrow (M_i, M_j) \in CS_{i, j}\} : \\
%     % & \hspace{1em} 
%     \forall M'_1 \in \mathcal{M}_1, \dots, M'_n \in \mathcal{M}_n : \exists \mathit{CPS}_1, \dots, \mathit{CPS}_k \in \mathcal{CPS} : \\
%     %& \forall M_1, \dots, M_n \mid \big( \forall CS_{i,j} \in \mathcal{CS} : (M_i, M_j) \in CS_{i, j} \big) : \\ % (i,j) \mid 1 \leq i, j \leq n
%     %& \exists p \in \mathbb{N}: (CPS_1 \circ \dots \circ CPS_k)^p \big( (M_1, M'_1), \dots, (M_n, M'_n) \big) = \big( (M_1, M''_1), \dots, (M_n, M''_n) \big) \\
%     & \hspace{1em} \mathit{CPS}_1 \circ \dots \circ \mathit{CPS}_k \big( (M_1, M'_1), \dots, (M_n, M'_n) \big) = \big( (M_1, M''_1), \dots, (M_n, M''_n) \big) \\
%     & \hspace{2em} \land \forall \mathit{CS}_{i,j} \in \mathcal{CS} : (M''_i, M''_j) \in \mathit{CS}_{i, j} %\forall (i,j) \mid 1 \leq i, j \leq n : CS_{i, j}(M''_i, M''_j)
% \end{align*}

% This means that there is always a sequence of consistency preservation specification applications, potentially with multiple applications of the same specification, that ensures that the modified models in all tuples are consistent after applying it.

%\todoHeiko{Zunächst mal die Konkatenierung erklären. Wir nehmen an, dass in einer korrekten Spezifikation eine Konkatenation existiert, die für eine beliebige Änderung wieder ein konsistentes Modell ausspuckt. Dafür ist die Ausführungsreihenfolge der Spezifikationen egal. Da man in der Praxis nicht nur wissen muss, dass die Modelle nach einer ausreichend langen Ausführung der Spezifikationen konsistent sind, sondern auch terminieren muss, wird die hippocraticness Eigenschaft~\cite{stevens2007a} vorausgesetzt, nach der Transformationen nichts tun, wenn die Modelle bereits konsistent sind. Siehe Fixpunktiteration} 

% Declarative transformation languages are usually well suited to define consistency specifications according to \autoref{def:consistency_specification}, 
% from which a consistency preservation specification is %, in the best case automatically, 
% derived. 
% Imperative transformation languages can be used to define consistency preservation specifications according to \autoref{def:consistency_preservation_specification}. 

% \end{copiedFrom} % ICMT

