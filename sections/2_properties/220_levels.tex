\chapter{Consistency Specification Levels}

% CONTEXT - MOTIVATION FOR NETWORKS OF BX
Models that contain concern-specific extracts of a system are a means to deal with the increasing complexity in today's software development. % projects. % of today's software systems.
%The complexity of software systems is continuously increasing.
%One approach to deal with that is the separation of a system description into different models containing concern-specific properties or extracts of the system.
%Such a fragmentation of information %into different models 
%results in dependencies %and redundancies 
%that have to be kept consistent.
%A common approach for preserving consistency between models are transformations, which incrementally update the models to stay consistent.
%\emph{Incremental \acp{BX}}, which keep two types of models consistent, are well researched. %, especially in terms of \emph{bidirectional transformations}, which consider both directions of changes.
A common approach for preserving consistency between %dependent information in 
such models are incremental \acp{BX}, which %incrementally 
keep two types of models consistent.
Usually, more than two types of models are used in development processes. % within a project. %development process. %, which necessitates approaches that keep multiple models consistent.
% ABSTRACT PROBLEMS
%\todoHeiko{Obsolete?}
%Consistency between multiple types of models 
Keeping them consistent can be achieved by combining \acp{BX} to networks, which has not been focused in research yet~\cite{stevens2017a}.
When such networks contain cycles, %is not a tree anymore, problems can easily occur, because 
information can be propagated across different paths during transformation execution, which may lead to problems on confluence.
%Those problems can occur because of different reasons.
%One reason is that the individual transformations are developed independently by different domain experts, who do usually not know about the transformations their one will be combined with.
%This can easily lead to contradictions in the considered consistency relations, as well as their operationalization.
%This is especially problematic if different domain experts only know about consistency relations within a limited set of models.
%They develop transformations independently, without knowing about the other transformations their one will be combined with later on.
%Such a \emph{black-box} combination can easily lead to contradictions in the considered consistency constraints as well as incompatibilities of thee operationalization of combined transformations.

%Consider the consistency relations exemplified on three simple models in \autoref{fig:motivation_example}.
%The \ac{PCM} is a component-based architecture description language, which also provides abstract specifications of services, so called SEFFs, to conduct performance predictions~\cite{reussner2016a}.
%A component is represented as one implementation class and one utility class in UML and Java code.
%SEFFs are represented as methods.
%These consistency relations are an alternation of those developed by \cite{langhammer2015a}.

% EXEMPLARY PROBLEMS
Consider the simple consistency relations exemplified in \autoref{fig:properties:motivational_example}.
A company uses three software systems to manage (1)~personnel data, (2)~tasks and their assignment to employees, and (3)~schedules for work times of employees and the deadlines of tasks.
The domain models contain dependent information, especially the data about employees and their relations to tasks, but none of them contains a superset of information of another, which requires to define consistency between all pairs of them.
If three domain experts define %the consistency constraints between all pairs of the \metamodels 
those binary constraints
independently, they can easily contradict. 
For example, imagine %that they specify 
a direct mapping of employee \emph{name} representations between the task management and scheduling system, a concatenation of \emph{firstname} and \emph{lastname} between personnel data and task management system and a comma-separated concatenation of \emph{lastname} and \emph{firstname} between personnel data and scheduling system.
These constraints are obviously incompatible, as they cannot be fulfilled at the same time.
%Additionally, even if the name mappings were compatible, specifying three transformations between all pairs of \metamodels that preserve those constraints leads to redundancies within the transformations.
%In consequence, the transformation have to ensure that they no element duplications arise from that.
%%leads to redundant the operationalization of transformations that preserve these constraints has to ensure that no element duplications arise from redundant transformations paths. 
%%Additionally, even if the name mapping was compatible, the operationalization of transformations that preserve these constraints has to ensure that no element duplications arise from redundant transformations paths. 
%For example, after adding an employee to the personnel data system, a transformation adds an employee to the task management system, which is then transformed into an employee in the scheduling system. 
%The additional transformation between personnel and scheduling system must correctly consider that an employee was already created transitively.
%\todoHeiko{Checken, ob auf Duplizierungsproblem später verwiesen wird, dann hier wieder einfügen}

\begin{figure}[tb]
    \centering
    %\includegraphics[angle=270, width=\textwidth]{figures/motivation_employee_example.pdf}
    \input{figures/properties/motivational_employee_example.tex}
    %\caption{Exemplary Consistency Relations between a PCM, UML Class and Java Model}
    \caption{Exemplary Consistency Relations ({\protect\tikz[baseline=-0.5ex] \protect\draw[latex-latex, consistency related element] (0,0) -- (1.5em,0);}) between Three Simple \Metamodels} %Personnel, Task Management and Scheduling System \Metamodels}
    \label{fig:properties:motivational_example}
\end{figure}

% ABSTRACT PROBLEMS
While such a problem may be trivially solvable in this simple scenario, it gets difficult in systems with more and larger \metamodels, %, especially in software development or system engineering scenarios, in which 
where
each domain expert only knows about the relation between two of them, but not about the others.
In consequence, each \ac{BX} has to be constructed in such a way that it can be combined with other, independently developed \acp{BX} in a \emph{black-box} manner later on.
Issues that arise from such a combination of independently developed \acp{BX} %the combination of independently developed \acp{BX} %to networks of them 
have not been investigated yet. %and categorized yet.
In consequence, potential failures, causal mistakes and techniques to avoid them by design are not systematically known.

% GOAL AND CONTRIBUTIONS
Our research goal is to identify and categorize issues that can arise from the combination of independently developed \acp{BX} to networks and how those issues can be avoided by construction. 
%Instead of performing analysis a-posteriori, when combining transformations to a network, we investigate how to deal with issues a-priori by avoiding them.
Our main contributions in this paper are:
\begin{description}[leftmargin=\parindent]
    \item[\contributionlabel{contrib:levels}{Classification of consistency specification levels}{C1}:] We identify different conceptual levels at which consistency for a set of model types can be defined.
    \item[\contributionlabel{contrib:issues}{Categorization of interoperability issues}{C2}:] We identify potential failures and mistakes in transformation networks and relate them to the specification levels.
    \item[\contributionlabel{contrib:avoidance}{Issue avoidance strategies}{C3}:] We discuss avoidance strategies for mistakes at the different levels and their degree of independence from the concrete scenario. %develop a problem-independent strategy to avoid a category of issues on one specification level.
    \item[\contributionlabel{contrib:evaluation}{Appropriateness evaluation}{C4}:] We show completeness and appropriateness of our categorization by applying it to %a case study of 
    independently developed transformations. %We apply our categorization %and the solution strategy 
    %to a case study of independently developed transformations to show completeness and appropriateness . %of our categorization.
\end{description}

We want to achieve a development process in which 
%that 
\acp{BX} are specified as partial descriptions of consistency, %in a complete system 
which can be combined to a network on demand, so that their repeated execution in arbitrary order leads to a consistent state after changes.
Our contributions help to achieve that by forming systematic knowledge on interoperability issues that have to be considered and solved.
%\todoHeiko{Add benefit of these contributions}

%We start with a clarification of assumptions and a formalization of basic concepts in \autoref{sec:foundations}.
%\autoref{sec:process} defines three conceptual levels in the consistency specification process.
%In \autoref{sec:classification}, we identify and categorize issues in transformation networks.
%We develop a solution strategy for one category of issues in \autoref{sec:avoiding} and evaluate our findings in \autoref{sec:evaluation}.
%After a comparison with related work in \autoref{sec:relatedwork}, we conclude the paper.


% Problem:
% \begin{itemize}
%     \item bx good for keeping models incrementally consistency
%     \item Usually more than two models involved
%     \item bx can be chained but as soon as the network is not a tree anymore, problems can easily occur
%     \item Additionally: Usually each domain expert develops single bx, which has to be combined with others afterwards, without knowing about them a priori (make this really, really clear as an important assumption!)
%     \item Such interoperability issues of incremental bx were not systematically investigated
% \end{itemize}

% \todoHeiko{Make assumptions explicit! Incremental, distributed development (divide and conquer), ...}
% \begin{itemize}
%     \item Repair, not only checking!
%     \item Incremental transformations for consistency preservation
%     \item Independent development of binary transformations by domain experts -> Necessity to independently develop and combine transformations afterwards
%     \item Normative: We define what is consistent (rather than defining consistency and checking it against a "real" relation)
% \end{itemize}

% Goal:
% \begin{itemize}
%     \item Goal was to investigate, how far interoperability of transformations can be achieved by construction (a-priori, rather than a-posteriori analysis)
%     \item Therefore, we categorized specification levels, mistakes and resulting failures associated with the different specification levels to derive from the characteristics of those levels how far they mistakes from that level can be omitted by construction
% \end{itemize}

% MAIN GOAL: Achieve interoperability by construction, as far as possible, by identifying and categorizing potential issues.

% Contribution:
% \begin{enumerate}
%     \item Identification and classification of potential issues $\rightarrow$ catalog to make developers aware of potential faults, their impact/manifestations to know what to consider during development
%     \item Generic solutions for one class of issues that can be generically solved
%     \item Application of classification and solutions to a case study to show completeness, appropriateness
% \end{enumerate}


\section{The Consistency Specification Process}
\label{sec:process}

%\todoHeiko{Annahme: Immer nur Änderung an einem Modell (keine Synchronisation)}

The process of specifying consistency between $n>2$ types of models using a network of \acp{BX} can be separated into different conceptual levels.
We distinguish three such levels:
At the \emph{global level}, we describe the ($n$-ary) relations between all involved model types.
At the \emph{modularization level}, we split these global relations into modular, binary relations.
Finally, at the \emph{operationalization level}, we define preservation of consistency %after changes 
according to the modular relations.
That classification forms our contribution \ref{contrib:levels}.

All of these levels have to be considered during the consistency specification process.
A developer specifies consistency on one of these levels, depending on the abstraction level that the transformation language provides, and the transformation engine finally derives an operationalization from that.
Although a developer does not specify consistency on multiple levels, he or she has to think about the levels on and above the one consistency is specified on.
For example, to define an operationalization, the developer must be aware of the modular consistency relations.
%If a developer only specifies the modular consistency relations, the transformations engine has to derive an appropriate operationalization.
%In the end, to preserve consistency, an operationlization has to be derived from a specification on any of those levels.
The benefit of clearly separating these levels is that they have different potentials for mistakes, faults, and resulting failures. 
Consequently, avoiding a specific kind of mistake, which is related to one of the identified levels, completely prevents a specific category of failures.
We exemplify these levels in \autoref{fig:properties:levels_overview} and explain them in more detail in the following.

%\todoHeiko{Give an example for mistakes here! Maybe one example for every level as well?}

\subsection{Consistency Specification Levels}
\label{sec:process:levels}

\begin{figure}
    \centering
%    \includegraphics[angle=-90, width=\textwidth]{figures/levels_overview.pdf}
    \input{figures/properties/levels_overview.tex}
    \caption{Examples for Abstraction Levels in the Consistency Specification Process}
    \label{fig:properties:levels_overview}
\end{figure}

%\todoHeiko{Definieren was Correctness auf jedem der Levels heißt. System: Richtig bzgl. den tatsächlichen Konsistenzbeziehungen, Modularization: Richtig bzgl. der globalen Spezifikation, Operationalization: Korrekte Ergebnisse nach Änderungen bzgl. der modularen Spezifikationen}

\subsubsection*{Level 1 (\emph{Global}):}
At the most abstract level, we consider the knowledge about all actual consistency relations between the involved model types.
This knowledge can be represented by an $n$-ary relation between all model types, containing all tuples of consistent instances of the $n$ model types according to a consistency specification (\autoref{def:consistency_specification}). 
We refer to this as a \emph{global} consistency specification.

\subsubsection*{Level 2 (\emph{Modularization}):} 
At the second level, the global knowledge of the first level is separated into partial, binary consistency relations that, in combination, represent the overall knowledge about consistency in the system.
These relations should not contain any contradictions.
We do not necessarily need to describe relations between all pairs of model types, since some may not share information that may become inconsistent, or some may be represented transitively across other relations.
%This does also comprise the selection of a network structure that is capable of representing the full system knowledge.
%Mathematically speaking, on this level the knowledge on this level 
This knowledge 
can be represented by up to $\frac{n*(n-1)}{2}$ binary relations, each containing all pairs of instances of two of the model types that are consistent.
This corresponds to a set of binary consistency specifications according to \autoref{def:consistency_specification}.
We refer to these as \emph{modular} consistency specifications.\\[-1em]

\noindent\textit{Remark:} 
%\begin{remark*}
Although in theory not all kinds of $n$-ary relations can be separated into binary relations~\cite{stevens2017a}, we assume that all consistency relations considered in an automated consistency preservation process can be expressed by binary relations.
We shortly discussed why this is a reasonable assumption in \autoref{sec:foundations:assumptions}.
%As stated by \textcite{stevens2017a}, this is a reasonable assumption, because it is hard enough for people to think about and specify binary relations.
%Additionally, the separation into binary relations is the extreme case, which we explicitly consider here, nevertheless our finding also apply to a modularization into consistency specifications of higher arity.
%\end{remark*}

%\todoHeiko{Definieren, wie man mit mehrere CPS Konsistenz erreicht -> Zum Ziel der Arbeit kommen, dass man modulare CPS bel. Veschalten kann, um zu Konsistenz zu kommen.}  
\subsubsection*{Level 3 (\emph{Operationalization}):}
At this level, the consistency preservation is operationalized in terms of binary consistency preservation specifications according to \autoref{def:consistency_preservation_specification}. % for modular consistency specifications %after \autoref{def:consistency_specification} 
%on the second level.
%This requires the definition of update operations that restore consistency after user changes.
As discussed in \autoref{sec:foundations:consistency}, we consider a set of consistency preservation specifications that can be composed to restore consistency.
In contrast to a single \ac{BX}, an operationalization in %arbitrary
networks of \acp{BX} has to deal with confluence of information.
This can lead to problems, such as overwrites or duplications of information, whenever a change can be propagated across at least two paths in the network of \acp{BX} to the same model.
%It especially requires an identification of matching elements in different consistency preservation specifications to avoid duplicate element creations or insertions. 
%For example, if an element is propagated from a model of $\mathcal{M}_1$ to a model of $\mathcal{M}_2$ and from this model to one of $\mathcal{M}_3$, then an additional consistency preservation specification from $\mathcal{M}_1$ to $\mathcal{M}_3$ must consider the already existing element instead of creating an additional or overwriting the existing one.
We have seen an example, in which such multiple transformation paths cannot be avoided, in \autoref{fig:properties:motivational_example}.
%We refer to these as modular consistency preservation specifications.

%\todoHeiko{Maybe call this recombination of modularized knowledge? Makes fokus more on operationalization/ consistency preservation, as that is where the problems occur}
%Mathematically speaking, on this level consistency preservation specifications according to \autoref{def:consistency_preservation_specification} are defined, which adhere to the consistency specifications according to \autoref{def:consistency_specification} on the second level.
%Mathematically speaking, this is the step from a consistency specification of relations to a consistency preservation specification of restore functions.
%We refer to these as modular consistency preservation specifications.
%OLD: partial knowledge (adding information to make partial specifications combinable without knowing about the others)


\subsection{Selecting the Specification Level}

A transformation language finally derives a consistency preservation specification from a specification on any of the levels and executes it. %specification is finally transformed into a consistency preservation specification by a transformation language, no matter on which level it is specified.
Imperative transformation languages expect specifications at the operationalization level, whereas rather declarative, usually bidirectional transformation languages expect specification at the modularization level.
Specifications at the global level are rather unusual, but could for example be expressed with multidirectional QVT-R~\cite{macedo2014a}, or the Commonalities language~\cite{gleitze2017a}.
A specification must finally be free of mistakes that can be made on any of those levels. 
The responsibility depends on the abstraction level the transformation language provides, as the developer is responsible for avoiding mistakes at or above the level at which he or she specifies consistency, whereas the transformation language is responsible for those below.

Specifications must especially be correct regarding all higher levels.
This means that an operationalization in consistency preservation specifications must preserve consistency according to the underlying modular consistency specifications.
So after changing a consistent set of models, the consistency preservation has to return another set of models that is consistent again, as shown in \autoref{fig:properties:levels_overview}.
Additionally, modular consistency specifications must be correct regarding the global specification in the sense that it must contain the same sets of models as the global specification. %exactly those sets of models that are in the relation of the modular specification are in the one of global specification.
Finally, the global consistency specification has to be correct regarding some, usually informal, notion of consistency for the considered model types.
Since this can usually not be validated, we assume a global specification to be correct. %made the assumption of having normative consistency specifications.
This conforms to the notion of \emph{correctness} already defined for \acp{BX}~\cite{stevens2010sosym}, but is used for the extension to networks of \acp{BX} here.

% A specification on one level must always be correct regarding all higher levels.
% This means, for example, that an operationalization in consistency preservation specifications must preserve consistency according to the underlying modular consistency specifications.
% So after changing a consistent set of models, the consistency preservation has to return another set of models that is consistent again, as shown in \autoref{fig:levels_overview}.
% Additionally, modular consistency specifications must be correct regarding the global specification in the sense that it must contain the same sets of models than the global specification. %exactly those sets of models that are in the relation of the modular specification are in the one of global specification.
% Finally, the global consistency specification has to be correct regarding some, usually informal notion of consistency for the considered model types.
% Since this can usually not be validated, we assume a global specification to be correct. %made the assumption of having normative consistency specifications.

% To preserve consistency for a set of models, all specification levels have to be considered.
% A developer defines a concrete specification on one of these levels, which usually depends on the used transformation language and especially the level of abstraction it provides.
% He therefore has to consider all levels on and above the one he specifies consistency on to ensure correctness, and especially has to avoid mistakes that can be made on those levels.
% On the other hand, the transformation language abstracts from all levels below the one consistency is specified on, and especially has to avoid all mistakes that can be made there.
% In the end, %for correct consistency preservation, 
% all mistakes on all levels must be avoided, but the responsibility depends on the level consistency is specified on.


% %Depending on level on which consistency is defined, potentials mistakes that can be made on one of the levels either have to be avoided by the developer or by the used transformation language and its engine.
% %The developer must avoid all mistakes that can arise from the conceptual levels on and above the one he specifies consistency one, whereas the transformation language must ensure that no mistakes occur on the lower levels, which it abstracts from.
% Imperative transformation languages expect specifications on the operationalization level, which means that the transformation developer has to ensure that he makes no mistakes on the Levels 1--3.
% Rather declarative, usually bidirectional transformation languages expect specifications on the modularization level, as they abstract from the operationalization. In that case, the developer must only deal with potential mistakes from Level 1--2 and possible operationalization mistakes have to be handled by the language and its engine.
% Finally, specifications on system level are rather unusual, but could for example be expressed with multidirectional QVT-R~\cite{macedo2014a}, or the Commonalities language~\cite{gleitze2017a}. % or the domain-specific DUALLY approach~\cite{eramo2012a}. %Nevertheless, knowledge about the overall consistency constraints in the system is still important, even when providing a specification on a lower level.
% \todoHeiko{Die letzten beiden Abschnitte möglicherweise tauschen, da im letzten eingängier erklärt wird, wie die Ebenen voneinandern abhängen. Der mittele Abschnitt ist sehr schwer verständlich.}
% %As we are focused on networks of \acp{BX}, whose specification happens on the modularization or operationalization level, we are especially concerned with those two levels. 
% %We therefore assume that the developer ensures that no mistakes on the system level are made by knowing about


